{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6274860,"sourceType":"datasetVersion","datasetId":3607457,"isSourceIdPinned":false}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:08:21.787816Z","iopub.execute_input":"2025-09-26T04:08:21.788094Z","iopub.status.idle":"2025-09-26T04:08:24.175377Z","shell.execute_reply.started":"2025-09-26T04:08:21.788066Z","shell.execute_reply":"2025-09-26T04:08:24.174164Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/cervical-cancer-dataset/cervical-cancer_csv.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# FIX compatibility issue between scikit-learn and imbalanced-learn\n!pip install -q scikit-learn==1.3.2 imbalanced-learn==0.11.0\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:08:24.176552Z","iopub.execute_input":"2025-09-26T04:08:24.177595Z","iopub.status.idle":"2025-09-26T04:08:34.521314Z","shell.execute_reply.started":"2025-09-26T04:08:24.177556Z","shell.execute_reply":"2025-09-26T04:08:34.520447Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"ranzeet013/cervical-cancer-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:08:34.522474Z","iopub.execute_input":"2025-09-26T04:08:34.522749Z","iopub.status.idle":"2025-09-26T04:08:35.074068Z","shell.execute_reply.started":"2025-09-26T04:08:34.522724Z","shell.execute_reply":"2025-09-26T04:08:35.073175Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/cervical-cancer-dataset\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cervical Cancer Prediction - Advanced Kaggle-ready Pipeline\n# File: cervical_cancer_advanced_pipeline.py\n# Purpose: End-to-end notebook-style script to train advanced ML models (classical + Deep Learning CNN)\n# on the provided cervical cancer dataset for research / Kaggle experiments.\n# Dataset path (as provided by user): /kaggle/input/cervical-cancer-dataset/cervical-cancer_csv.csv\n\n# ---------- 1. Install required packages (Kaggle-friendly) ----------\n# Run these cells at top of the notebook / script. Kaggle generally has many packages preinstalled,\n# but we include pip installs for ones that might be missing.\n\n!pip install -q xgboost imbalanced-learn shap tensorflow==2.12.0 scikit-optimize\n\n# ---------- 2. Imports ----------\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nimport matplotlib.pyplot as plt\n\n# Reproducibility\nSEED = 42\nnp.random.seed(SEED)\nrandom.seed(SEED)\ntf.random.set_seed(SEED)\n\n# ---------- 3. Load dataset ----------\nDATA_PATH = '/kaggle/input/cervical-cancer-dataset/cervical-cancer_csv.csv'\nassert os.path.exists(DATA_PATH), f\"Dataset not found at {DATA_PATH}. Please check path.\"\n\ndf = pd.read_csv(DATA_PATH)\n\n# Quick peek\nprint('Shape:', df.shape)\nprint(df.columns.tolist())\n\ndf.head()\n\n# ---------- 4. Column names and target ----------\n# The user provided these columns: Age, Number of sexual partners, First sexual intercourse,\n# Num of pregnancies, Smokes, Smokes (years), Smokes (packs/year), Hormonal Contraceptives,\n# Hormonal Contraceptives (years), IUD  -- but dataset may have more columns. We'll detect target.\n\n# Try to find a binary target commonly present in cervical cancer datasets. Common columns: 'Hinselmann', 'Schiller', 'Citology', 'Biopsy'\n# We'll use a composite target: if any of the diagnostic columns are positive (1), mark as positive. If the dataset already has a target column named e.g. 'Biopsy', prefer it.\n\npossible_targets = ['Biopsy','Hinselmann','Schiller','Citology','biopsy']\nexisting_targets = [c for c in df.columns if c in possible_targets]\n\nif existing_targets:\n    TARGET = existing_targets[0]\n    print('Using existing target column:', TARGET)\nelse:\n    # Create composite target from any of the diagnostic columns if present\n    diag_cols = [c for c in df.columns if c.lower() in ['hinselmann','schiller','citology','biopsy']]\n    if diag_cols:\n        TARGET = 'target_composite'\n        df[TARGET] = (df[diag_cols].sum(axis=1) > 0).astype(int)\n        print('Created composite target from:', diag_cols)\n    else:\n        # fallback: ask user (but per instruction don't ask) -> choose last column if it's binary\n        last_col = df.columns[-1]\n        unique_vals = df[last_col].dropna().unique()\n        if set(unique_vals) <= set([0,1]) or len(unique_vals) <= 5:\n            TARGET = last_col\n            print('Falling back to last column as target:', TARGET)\n        else:\n            raise ValueError('No obvious binary target found in dataset columns. Please provide the target column name.')\n\n# ---------- 5. Basic EDA (counts, missingness) ----------\nprint('\\nTarget distribution:')\nprint(df[TARGET].value_counts(dropna=False))\n\nmissing = df.isna().mean().sort_values(ascending=False)\nprint('\\nTop missingness:')\nprint(missing[missing>0].head(20))\n\n# ---------- 6. Select features (focus on user-provided columns + numeric columns)\n# We'll take numeric columns except the target and identifier columns.\n\nexcluded = [TARGET]\n# Drop ID-like columns if exist\nid_like = [c for c in df.columns if c.lower() in ['id','patient_id','record_id']]\nexcluded += id_like\n\nnumeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\nfeatures = [c for c in numeric_cols if c not in excluded]\n\nprint('\\nNumeric features found (used):', features)\n\n# If user-specified subset exists, prioritize those column names\nuser_cols = ['Age','Number of sexual partners','First sexual intercourse','Num of pregnancies','Smokes','Smokes (years)','Smokes (packs/year)','Hormonal Contraceptives','Hormonal Contraceptives (years)','IUD']\npresent_user_cols = [c for c in user_cols if c in df.columns]\nif present_user_cols:\n    # ensure they are included and maintain order\n    features = present_user_cols + [c for c in features if c not in present_user_cols]\n    print('Using user-specified columns subset present in dataset:', present_user_cols)\n\n# ---------- 7. Preprocessing pipeline ----------\n# Impute numeric features using median; scale using StandardScaler\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numeric_transformer, features)\n], remainder='drop')\n\n# ---------- 8. Prepare train/test split ----------\nX = df[features].copy()\ny = df[TARGET].astype(int)\n\n# Small datasets need careful splitting; we'll stratify\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\nprint('\\nTrain shape:', X_train.shape, 'Test shape:', X_test.shape)\n\n# ---------- 9. Baseline classical ML models with SMOTE and pipeline ----------\n# We'll train Logistic Regression, RandomForest, XGBoost with a consistent pipeline that handles scaling and SMOTE.\n\nmodels_dict = {}\n\n# Logistic Regression\npipe_lr = ImbPipeline(steps=[\n    ('pre', preprocessor),\n    ('smote', SMOTE(random_state=SEED)),\n    ('clf', LogisticRegression(max_iter=2000, class_weight='balanced', random_state=SEED))\n])\npipe_lr.fit(X_train, y_train)\nmodels_dict['logistic'] = pipe_lr\n\n# Random Forest\npipe_rf = ImbPipeline(steps=[\n    ('pre', preprocessor),\n    ('smote', SMOTE(random_state=SEED)),\n    ('clf', RandomForestClassifier(n_estimators=200, random_state=SEED, class_weight='balanced'))\n])\npipe_rf.fit(X_train, y_train)\nmodels_dict['random_forest'] = pipe_rf\n\n# XGBoost (scale_pos_weight instead of SMOTE for XGBoost experiment)\n# Compute scale_pos_weight\npos = (y_train==1).sum(); neg = (y_train==0).sum()\nscale_pos_weight = neg / max(pos,1)\n\npipe_xgb = Pipeline(steps=[\n    ('pre', preprocessor),\n    ('clf', xgb.XGBClassifier(n_estimators=300, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight, random_state=SEED))\n])\npipe_xgb.fit(X_train, y_train)\nmodels_dict['xgboost'] = pipe_xgb\n\n# Evaluate classical models\nprint('\\nClassical models evaluation on test set:')\nfor name, model in models_dict.items():\n    y_proba = model.predict_proba(X_test)[:,1]\n    y_pred = model.predict(X_test)\n    auc = roc_auc_score(y_test, y_proba)\n    ap = average_precision_score(y_test, y_proba)\n    acc = accuracy_score(y_test, y_pred)\n    print(f\"{name}: AUC={auc:.4f}, AP={ap:.4f}, Acc={acc:.4f}\")\n\n# Save classical models\nimport joblib\nos.makedirs('/kaggle/working/models', exist_ok=True)\nfor name, model in models_dict.items():\n    joblib.dump(model, f\"/kaggle/working/models/{name}.joblib\")\n\n# ---------- 10. Advanced Deep Learning: 1D-CNN on tabular data ----------\n# Approach: treat the feature vector as a 1D sequence of length = num_features and apply Conv1D.\n# Pros: can learn local interactions between features; useful as an experimental architecture.\n\n# Preprocess: impute + scale then reshape to (samples, timesteps=num_features, channels=1)\nX_all = preprocessor.fit_transform(X)\n\n# Fit scaler & imputer already done inside preprocessor; we'll reuse for train/test transforms\nX_train_proc = preprocessor.transform(X_train)\nX_test_proc = preprocessor.transform(X_test)\n\n# reshape\nn_features = X_train_proc.shape[1]\nX_train_cnn = X_train_proc.reshape((-1, n_features, 1))\nX_test_cnn = X_test_proc.reshape((-1, n_features, 1))\n\n# handle class imbalance by computing class weights\nfrom sklearn.utils import compute_class_weight\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = {i: w for i,w in enumerate(class_weights)}\nprint('\\nClass weights for CNN:', class_weight_dict)\n\n# Build CNN model\ndef build_cnn(input_shape, dropout=0.3, lr=1e-3):\n    inputs = layers.Input(shape=input_shape)\n    x = layers.Conv1D(64, kernel_size=3, padding='same', activation='relu')(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv1D(128, kernel_size=3, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.Dropout(dropout)(x)\n    outputs = layers.Dense(1, activation='sigmoid')(x)\n    model = models.Model(inputs, outputs)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['AUC'])\n    return model\n\ncnn = build_cnn((n_features,1), dropout=0.4, lr=1e-3)\ncnn.summary()\n\n# Callbacks\nes = callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\nreduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6)\n\n# Augment training with SMOTE for CNN as well (we'll create balanced X_train_proc/y_train)\nsm = SMOTE(random_state=SEED)\nX_train_bal, y_train_bal = sm.fit_resample(X_train_proc, y_train)\nX_train_bal_cnn = X_train_bal.reshape((-1, n_features, 1))\n\n# Train CNN\nhistory = cnn.fit(\n    X_train_bal_cnn, y_train_bal,\n    validation_data=(X_test_cnn, y_test),\n    epochs=200,\n    batch_size=32,\n    class_weight=None, \n    callbacks=[es, reduce_lr],\n    verbose=2\n)\n\n# Evaluate CNN\ny_proba_cnn = cnn.predict(X_test_cnn).ravel()\nauc_cnn = roc_auc_score(y_test, y_proba_cnn)\nap_cnn = average_precision_score(y_test, y_proba_cnn)\nprint(f\"\\nCNN: AUC={auc_cnn:.4f}, AP={ap_cnn:.4f}\")\n\n# Save CNN\ncnn.save('/kaggle/working/models/cnn_tabular.h5')\n\n# Plot training curves\nplt.figure(figsize=(10,4))\nplt.subplot(1,2,1)\nplt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.legend(); plt.title('Loss')\n\nplt.subplot(1,2,2)\nplt.plot(history.history['auc'], label='train_auc')\nplt.plot(history.history['val_auc'], label='val_auc')\nplt.legend(); plt.title('AUC')\n\nplt.tight_layout()\nplt.savefig('/kaggle/working/training_curves.png')\n\n# ---------- 11. Model explainability (SHAP) ----------\ntry:\n    import shap\n    explainer = shap.TreeExplainer(models_dict['random_forest'].named_steps['clf'])\n    # Need to pass preprocessed sample\n    X_test_shap = preprocessor.transform(X_test)\n    shap_values = explainer.shap_values(X_test_shap)\n    # Summary plot (be mindful of headless environment)\n    shap.summary_plot(shap_values, X_test_shap, feature_names=features, show=False)\n    plt.savefig('/kaggle/working/shap_summary.png')\nexcept Exception as e:\n    print('SHAP explanation failed or is unavailable in this environment:', e)\n\n# ---------- 12. Cross-validation and reporting ----------\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\ncv_aucs = []\nfor fold, (train_ix, val_ix) in enumerate(skf.split(X, y)):\n    X_tr, X_val = X.iloc[train_ix], X.iloc[val_ix]\n    y_tr, y_val = y.iloc[train_ix], y.iloc[val_ix]\n    pipe = Pipeline(steps=[('pre', preprocessor), ('clf', xgb.XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric='logloss', random_state=SEED))])\n    pipe.fit(X_tr, y_tr)\n    yv = pipe.predict_proba(X_val)[:,1]\n    auc = roc_auc_score(y_val, yv)\n    cv_aucs.append(auc)\n    print(f'Fold {fold+1} AUC: {auc:.4f}')\n\nprint('CV AUC mean {:.4f} +/- {:.4f}'.format(np.mean(cv_aucs), np.std(cv_aucs)))\n\n\n\nprint('\\nAll models and artifacts saved to /kaggle/working/models and images saved to /kaggle/working')\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:08:35.076525Z","iopub.execute_input":"2025-09-26T04:08:35.076789Z","iopub.status.idle":"2025-09-26T04:10:38.748119Z","shell.execute_reply.started":"2025-09-26T04:08:35.076767Z","shell.execute_reply":"2025-09-26T04:10:38.747225Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nbayesian-optimization 3.0.0 requires numpy>=1.25; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.23.5 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\nscikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\ntreescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\norbax-checkpoint 0.11.16 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\nalbumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\npymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nblosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\nxarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\nflax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nalbucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\ndb-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\nchex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nxarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mShape: (835, 36)\n['Age', 'Number of sexual partners', 'First sexual intercourse', 'Num of pregnancies', 'Smokes', 'Smokes (years)', 'Smokes (packs/year)', 'Hormonal Contraceptives', 'Hormonal Contraceptives (years)', 'IUD', 'IUD (years)', 'STDs', 'STDs (number)', 'STDs:condylomatosis', 'STDs:cervical condylomatosis', 'STDs:vaginal condylomatosis', 'STDs:vulvo-perineal condylomatosis', 'STDs:syphilis', 'STDs:pelvic inflammatory disease', 'STDs:genital herpes', 'STDs:molluscum contagiosum', 'STDs:AIDS', 'STDs:HIV', 'STDs:Hepatitis B', 'STDs:HPV', 'STDs: Number of diagnosis', 'STDs: Time since first diagnosis', 'STDs: Time since last diagnosis', 'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Dx', 'Hinselmann', 'Schiller', 'Citology', 'Biopsy']\nUsing existing target column: Hinselmann\n\nTarget distribution:\nHinselmann\n0    800\n1     35\nName: count, dtype: int64\n\nTop missingness:\nSTDs: Time since last diagnosis       0.914970\nSTDs: Time since first diagnosis      0.914970\nIUD                                   0.134132\nIUD (years)                           0.134132\nHormonal Contraceptives               0.123353\nHormonal Contraceptives (years)       0.123353\nSTDs:pelvic inflammatory disease      0.119760\nSTDs:vulvo-perineal condylomatosis    0.119760\nSTDs:HPV                              0.119760\nSTDs:Hepatitis B                      0.119760\nSTDs:HIV                              0.119760\nSTDs:AIDS                             0.119760\nSTDs:molluscum contagiosum            0.119760\nSTDs:genital herpes                   0.119760\nSTDs:syphilis                         0.119760\nSTDs:vaginal condylomatosis           0.119760\nSTDs:cervical condylomatosis          0.119760\nSTDs:condylomatosis                   0.119760\nSTDs (number)                         0.119760\nSTDs                                  0.119760\ndtype: float64\n\nNumeric features found (used): ['Age', 'Number of sexual partners', 'First sexual intercourse', 'Num of pregnancies', 'Smokes', 'Smokes (years)', 'Smokes (packs/year)', 'Hormonal Contraceptives', 'Hormonal Contraceptives (years)', 'IUD', 'IUD (years)', 'STDs', 'STDs (number)', 'STDs:condylomatosis', 'STDs:cervical condylomatosis', 'STDs:vaginal condylomatosis', 'STDs:vulvo-perineal condylomatosis', 'STDs:syphilis', 'STDs:pelvic inflammatory disease', 'STDs:genital herpes', 'STDs:molluscum contagiosum', 'STDs:AIDS', 'STDs:HIV', 'STDs:Hepatitis B', 'STDs:HPV', 'STDs: Number of diagnosis', 'STDs: Time since first diagnosis', 'STDs: Time since last diagnosis', 'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Dx', 'Schiller', 'Citology', 'Biopsy']\nUsing user-specified columns subset present in dataset: ['Age', 'Number of sexual partners', 'First sexual intercourse', 'Num of pregnancies', 'Smokes', 'Smokes (years)', 'Smokes (packs/year)', 'Hormonal Contraceptives', 'Hormonal Contraceptives (years)', 'IUD']\n\nTrain shape: (668, 35) Test shape: (167, 35)\n\nClassical models evaluation on test set:\nlogistic: AUC=0.7955, AP=0.3287, Acc=0.9281\nrandom_forest: AUC=0.9616, AP=0.4187, Acc=0.9461\nxgboost: AUC=0.9402, AP=0.3321, Acc=0.9162\n\nClass weights for CNN: {0: 0.521875, 1: 11.928571428571429}\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 35, 1)]           0         \n                                                                 \n conv1d (Conv1D)             (None, 35, 64)            256       \n                                                                 \n batch_normalization (BatchN  (None, 35, 64)           256       \n ormalization)                                                   \n                                                                 \n conv1d_1 (Conv1D)           (None, 35, 128)           24704     \n                                                                 \n batch_normalization_1 (Batc  (None, 35, 128)          512       \n hNormalization)                                                 \n                                                                 \n global_average_pooling1d (G  (None, 128)              0         \n lobalAveragePooling1D)                                          \n                                                                 \n dense (Dense)               (None, 64)                8256      \n                                                                 \n dropout (Dropout)           (None, 64)                0         \n                                                                 \n dense_1 (Dense)             (None, 1)                 65        \n                                                                 \n=================================================================\nTotal params: 34,049\nTrainable params: 33,665\nNon-trainable params: 384\n_________________________________________________________________\nEpoch 1/200\n40/40 - 3s - loss: 0.4301 - auc: 0.8968 - val_loss: 0.8849 - val_auc: 0.6674 - lr: 0.0010 - 3s/epoch - 69ms/step\nEpoch 2/200\n40/40 - 0s - loss: 0.2628 - auc: 0.9663 - val_loss: 1.7223 - val_auc: 0.6000 - lr: 0.0010 - 355ms/epoch - 9ms/step\nEpoch 3/200\n40/40 - 0s - loss: 0.1724 - auc: 0.9855 - val_loss: 2.6973 - val_auc: 0.5152 - lr: 0.0010 - 359ms/epoch - 9ms/step\nEpoch 4/200\n40/40 - 0s - loss: 0.1478 - auc: 0.9857 - val_loss: 3.3683 - val_auc: 0.5134 - lr: 0.0010 - 357ms/epoch - 9ms/step\nEpoch 5/200\n40/40 - 0s - loss: 0.1291 - auc: 0.9896 - val_loss: 3.0469 - val_auc: 0.8156 - lr: 0.0010 - 355ms/epoch - 9ms/step\nEpoch 6/200\n40/40 - 0s - loss: 0.1330 - auc: 0.9855 - val_loss: 3.1041 - val_auc: 0.7772 - lr: 0.0010 - 357ms/epoch - 9ms/step\nEpoch 7/200\n40/40 - 0s - loss: 0.1006 - auc: 0.9928 - val_loss: 2.9214 - val_auc: 0.6071 - lr: 0.0010 - 363ms/epoch - 9ms/step\nEpoch 8/200\n40/40 - 0s - loss: 0.0899 - auc: 0.9930 - val_loss: 1.9707 - val_auc: 0.8192 - lr: 5.0000e-04 - 357ms/epoch - 9ms/step\nEpoch 9/200\n40/40 - 0s - loss: 0.0769 - auc: 0.9945 - val_loss: 1.2738 - val_auc: 0.8268 - lr: 5.0000e-04 - 351ms/epoch - 9ms/step\nEpoch 10/200\n40/40 - 0s - loss: 0.0790 - auc: 0.9952 - val_loss: 1.8792 - val_auc: 0.7424 - lr: 5.0000e-04 - 357ms/epoch - 9ms/step\nEpoch 11/200\n40/40 - 0s - loss: 0.0834 - auc: 0.9935 - val_loss: 0.7248 - val_auc: 0.8446 - lr: 5.0000e-04 - 362ms/epoch - 9ms/step\nEpoch 12/200\n40/40 - 0s - loss: 0.0711 - auc: 0.9949 - val_loss: 0.5879 - val_auc: 0.8598 - lr: 5.0000e-04 - 363ms/epoch - 9ms/step\nEpoch 13/200\n40/40 - 0s - loss: 0.0588 - auc: 0.9972 - val_loss: 0.3952 - val_auc: 0.9134 - lr: 5.0000e-04 - 358ms/epoch - 9ms/step\nEpoch 14/200\n40/40 - 0s - loss: 0.0696 - auc: 0.9960 - val_loss: 0.2666 - val_auc: 0.9299 - lr: 5.0000e-04 - 360ms/epoch - 9ms/step\nEpoch 15/200\n40/40 - 0s - loss: 0.0585 - auc: 0.9975 - val_loss: 0.2961 - val_auc: 0.8906 - lr: 5.0000e-04 - 354ms/epoch - 9ms/step\nEpoch 16/200\n40/40 - 0s - loss: 0.0667 - auc: 0.9970 - val_loss: 0.2415 - val_auc: 0.8656 - lr: 5.0000e-04 - 354ms/epoch - 9ms/step\nEpoch 17/200\n40/40 - 0s - loss: 0.0610 - auc: 0.9961 - val_loss: 0.1496 - val_auc: 0.9545 - lr: 5.0000e-04 - 367ms/epoch - 9ms/step\nEpoch 18/200\n40/40 - 0s - loss: 0.0572 - auc: 0.9971 - val_loss: 0.1903 - val_auc: 0.8652 - lr: 5.0000e-04 - 365ms/epoch - 9ms/step\nEpoch 19/200\n40/40 - 0s - loss: 0.0635 - auc: 0.9976 - val_loss: 0.2565 - val_auc: 0.8192 - lr: 5.0000e-04 - 367ms/epoch - 9ms/step\nEpoch 20/200\n40/40 - 0s - loss: 0.0543 - auc: 0.9982 - val_loss: 0.2394 - val_auc: 0.8799 - lr: 5.0000e-04 - 395ms/epoch - 10ms/step\nEpoch 21/200\n40/40 - 0s - loss: 0.0585 - auc: 0.9972 - val_loss: 0.1723 - val_auc: 0.9415 - lr: 5.0000e-04 - 364ms/epoch - 9ms/step\nEpoch 22/200\n40/40 - 0s - loss: 0.0402 - auc: 0.9989 - val_loss: 0.1980 - val_auc: 0.8938 - lr: 5.0000e-04 - 497ms/epoch - 12ms/step\nEpoch 23/200\n40/40 - 0s - loss: 0.0464 - auc: 0.9986 - val_loss: 0.2728 - val_auc: 0.7978 - lr: 5.0000e-04 - 423ms/epoch - 11ms/step\nEpoch 24/200\n40/40 - 0s - loss: 0.0405 - auc: 0.9990 - val_loss: 0.2065 - val_auc: 0.8830 - lr: 2.5000e-04 - 379ms/epoch - 9ms/step\nEpoch 25/200\n40/40 - 0s - loss: 0.0352 - auc: 0.9993 - val_loss: 0.3021 - val_auc: 0.7902 - lr: 2.5000e-04 - 377ms/epoch - 9ms/step\nEpoch 26/200\n40/40 - 0s - loss: 0.0437 - auc: 0.9990 - val_loss: 0.2451 - val_auc: 0.8388 - lr: 2.5000e-04 - 374ms/epoch - 9ms/step\nEpoch 27/200\n40/40 - 0s - loss: 0.0327 - auc: 0.9996 - val_loss: 0.1795 - val_auc: 0.9357 - lr: 2.5000e-04 - 364ms/epoch - 9ms/step\nEpoch 28/200\n40/40 - 0s - loss: 0.0315 - auc: 0.9992 - val_loss: 0.2345 - val_auc: 0.8219 - lr: 2.5000e-04 - 365ms/epoch - 9ms/step\nEpoch 29/200\n40/40 - 0s - loss: 0.0326 - auc: 0.9985 - val_loss: 0.2047 - val_auc: 0.9049 - lr: 2.5000e-04 - 363ms/epoch - 9ms/step\nEpoch 30/200\n40/40 - 0s - loss: 0.0331 - auc: 0.9990 - val_loss: 0.2072 - val_auc: 0.9013 - lr: 1.2500e-04 - 360ms/epoch - 9ms/step\nEpoch 31/200\n40/40 - 0s - loss: 0.0339 - auc: 0.9988 - val_loss: 0.2057 - val_auc: 0.8482 - lr: 1.2500e-04 - 359ms/epoch - 9ms/step\nEpoch 32/200\n40/40 - 0s - loss: 0.0313 - auc: 0.9996 - val_loss: 0.1934 - val_auc: 0.9214 - lr: 1.2500e-04 - 370ms/epoch - 9ms/step\n6/6 [==============================] - 0s 3ms/step\n\nCNN: AUC=0.9545, AP=0.3829\n","output_type":"stream"},{"name":"stderr","text":"The figure layout has changed to tight\n","output_type":"stream"},{"name":"stdout","text":"Fold 1 AUC: 0.9062\nFold 2 AUC: 0.9643\nFold 3 AUC: 0.9839\nFold 4 AUC: 0.9589\nFold 5 AUC: 0.9732\nCV AUC mean 0.9573 +/- 0.0269\n\nAll models and artifacts saved to /kaggle/working/models and images saved to /kaggle/working\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x950 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Installation Requirements\n!pip install tensorflow keras scikit-learn pandas numpy matplotlib seaborn\n!pip install imbalanced-learn tensorflow-addons scikit-plot\n!pip install sdv\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.regularizers import l1_l2\nimport tensorflow_addons as tfa\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nprint(f\"TensorFlow version: {tf.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:10:38.749292Z","iopub.execute_input":"2025-09-26T04:10:38.749914Z","iopub.status.idle":"2025-09-26T04:12:26.442921Z","shell.execute_reply.started":"2025-09-26T04:10:38.749883Z","shell.execute_reply":"2025-09-26T04:12:26.441579Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.12.0)\nRequirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (2.12.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.3.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.23.5)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\nRequirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.30)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.2)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow) (0.4.30)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow) (0.4.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.40.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.8.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.32.4)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.1.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (2.0.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (3.0.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.3.1)\nRequirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.11.0)\nCollecting tensorflow-addons\n  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: scikit-plot in /usr/local/lib/python3.11/dist-packages (0.3.7)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.23.5)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.3.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (25.0)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from scikit-plot) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.17.0)\nDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nInstalling collected packages: typeguard, tensorflow-addons\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.4.4\n    Uninstalling typeguard-4.4.4:\n      Successfully uninstalled typeguard-4.4.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.16.1 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\ninflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\nCollecting sdv\n  Downloading sdv-1.27.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: boto3<2.0.0,>=1.28 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.39.1)\nRequirement already satisfied: botocore<2.0.0,>=1.31 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.39.1)\nRequirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (3.1.1)\nRequirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.21)\nCollecting numpy>=1.24.0 (from sdv)\n  Downloading numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.2.3)\nRequirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.67.1)\nCollecting copulas>=0.12.1 (from sdv)\n  Downloading copulas-0.12.3-py3-none-any.whl.metadata (9.5 kB)\nCollecting ctgan>=0.11.0 (from sdv)\n  Downloading ctgan-0.11.0-py3-none-any.whl.metadata (10 kB)\nCollecting deepecho>=0.7.0 (from sdv)\n  Downloading deepecho-0.7.0-py3-none-any.whl.metadata (10 kB)\nCollecting rdt>=1.17.0 (from sdv)\n  Downloading rdt-1.18.1-py3-none-any.whl.metadata (10 kB)\nCollecting sdmetrics>=0.21.0 (from sdv)\n  Downloading sdmetrics-0.23.0-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.3.8)\nRequirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from sdv) (6.0.2)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2.0.0,>=1.28->sdv) (1.0.1)\nRequirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2.0.0,>=1.28->sdv) (0.13.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.9.0.post0)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.5.0)\nRequirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (5.24.1)\nRequirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (1.15.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ctgan>=0.11.0->sdv) (2.6.0+cu124)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\nRequirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.17.0->sdv) (1.3.2)\nCollecting Faker>=17 (from rdt>=1.17.0->sdv)\n  Downloading faker-37.8.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (8.5.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (25.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.31->sdv) (1.17.0)\nCollecting numpy>=1.24.0 (from sdv)\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.17.0->sdv) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.17.0->sdv) (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->ctgan>=0.11.0->sdv) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->ctgan>=0.11.0->sdv) (3.0.2)\nDownloading sdv-1.27.0-py3-none-any.whl (186 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading copulas-0.12.3-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ctgan-0.11.0-py3-none-any.whl (24 kB)\nDownloading deepecho-0.7.0-py3-none-any.whl (27 kB)\nDownloading rdt-1.18.1-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sdmetrics-0.23.0-py3-none-any.whl (198 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.4/198.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faker-37.8.0-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, Faker, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, copulas, sdmetrics, rdt, deepecho, ctgan, sdv\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Uninstalling numpy-1.23.5:\n      Successfully uninstalled numpy-1.23.5\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ntensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.4 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nydata-profiling 4.16.1 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\norbax-checkpoint 0.11.16 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\nflax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Faker-37.8.0 copulas-0.12.3 ctgan-0.11.0 deepecho-0.7.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdt-1.18.1 sdmetrics-0.23.0 sdv-1.27.0\nTensorFlow version: 2.12.0\n","output_type":"stream"},{"name":"stderr","text":"\n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\nTensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Uninstall incompatible TensorFlow and Addons\n!pip uninstall -y tensorflow keras tensorflow-addons\n\n# Install compatible versions\n!pip install tensorflow==2.13.0 keras==2.13.1 tensorflow-addons==0.22.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:12:26.444155Z","iopub.execute_input":"2025-09-26T04:12:26.444462Z","iopub.status.idle":"2025-09-26T04:13:28.124857Z","shell.execute_reply.started":"2025-09-26T04:12:26.444434Z","shell.execute_reply":"2025-09-26T04:13:28.123589Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.12.0\nUninstalling tensorflow-2.12.0:\n  Successfully uninstalled tensorflow-2.12.0\nFound existing installation: keras 2.12.0\nUninstalling keras-2.12.0:\n  Successfully uninstalled keras-2.12.0\nFound existing installation: tensorflow-addons 0.23.0\nUninstalling tensorflow-addons-0.23.0:\n  Successfully uninstalled tensorflow-addons-0.23.0\nCollecting tensorflow==2.13.0\n  Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting keras==2.13.1\n  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting tensorflow-addons==0.22.0\n  Downloading tensorflow_addons-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (25.2.10)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.73.1)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.14.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (18.1.1)\nCollecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.0)\n  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.17.0)\nCollecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.1.0)\nCollecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.14.2)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (0.37.1)\nRequirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons==0.22.0) (2.13.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.45.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.40.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.8.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.4)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.1.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.1)\nDownloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.2/524.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_addons-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nInstalling collected packages: typing-extensions, tensorflow-estimator, tensorflow-addons, numpy, keras, tensorboard, tensorflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.14.0\n    Uninstalling typing_extensions-4.14.0:\n      Successfully uninstalled typing_extensions-4.14.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.12.0\n    Uninstalling tensorflow-estimator-2.12.0:\n      Successfully uninstalled tensorflow-estimator-2.12.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.12.3\n    Uninstalling tensorboard-2.12.3:\n      Successfully uninstalled tensorboard-2.12.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\npydantic-core 2.33.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\npydantic 2.11.7 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\ntyping-inspection 0.4.1 requires typing-extensions>=4.12.0, but you have typing-extensions 4.5.0 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\npyopenssl 25.1.0 requires typing-extensions>=4.9; python_version < \"3.13\" and python_version >= \"3.8\", but you have typing-extensions 4.5.0 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nydata-profiling 4.16.1 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\nbayesian-optimization 3.0.0 requires numpy>=1.25; python_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\ndocstring-to-markdown 0.17 requires typing_extensions>=4.6, but you have typing-extensions 4.5.0 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires typing_extensions>=4.7.1, but you have typing-extensions 4.5.0 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nalembic 1.16.2 requires typing-extensions>=4.12, but you have typing-extensions 4.5.0 which is incompatible.\nplum-dispatch 2.5.7 requires typing-extensions>=4.9.0, but you have typing-extensions 4.5.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.24.3 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\nopenai 1.91.0 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\ngoogle-genai 1.21.1 requires typing-extensions<5.0.0,>=4.11.0, but you have typing-extensions 4.5.0 which is incompatible.\ntreescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\norbax-checkpoint 0.11.16 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\ntorch 2.6.0+cu124 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\noptree 0.16.0 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\nfastapi 0.115.13 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\nalbumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\npymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nblosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\nnibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.13.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.13.0 which is incompatible.\nwandb 0.20.1 requires typing-extensions<5,>=4.8, but you have typing-extensions 4.5.0 which is incompatible.\nxarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\nlangchain-core 0.3.66 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.13.0 which is incompatible.\nflax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nalbucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\naltair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nsqlalchemy 2.0.41 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-addons-0.22.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Load the specific dataset from Kaggle\ndf = pd.read_csv('/kaggle/input/cervical-cancer-dataset/cervical-cancer_csv.csv')\n\n# Display basic information\nprint(\"Dataset Shape:\", df.shape)\nprint(\"\\nDataset Columns:\")\nprint(df.columns.tolist())\nprint(\"\\nFirst 5 rows:\")\nprint(df.head())\nprint(\"\\nDataset Info:\")\nprint(df.info())\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())\n\n# Check for target variable - since it's not mentioned, we need to identify it\n# Common target variables in cervical cancer datasets are 'Biopsy', 'Dx:Cancer', or similar\n# Let's check what columns might be the target\npossible_targets = [col for col in df.columns if 'cancer' in col.lower() or 'biopsy' in col.lower() or 'dx' in col.lower()]\nprint(f\"\\nPossible target variables: {possible_targets}\")\n\n# If no obvious target, let's check the last column or ask for clarification\n# For now, I'll assume the target is 'Biopsy' (common in cervical cancer datasets)\n# If this is incorrect, please specify the actual target column name\n\n# Check if 'Biopsy' exists\nif 'Biopsy' in df.columns:\n    target_column = 'Biopsy'\n    print(f\"\\nUsing 'Biopsy' as target column\")\nelif 'Dx:Cancer' in df.columns:\n    target_column = 'Dx:Cancer'\n    print(f\"\\nUsing 'Dx:Cancer' as target column\")\nelse:\n    # If no standard target found, use the last column as target (common practice)\n    target_column = df.columns[-1]\n    print(f\"\\nUsing last column '{target_column}' as target column\")\n\nprint(f\"\\nTarget column: {target_column}\")\nprint(f\"Target distribution:\")\nprint(df[target_column].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:13:28.126330Z","iopub.execute_input":"2025-09-26T04:13:28.126709Z","iopub.status.idle":"2025-09-26T04:13:28.182809Z","shell.execute_reply.started":"2025-09-26T04:13:28.126657Z","shell.execute_reply":"2025-09-26T04:13:28.181933Z"}},"outputs":[{"name":"stdout","text":"Dataset Shape: (835, 36)\n\nDataset Columns:\n['Age', 'Number of sexual partners', 'First sexual intercourse', 'Num of pregnancies', 'Smokes', 'Smokes (years)', 'Smokes (packs/year)', 'Hormonal Contraceptives', 'Hormonal Contraceptives (years)', 'IUD', 'IUD (years)', 'STDs', 'STDs (number)', 'STDs:condylomatosis', 'STDs:cervical condylomatosis', 'STDs:vaginal condylomatosis', 'STDs:vulvo-perineal condylomatosis', 'STDs:syphilis', 'STDs:pelvic inflammatory disease', 'STDs:genital herpes', 'STDs:molluscum contagiosum', 'STDs:AIDS', 'STDs:HIV', 'STDs:Hepatitis B', 'STDs:HPV', 'STDs: Number of diagnosis', 'STDs: Time since first diagnosis', 'STDs: Time since last diagnosis', 'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Dx', 'Hinselmann', 'Schiller', 'Citology', 'Biopsy']\n\nFirst 5 rows:\n   Age  Number of sexual partners  First sexual intercourse  \\\n0   18                        4.0                      15.0   \n1   15                        1.0                      14.0   \n2   34                        1.0                       NaN   \n3   52                        5.0                      16.0   \n4   46                        3.0                      21.0   \n\n   Num of pregnancies  Smokes  Smokes (years)  Smokes (packs/year)  \\\n0                 1.0     0.0             0.0                  0.0   \n1                 1.0     0.0             0.0                  0.0   \n2                 1.0     0.0             0.0                  0.0   \n3                 4.0     1.0            37.0                 37.0   \n4                 4.0     0.0             0.0                  0.0   \n\n   Hormonal Contraceptives  Hormonal Contraceptives (years)  IUD  ...  \\\n0                      0.0                              0.0  0.0  ...   \n1                      0.0                              0.0  0.0  ...   \n2                      0.0                              0.0  0.0  ...   \n3                      1.0                              3.0  0.0  ...   \n4                      1.0                             15.0  0.0  ...   \n\n   STDs: Time since first diagnosis  STDs: Time since last diagnosis  \\\n0                               NaN                              NaN   \n1                               NaN                              NaN   \n2                               NaN                              NaN   \n3                               NaN                              NaN   \n4                               NaN                              NaN   \n\n   Dx:Cancer  Dx:CIN  Dx:HPV  Dx  Hinselmann  Schiller  Citology  Biopsy  \n0          0       0       0   0           0         0         0       0  \n1          0       0       0   0           0         0         0       0  \n2          0       0       0   0           0         0         0       0  \n3          1       0       1   0           0         0         0       0  \n4          0       0       0   0           0         0         0       0  \n\n[5 rows x 36 columns]\n\nDataset Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 835 entries, 0 to 834\nData columns (total 36 columns):\n #   Column                              Non-Null Count  Dtype  \n---  ------                              --------------  -----  \n 0   Age                                 835 non-null    int64  \n 1   Number of sexual partners           810 non-null    float64\n 2   First sexual intercourse            828 non-null    float64\n 3   Num of pregnancies                  779 non-null    float64\n 4   Smokes                              822 non-null    float64\n 5   Smokes (years)                      822 non-null    float64\n 6   Smokes (packs/year)                 822 non-null    float64\n 7   Hormonal Contraceptives             732 non-null    float64\n 8   Hormonal Contraceptives (years)     732 non-null    float64\n 9   IUD                                 723 non-null    float64\n 10  IUD (years)                         723 non-null    float64\n 11  STDs                                735 non-null    float64\n 12  STDs (number)                       735 non-null    float64\n 13  STDs:condylomatosis                 735 non-null    float64\n 14  STDs:cervical condylomatosis        735 non-null    float64\n 15  STDs:vaginal condylomatosis         735 non-null    float64\n 16  STDs:vulvo-perineal condylomatosis  735 non-null    float64\n 17  STDs:syphilis                       735 non-null    float64\n 18  STDs:pelvic inflammatory disease    735 non-null    float64\n 19  STDs:genital herpes                 735 non-null    float64\n 20  STDs:molluscum contagiosum          735 non-null    float64\n 21  STDs:AIDS                           735 non-null    float64\n 22  STDs:HIV                            735 non-null    float64\n 23  STDs:Hepatitis B                    735 non-null    float64\n 24  STDs:HPV                            735 non-null    float64\n 25  STDs: Number of diagnosis           835 non-null    int64  \n 26  STDs: Time since first diagnosis    71 non-null     float64\n 27  STDs: Time since last diagnosis     71 non-null     float64\n 28  Dx:Cancer                           835 non-null    int64  \n 29  Dx:CIN                              835 non-null    int64  \n 30  Dx:HPV                              835 non-null    int64  \n 31  Dx                                  835 non-null    int64  \n 32  Hinselmann                          835 non-null    int64  \n 33  Schiller                            835 non-null    int64  \n 34  Citology                            835 non-null    int64  \n 35  Biopsy                              835 non-null    int64  \ndtypes: float64(26), int64(10)\nmemory usage: 235.0 KB\nNone\n\nMissing Values:\nAge                                     0\nNumber of sexual partners              25\nFirst sexual intercourse                7\nNum of pregnancies                     56\nSmokes                                 13\nSmokes (years)                         13\nSmokes (packs/year)                    13\nHormonal Contraceptives               103\nHormonal Contraceptives (years)       103\nIUD                                   112\nIUD (years)                           112\nSTDs                                  100\nSTDs (number)                         100\nSTDs:condylomatosis                   100\nSTDs:cervical condylomatosis          100\nSTDs:vaginal condylomatosis           100\nSTDs:vulvo-perineal condylomatosis    100\nSTDs:syphilis                         100\nSTDs:pelvic inflammatory disease      100\nSTDs:genital herpes                   100\nSTDs:molluscum contagiosum            100\nSTDs:AIDS                             100\nSTDs:HIV                              100\nSTDs:Hepatitis B                      100\nSTDs:HPV                              100\nSTDs: Number of diagnosis               0\nSTDs: Time since first diagnosis      764\nSTDs: Time since last diagnosis       764\nDx:Cancer                               0\nDx:CIN                                  0\nDx:HPV                                  0\nDx                                      0\nHinselmann                              0\nSchiller                                0\nCitology                                0\nBiopsy                                  0\ndtype: int64\n\nPossible target variables: ['Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Dx', 'Biopsy']\n\nUsing 'Biopsy' as target column\n\nTarget column: Biopsy\nTarget distribution:\nBiopsy\n0    781\n1     54\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Separate features and target\nfeature_columns = ['Age', 'Number of sexual partners', 'First sexual intercourse', \n                   'Num of pregnancies', 'Smokes', 'Smokes (years)', \n                   'Smokes (packs/year)', 'Hormonal Contraceptives', \n                   'Hormonal Contraceptives (years)', 'IUD']\n\n# Verify all expected columns are present\nmissing_features = [col for col in feature_columns if col not in df.columns]\nif missing_features:\n    print(f\"Warning: Missing columns: {missing_features}\")\n    # Remove missing columns from feature list\n    feature_columns = [col for col in feature_columns if col in df.columns]\n\nprint(f\"Available feature columns: {feature_columns}\")\n\nX = df[feature_columns].copy()\ny = df[target_column].copy()\n\n# Handle missing values appropriately for your dataset\nprint(\"\\nHandling missing values...\")\n\n# Identify numerical and binary features based on your dataset\nnumerical_features = ['Age', 'Number of sexual partners', 'First sexual intercourse', \n                     'Num of pregnancies', 'Smokes (years)', 'Smokes (packs/year)', \n                     'Hormonal Contraceptives (years)']\n\nbinary_features = ['Smokes', 'Hormonal Contraceptives', 'IUD']\n\n# Filter to only include available columns\nnumerical_features = [col for col in numerical_features if col in X.columns]\nbinary_features = [col for col in binary_features if col in X.columns]\n\nprint(f\"Numerical features: {numerical_features}\")\nprint(f\"Binary features: {binary_features}\")\n\n# Imputation strategy\n# For numerical features: KNN imputation\nif numerical_features:\n    knn_imputer = KNNImputer(n_neighbors=3)  # Using 3 neighbors for small dataset\n    X_numerical_imputed = knn_imputer.fit_transform(X[numerical_features])\n    X_numerical_imputed = pd.DataFrame(X_numerical_imputed, columns=numerical_features, index=X.index)\nelse:\n    X_numerical_imputed = pd.DataFrame(index=X.index)\n\n# For binary features: mode imputation\nif binary_features:\n    mode_imputer = SimpleImputer(strategy='most_frequent')\n    X_binary_imputed = mode_imputer.fit_transform(X[binary_features])\n    X_binary_imputed = pd.DataFrame(X_binary_imputed, columns=binary_features, index=X.index)\nelse:\n    X_binary_imputed = pd.DataFrame(index=X.index)\n\n# Combine imputed features\nX_imputed = pd.concat([X_numerical_imputed, X_binary_imputed], axis=1)\n\n# Ensure proper data types for binary features\nfor col in binary_features:\n    X_imputed[col] = X_imputed[col].astype(int)\n\n# Handle any remaining missing values\nX_final = X_imputed.fillna(0)\ny_final = y.fillna(0).astype(int)\n\nprint(f\"\\nFinal dataset shape: {X_final.shape}\")\nprint(f\"Final target distribution: {y_final.value_counts().to_dict()}\")\nprint(f\"Class distribution: {dict(y_final.value_counts(normalize=True))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:13:28.183729Z","iopub.execute_input":"2025-09-26T04:13:28.184019Z","iopub.status.idle":"2025-09-26T04:13:28.243797Z","shell.execute_reply.started":"2025-09-26T04:13:28.183997Z","shell.execute_reply":"2025-09-26T04:13:28.242826Z"}},"outputs":[{"name":"stdout","text":"Available feature columns: ['Age', 'Number of sexual partners', 'First sexual intercourse', 'Num of pregnancies', 'Smokes', 'Smokes (years)', 'Smokes (packs/year)', 'Hormonal Contraceptives', 'Hormonal Contraceptives (years)', 'IUD']\n\nHandling missing values...\nNumerical features: ['Age', 'Number of sexual partners', 'First sexual intercourse', 'Num of pregnancies', 'Smokes (years)', 'Smokes (packs/year)', 'Hormonal Contraceptives (years)']\nBinary features: ['Smokes', 'Hormonal Contraceptives', 'IUD']\n\nFinal dataset shape: (835, 10)\nFinal target distribution: {0: 781, 1: 54}\nClass distribution: {0: 0.9353293413173652, 1: 0.06467065868263473}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Create advanced features specifically for your cervical cancer dataset\nX_engineered = X_final.copy()\n\n# 1. Age-related features\nX_engineered['Age_squared'] = X_engineered['Age'] ** 2\nX_engineered['Age_cubed'] = X_engineered['Age'] ** 3\n\n# 2. Sexual behavior features\nif 'Number of sexual partners' in X_engineered.columns and 'First sexual intercourse' in X_engineered.columns:\n    X_engineered['Years_since_first_intercourse'] = X_engineered['Age'] - X_engineered['First sexual intercourse']\n    X_engineered['Partners_per_year'] = X_engineered['Number of sexual partners'] / (X_engineered['Years_since_first_intercourse'] + 1)\n    X_engineered['Partners_per_year'] = X_engineered['Partners_per_year'].replace([np.inf, -np.inf], 0)\n\n# 3. Smoking intensity features\nif 'Smokes (years)' in X_engineered.columns and 'Smokes (packs/year)' in X_engineered.columns:\n    X_engineered['Total_packs_smoked'] = X_engineered['Smokes (years)'] * X_engineered['Smokes (packs/year)']\n\n# 4. Contraceptive usage features\ncontraceptive_features = []\nif 'Hormonal Contraceptives (years)' in X_engineered.columns:\n    contraceptive_features.append('Hormonal Contraceptives (years)')\nif 'IUD' in X_engineered.columns:\n    # Create IUD years feature if not present (assume 5 years if using IUD)\n    X_engineered['IUD_years'] = X_engineered['IUD'] * 5\n    contraceptive_features.append('IUD_years')\n\nif contraceptive_features:\n    X_engineered['Total_contraceptive_years'] = X_engineered[contraceptive_features].sum(axis=1)\n\n# 5. Risk factor combinations\nif 'Smokes' in X_engineered.columns and 'Hormonal Contraceptives' in X_engineered.columns:\n    X_engineered['Smoking_contraceptive_risk'] = X_engineered['Smokes'] * X_engineered['Hormonal Contraceptives']\n\n# 6. Age groups (clinically relevant)\nX_engineered['Age_group'] = pd.cut(X_engineered['Age'], \n                                  bins=[0, 25, 35, 45, 100], \n                                  labels=[0, 1, 2, 3])\nX_engineered['Age_group'] = X_engineered['Age_group'].astype(int)\n\n# 7. High-risk pregnancy indicator\nif 'Num of pregnancies' in X_engineered.columns:\n    X_engineered['High_risk_pregnancy'] = (X_engineered['Num of pregnancies'] > 3).astype(int)\n\n# Handle any infinite or NaN values\nX_engineered = X_engineered.replace([np.inf, -np.inf], 0)\nX_engineered = X_engineered.fillna(0)\n\nprint(f\"Engineered dataset shape: {X_engineered.shape}\")\nprint(\"New features created:\", [col for col in X_engineered.columns if col not in feature_columns])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:13:28.244931Z","iopub.execute_input":"2025-09-26T04:13:28.245521Z","iopub.status.idle":"2025-09-26T04:13:28.277830Z","shell.execute_reply.started":"2025-09-26T04:13:28.245487Z","shell.execute_reply":"2025-09-26T04:13:28.276770Z"}},"outputs":[{"name":"stdout","text":"Engineered dataset shape: (835, 20)\nNew features created: ['Age_squared', 'Age_cubed', 'Years_since_first_intercourse', 'Partners_per_year', 'Total_packs_smoked', 'IUD_years', 'Total_contraceptive_years', 'Smoking_contraceptive_risk', 'Age_group', 'High_risk_pregnancy']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Create advanced features specifically for your cervical cancer dataset\nX_engineered = X_final.copy()\n\n# 1. Age-related features\nX_engineered['Age_squared'] = X_engineered['Age'] ** 2\nX_engineered['Age_cubed'] = X_engineered['Age'] ** 3\n\n# 2. Sexual behavior features\nif 'Number of sexual partners' in X_engineered.columns and 'First sexual intercourse' in X_engineered.columns:\n    X_engineered['Years_since_first_intercourse'] = X_engineered['Age'] - X_engineered['First sexual intercourse']\n    X_engineered['Partners_per_year'] = X_engineered['Number of sexual partners'] / (X_engineered['Years_since_first_intercourse'] + 1)\n    X_engineered['Partners_per_year'] = X_engineered['Partners_per_year'].replace([np.inf, -np.inf], 0)\n\n# 3. Smoking intensity features\nif 'Smokes (years)' in X_engineered.columns and 'Smokes (packs/year)' in X_engineered.columns:\n    X_engineered['Total_packs_smoked'] = X_engineered['Smokes (years)'] * X_engineered['Smokes (packs/year)']\n\n# 4. Contraceptive usage features\ncontraceptive_features = []\nif 'Hormonal Contraceptives (years)' in X_engineered.columns:\n    contraceptive_features.append('Hormonal Contraceptives (years)')\nif 'IUD' in X_engineered.columns:\n    # Create IUD years feature if not present (assume 5 years if using IUD)\n    X_engineered['IUD_years'] = X_engineered['IUD'] * 5\n    contraceptive_features.append('IUD_years')\n\nif contraceptive_features:\n    X_engineered['Total_contraceptive_years'] = X_engineered[contraceptive_features].sum(axis=1)\n\n# 5. Risk factor combinations\nif 'Smokes' in X_engineered.columns and 'Hormonal Contraceptives' in X_engineered.columns:\n    X_engineered['Smoking_contraceptive_risk'] = X_engineered['Smokes'] * X_engineered['Hormonal Contraceptives']\n\n# 6. Age groups (clinically relevant)\nX_engineered['Age_group'] = pd.cut(X_engineered['Age'], \n                                  bins=[0, 25, 35, 45, 100], \n                                  labels=[0, 1, 2, 3])\nX_engineered['Age_group'] = X_engineered['Age_group'].astype(int)\n\n# 7. High-risk pregnancy indicator\nif 'Num of pregnancies' in X_engineered.columns:\n    X_engineered['High_risk_pregnancy'] = (X_engineered['Num of pregnancies'] > 3).astype(int)\n\n# Handle any infinite or NaN values\nX_engineered = X_engineered.replace([np.inf, -np.inf], 0)\nX_engineered = X_engineered.fillna(0)\n\nprint(f\"Engineered dataset shape: {X_engineered.shape}\")\nprint(\"New features created:\", [col for col in X_engineered.columns if col not in feature_columns])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:13:28.278968Z","iopub.execute_input":"2025-09-26T04:13:28.279313Z","iopub.status.idle":"2025-09-26T04:13:28.309909Z","shell.execute_reply.started":"2025-09-26T04:13:28.279273Z","shell.execute_reply":"2025-09-26T04:13:28.308542Z"}},"outputs":[{"name":"stdout","text":"Engineered dataset shape: (835, 20)\nNew features created: ['Age_squared', 'Age_cubed', 'Years_since_first_intercourse', 'Partners_per_year', 'Total_packs_smoked', 'IUD_years', 'Total_contraceptive_years', 'Smoking_contraceptive_risk', 'Age_group', 'High_risk_pregnancy']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"class CustomCervicalCancerDNN(Model):\n    \"\"\"\n    Custom Deep Neural Network specifically designed for cervical cancer prediction\n    with your dataset structure\n    \"\"\"\n    def __init__(self, input_dim, hidden_layers=[128, 64, 32], dropout_rate=0.3):\n        super(CustomCervicalCancerDNN, self).__init__()\n        \n        # Input layer with batch normalization\n        self.input_layer = Dense(input_dim, activation='relu')\n        self.input_bn = BatchNormalization()\n        self.input_dropout = Dropout(dropout_rate)\n        \n        # Hidden layers\n        self.hidden_layers = []\n        self.batch_norms = []\n        self.dropouts = []\n        \n        for units in hidden_layers:\n            self.hidden_layers.append(Dense(units, activation='relu', \n                                          kernel_regularizer=l1_l2(l1=0.001, l2=0.001)))\n            self.batch_norms.append(BatchNormalization())\n            self.dropouts.append(Dropout(dropout_rate))\n        \n        # Output layer\n        self.output_layer = Dense(1, activation='sigmoid')\n    \n    def call(self, inputs, training=None):\n        x = self.input_layer(inputs)\n        x = self.input_bn(x, training=training)\n        x = self.input_dropout(x, training=training)\n        \n        for hidden_layer, batch_norm, dropout in zip(self.hidden_layers, \n                                                    self.batch_norms, \n                                                    self.dropouts):\n            x = hidden_layer(x)\n            x = batch_norm(x, training=training)\n            x = dropout(x, training=training)\n        \n        return self.output_layer(x)\n\nclass CustomCervicalCancerCNN(Model):\n    \"\"\"\n    Custom CNN treating tabular data as 1D sequences for cervical cancer prediction\n    \"\"\"\n    def __init__(self, input_dim):\n        super(CustomCervicalCancerCNN, self).__init__()\n        \n        # Reshape for 1D convolution\n        self.reshape = layers.Reshape((input_dim, 1))\n        \n        # Convolutional layers\n        self.conv1 = layers.Conv1D(32, 3, activation='relu', padding='same')\n        self.bn1 = BatchNormalization()\n        self.pool1 = layers.MaxPooling1D(2, padding='same')\n        self.dropout1 = Dropout(0.2)\n        \n        self.conv2 = layers.Conv1D(64, 3, activation='relu', padding='same')\n        self.bn2 = BatchNormalization()\n        self.pool2 = layers.MaxPooling1D(2, padding='same')\n        self.dropout2 = Dropout(0.3)\n        \n        # Global pooling\n        self.global_pool = layers.GlobalAveragePooling1D()\n        \n        # Dense layers\n        self.dense1 = Dense(64, activation='relu')\n        self.bn3 = BatchNormalization()\n        self.dropout3 = Dropout(0.4)\n        \n        self.dense2 = Dense(32, activation='relu')\n        self.bn4 = BatchNormalization()\n        self.dropout4 = Dropout(0.4)\n        \n        self.output_layer = Dense(1, activation='sigmoid')\n    \n    def call(self, inputs, training=None):\n        x = self.reshape(inputs)\n        x = self.conv1(x)\n        x = self.bn1(x, training=training)\n        x = self.pool1(x)\n        x = self.dropout1(x, training=training)\n        \n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = self.pool2(x)\n        x = self.dropout2(x, training=training)\n        \n        x = self.global_pool(x)\n        x = self.dense1(x)\n        x = self.bn3(x, training=training)\n        x = self.dropout3(x, training=training)\n        \n        x = self.dense2(x)\n        x = self.bn4(x, training=training)\n        x = self.dropout4(x, training=training)\n        \n        return self.output_layer(x)\n\nclass HybridCervicalCancerModel(Model):\n    \"\"\"\n    Hybrid model combining DNN and CNN approaches for maximum performance\n    \"\"\"\n    def __init__(self, input_dim):\n        super(HybridCervicalCancerModel, self).__init__()\n        \n        # CNN Branch\n        self.cnn_reshape = layers.Reshape((input_dim, 1))\n        self.cnn_conv1 = layers.Conv1D(32, 3, activation='relu', padding='same')\n        self.cnn_bn1 = BatchNormalization()\n        self.cnn_pool1 = layers.MaxPooling1D(2, padding='same')\n        self.cnn_dropout1 = Dropout(0.2)\n        \n        self.cnn_conv2 = layers.Conv1D(64, 3, activation='relu', padding='same')\n        self.cnn_bn2 = BatchNormalization()\n        self.cnn_pool2 = layers.MaxPooling1D(2, padding='same')\n        self.cnn_dropout2 = Dropout(0.3)\n        \n        self.cnn_global_pool = layers.GlobalAveragePooling1D()\n        \n        # DNN Branch\n        self.dnn_dense1 = Dense(64, activation='relu')\n        self.dnn_bn1 = BatchNormalization()\n        self.dnn_dropout1 = Dropout(0.3)\n        \n        self.dnn_dense2 = Dense(32, activation='relu')\n        self.dnn_bn2 = BatchNormalization()\n        self.dnn_dropout2 = Dropout(0.3)\n        \n        # Combined layers\n        self.combined_dense1 = Dense(64, activation='relu')\n        self.combined_bn1 = BatchNormalization()\n        self.combined_dropout1 = Dropout(0.4)\n        \n        self.combined_dense2 = Dense(32, activation='relu')\n        self.combined_bn2 = BatchNormalization()\n        self.combined_dropout2 = Dropout(0.4)\n        \n        self.output_layer = Dense(1, activation='sigmoid')\n    \n    def call(self, inputs, training=None):\n        # CNN Branch\n        cnn_x = self.cnn_reshape(inputs)\n        cnn_x = self.cnn_conv1(cnn_x)\n        cnn_x = self.cnn_bn1(cnn_x, training=training)\n        cnn_x = self.cnn_pool1(cnn_x)\n        cnn_x = self.cnn_dropout1(cnn_x, training=training)\n        \n        cnn_x = self.cnn_conv2(cnn_x)\n        cnn_x = self.cnn_bn2(cnn_x, training=training)\n        cnn_x = self.cnn_pool2(cnn_x)\n        cnn_x = self.cnn_dropout2(cnn_x, training=training)\n        \n        cnn_x = self.cnn_global_pool(cnn_x)\n        \n        # DNN Branch\n        dnn_x = self.dnn_dense1(inputs)\n        dnn_x = self.dnn_bn1(dnn_x, training=training)\n        dnn_x = self.dnn_dropout1(dnn_x, training=training)\n        \n        dnn_x = self.dnn_dense2(dnn_x)\n        dnn_x = self.dnn_bn2(dnn_x, training=training)\n        dnn_x = self.dnn_dropout2(dnn_x, training=training)\n        \n        # Combine\n        combined_x = tf.concat([cnn_x, dnn_x], axis=1)\n        combined_x = self.combined_dense1(combined_x)\n        combined_x = self.combined_bn1(combined_x, training=training)\n        combined_x = self.combined_dropout1(combined_x, training=training)\n        \n        combined_x = self.combined_dense2(combined_x)\n        combined_x = self.combined_bn2(combined_x, training=training)\n        combined_x = self.combined_dropout2(combined_x, training=training)\n        \n        return self.output_layer(combined_x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:13:28.310948Z","iopub.execute_input":"2025-09-26T04:13:28.311209Z","iopub.status.idle":"2025-09-26T04:13:28.334643Z","shell.execute_reply.started":"2025-09-26T04:13:28.311190Z","shell.execute_reply":"2025-09-26T04:13:28.333690Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Prepare data for deep learning\nX_dl = X_engineered.values\ny_dl = y_final.values\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_dl)\n\n# Since you only have training data, we'll use stratified k-fold cross-validation\n# But first, let's create a holdout set for final evaluation\nX_train, X_holdout, y_train, y_holdout = train_test_split(\n    X_scaled, y_dl, test_size=0.2, random_state=42, stratify=y_dl\n)\n\nprint(f\"Training set: {X_train.shape}\")\nprint(f\"Holdout set: {X_holdout.shape}\")\nprint(f\"Training class distribution: {np.bincount(y_train)}\")\nprint(f\"Holdout class distribution: {np.bincount(y_holdout)}\")\n\n# Handle class imbalance with SMOTE on training data only\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\nprint(f\"Balanced training set: {X_train_balanced.shape}\")\nprint(f\"Balanced training class distribution: {np.bincount(y_train_balanced)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:13:28.337733Z","iopub.execute_input":"2025-09-26T04:13:28.338013Z","iopub.status.idle":"2025-09-26T04:13:28.371418Z","shell.execute_reply.started":"2025-09-26T04:13:28.337989Z","shell.execute_reply":"2025-09-26T04:13:28.368685Z"}},"outputs":[{"name":"stdout","text":"Training set: (668, 20)\nHoldout set: (167, 20)\nTraining class distribution: [625  43]\nHoldout class distribution: [156  11]\nBalanced training set: (1250, 20)\nBalanced training class distribution: [625 625]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# =============================\n# Cervical Cancer Prediction – Advanced Deep Learning Models\n# =============================\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\n\n# =============================\n# 1. Create Callbacks\n# =============================\ndef create_model_callbacks(model_name):\n    \"\"\"Create callbacks for model training\"\"\"\n    early_stopping = EarlyStopping(\n        monitor='val_loss',\n        patience=20,\n        restore_best_weights=True,\n        verbose=1\n    )\n    \n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=10,\n        min_lr=1e-6,\n        verbose=1\n    )\n    \n    model_checkpoint = ModelCheckpoint(\n        f'best_{model_name}_model.h5',\n        monitor='val_loss',\n        save_best_only=True,\n        verbose=1\n    )\n    \n    return [early_stopping, reduce_lr, model_checkpoint]\n\n\n# =============================\n# 2. Train + Evaluate Function\n# =============================\ndef train_and_evaluate_model(model_fn, X_train, y_train, X_val, y_val, model_name, epochs=200):\n    \"\"\"Train and evaluate a model\"\"\"\n    model = model_fn()\n    model.compile(\n        optimizer=Adam(learning_rate=0.0008),  # tuned LR\n        loss='binary_crossentropy',\n        metrics=[\n            'accuracy',\n            tf.keras.metrics.Precision(name=\"precision\"),\n            tf.keras.metrics.Recall(name=\"recall\"),\n            # ✅ Fix: binary classification F1\n            tfa.metrics.F1Score(num_classes=1, average=\"micro\", threshold=0.5, name=\"f1_score\")\n        ]\n    )\n    \n    callbacks = create_model_callbacks(model_name)\n    history = model.fit(\n        X_train, y_train,\n        batch_size=32,\n        epochs=epochs,\n        validation_data=(X_val, y_val),\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    return model, history\n\n\n# =============================\n# 3. Stronger Model Architectures\n# =============================\n\ninput_dim = X_train_balanced.shape[1]\n\n# Deep Neural Network (DNN)\ndef create_dnn():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(input_dim,)),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.4),\n\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n\n\n# CNN-based model (for tabular → 1D sequence)\ndef create_cnn():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n        tf.keras.layers.MaxPooling1D(pool_size=2),\n        tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu'),\n        tf.keras.layers.GlobalMaxPooling1D(),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n\n\n# Hybrid Model (DNN + CNN merged)\ndef create_hybrid():\n    # Input\n    inp = tf.keras.layers.Input(shape=(input_dim,))\n    \n    # DNN branch\n    dnn = tf.keras.layers.Dense(128, activation='relu')(inp)\n    dnn = tf.keras.layers.BatchNormalization()(dnn)\n    dnn = tf.keras.layers.Dropout(0.3)(dnn)\n    \n    # CNN branch\n    cnn = tf.keras.layers.Reshape((input_dim, 1))(inp)\n    cnn = tf.keras.layers.Conv1D(64, 3, activation='relu')(cnn)\n    cnn = tf.keras.layers.GlobalMaxPooling1D()(cnn)\n    \n    # Merge branches\n    merged = tf.keras.layers.Concatenate()([dnn, cnn])\n    merged = tf.keras.layers.Dense(64, activation='relu')(merged)\n    merged = tf.keras.layers.Dropout(0.3)(merged)\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(merged)\n    \n    model = tf.keras.Model(inputs=inp, outputs=out)\n    return model\n\n\n# =============================\n# 4. Train-Validation Split\n# =============================\nX_train_split, X_val, y_train_split, y_val = train_test_split(\n    X_train_balanced, y_train_balanced,\n    test_size=0.2, random_state=42, stratify=y_train_balanced\n)\n\n\n# =============================\n# 5. Train Models\n# =============================\nprint(\"Training Custom DNN...\")\ndnn_model, dnn_history = train_and_evaluate_model(\n    create_dnn, X_train_split, y_train_split, X_val, y_val, 'dnn', epochs=200\n)\n\nprint(\"\\nTraining Custom CNN...\")\ncnn_model, cnn_history = train_and_evaluate_model(\n    create_cnn, X_train_split, y_train_split, X_val, y_val, 'cnn', epochs=200\n)\n\nprint(\"\\nTraining Hybrid Model...\")\nhybrid_model, hybrid_history = train_and_evaluate_model(\n    create_hybrid, X_train_split, y_train_split, X_val, y_val, 'hybrid', epochs=200\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:18:27.065578Z","iopub.execute_input":"2025-09-26T04:18:27.065976Z","iopub.status.idle":"2025-09-26T04:19:50.542638Z","shell.execute_reply.started":"2025-09-26T04:18:27.065950Z","shell.execute_reply":"2025-09-26T04:19:50.541763Z"}},"outputs":[{"name":"stdout","text":"Training Custom DNN...\nEpoch 1/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.8125 - accuracy: 0.5625 - precision: 0.5661 - recall: 0.6009 - f1_score: 0.5830\nEpoch 1: val_loss improved from inf to 0.65614, saving model to best_dnn_model.h5\n32/32 [==============================] - 4s 23ms/step - loss: 0.8084 - accuracy: 0.5620 - precision: 0.5574 - recall: 0.6020 - f1_score: 0.5788 - val_loss: 0.6561 - val_accuracy: 0.6240 - val_precision: 0.5764 - val_recall: 0.9360 - val_f1_score: 0.7134 - lr: 8.0000e-04\nEpoch 2/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.7046 - accuracy: 0.6053 - precision: 0.6009 - recall: 0.6218 - f1_score: 0.6112\nEpoch 2: val_loss improved from 0.65614 to 0.64387, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.6991 - accuracy: 0.6140 - precision: 0.6105 - recall: 0.6300 - f1_score: 0.6201 - val_loss: 0.6439 - val_accuracy: 0.5640 - val_precision: 0.5342 - val_recall: 1.0000 - val_f1_score: 0.6964 - lr: 8.0000e-04\nEpoch 3/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.6360 - accuracy: 0.6507 - precision: 0.6253 - recall: 0.6959 - f1_score: 0.6587\nEpoch 3: val_loss did not improve from 0.64387\n32/32 [==============================] - 0s 6ms/step - loss: 0.6369 - accuracy: 0.6510 - precision: 0.6411 - recall: 0.6860 - f1_score: 0.6628 - val_loss: 0.6515 - val_accuracy: 0.5480 - val_precision: 0.5252 - val_recall: 1.0000 - val_f1_score: 0.6887 - lr: 8.0000e-04\nEpoch 4/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.5800 - accuracy: 0.7009 - precision: 0.6925 - recall: 0.7323 - f1_score: 0.7118\nEpoch 4: val_loss did not improve from 0.64387\n32/32 [==============================] - 0s 6ms/step - loss: 0.5826 - accuracy: 0.7010 - precision: 0.6893 - recall: 0.7320 - f1_score: 0.7100 - val_loss: 0.6638 - val_accuracy: 0.5520 - val_precision: 0.5274 - val_recall: 1.0000 - val_f1_score: 0.6906 - lr: 8.0000e-04\nEpoch 5/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.5879 - accuracy: 0.7069 - precision: 0.6885 - recall: 0.7368 - f1_score: 0.7119\nEpoch 5: val_loss did not improve from 0.64387\n32/32 [==============================] - 0s 5ms/step - loss: 0.5820 - accuracy: 0.7140 - precision: 0.7027 - recall: 0.7420 - f1_score: 0.7218 - val_loss: 0.6642 - val_accuracy: 0.5520 - val_precision: 0.5274 - val_recall: 1.0000 - val_f1_score: 0.6906 - lr: 8.0000e-04\nEpoch 6/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.5266 - accuracy: 0.7241 - precision: 0.7053 - recall: 0.7720 - f1_score: 0.7372\nEpoch 6: val_loss did not improve from 0.64387\n32/32 [==============================] - 0s 5ms/step - loss: 0.5248 - accuracy: 0.7240 - precision: 0.7044 - recall: 0.7720 - f1_score: 0.7366 - val_loss: 0.6558 - val_accuracy: 0.5600 - val_precision: 0.5319 - val_recall: 1.0000 - val_f1_score: 0.6944 - lr: 8.0000e-04\nEpoch 7/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.5180 - accuracy: 0.7479 - precision: 0.7301 - recall: 0.7850 - f1_score: 0.7565\nEpoch 7: val_loss improved from 0.64387 to 0.61529, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.5160 - accuracy: 0.7500 - precision: 0.7341 - recall: 0.7840 - f1_score: 0.7582 - val_loss: 0.6153 - val_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 1.0000 - val_f1_score: 0.7143 - lr: 8.0000e-04\nEpoch 8/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.4940 - accuracy: 0.7556 - precision: 0.7320 - recall: 0.7995 - f1_score: 0.7643\nEpoch 8: val_loss improved from 0.61529 to 0.58566, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.7510 - precision: 0.7337 - recall: 0.7880 - f1_score: 0.7599 - val_loss: 0.5857 - val_accuracy: 0.6680 - val_precision: 0.6010 - val_recall: 1.0000 - val_f1_score: 0.7508 - lr: 8.0000e-04\nEpoch 9/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.4694 - accuracy: 0.7857 - precision: 0.7724 - recall: 0.8168 - f1_score: 0.7940\nEpoch 9: val_loss improved from 0.58566 to 0.53328, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.7860 - precision: 0.7688 - recall: 0.8180 - f1_score: 0.7926 - val_loss: 0.5333 - val_accuracy: 0.7320 - val_precision: 0.6510 - val_recall: 1.0000 - val_f1_score: 0.7886 - lr: 8.0000e-04\nEpoch 10/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.4757 - accuracy: 0.7780 - precision: 0.7607 - recall: 0.8069 - f1_score: 0.7832\nEpoch 10: val_loss improved from 0.53328 to 0.50364, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.7750 - precision: 0.7599 - recall: 0.8040 - f1_score: 0.7813 - val_loss: 0.5036 - val_accuracy: 0.7520 - val_precision: 0.6684 - val_recall: 1.0000 - val_f1_score: 0.8013 - lr: 8.0000e-04\nEpoch 11/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.4512 - accuracy: 0.7834 - precision: 0.7724 - recall: 0.8009 - f1_score: 0.7864\nEpoch 11: val_loss improved from 0.50364 to 0.47683, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.7870 - precision: 0.7786 - recall: 0.8020 - f1_score: 0.7901 - val_loss: 0.4768 - val_accuracy: 0.7480 - val_precision: 0.6649 - val_recall: 1.0000 - val_f1_score: 0.7987 - lr: 8.0000e-04\nEpoch 12/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.4295 - accuracy: 0.7913 - precision: 0.7686 - recall: 0.8322 - f1_score: 0.7991\nEpoch 12: val_loss improved from 0.47683 to 0.45465, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.7910 - precision: 0.7709 - recall: 0.8280 - f1_score: 0.7985 - val_loss: 0.4547 - val_accuracy: 0.7760 - val_precision: 0.6906 - val_recall: 1.0000 - val_f1_score: 0.8170 - lr: 8.0000e-04\nEpoch 13/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.4397 - accuracy: 0.7940 - precision: 0.7770 - recall: 0.8205 - f1_score: 0.7982\nEpoch 13: val_loss improved from 0.45465 to 0.44421, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7850 - precision: 0.7684 - recall: 0.8160 - f1_score: 0.7915 - val_loss: 0.4442 - val_accuracy: 0.7760 - val_precision: 0.6906 - val_recall: 1.0000 - val_f1_score: 0.8170 - lr: 8.0000e-04\nEpoch 14/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.3999 - accuracy: 0.8137 - precision: 0.7905 - recall: 0.8499 - f1_score: 0.8191\nEpoch 14: val_loss improved from 0.44421 to 0.40408, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8070 - precision: 0.7924 - recall: 0.8320 - f1_score: 0.8117 - val_loss: 0.4041 - val_accuracy: 0.7920 - val_precision: 0.7062 - val_recall: 1.0000 - val_f1_score: 0.8278 - lr: 8.0000e-04\nEpoch 15/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.4139 - accuracy: 0.8317 - precision: 0.8145 - recall: 0.8612 - f1_score: 0.8372\nEpoch 15: val_loss improved from 0.40408 to 0.38114, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8290 - precision: 0.8098 - recall: 0.8600 - f1_score: 0.8341 - val_loss: 0.3811 - val_accuracy: 0.8040 - val_precision: 0.7209 - val_recall: 0.9920 - val_f1_score: 0.8350 - lr: 8.0000e-04\nEpoch 16/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3800 - accuracy: 0.8287 - precision: 0.8047 - recall: 0.8747 - f1_score: 0.8383\nEpoch 16: val_loss improved from 0.38114 to 0.37263, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8280 - precision: 0.7993 - recall: 0.8760 - f1_score: 0.8359 - val_loss: 0.3726 - val_accuracy: 0.8080 - val_precision: 0.7251 - val_recall: 0.9920 - val_f1_score: 0.8378 - lr: 8.0000e-04\nEpoch 17/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.3737 - accuracy: 0.8281 - precision: 0.8019 - recall: 0.8706 - f1_score: 0.8348\nEpoch 17: val_loss improved from 0.37263 to 0.34721, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3824 - accuracy: 0.8270 - precision: 0.8033 - recall: 0.8660 - f1_score: 0.8335 - val_loss: 0.3472 - val_accuracy: 0.8520 - val_precision: 0.7750 - val_recall: 0.9920 - val_f1_score: 0.8702 - lr: 8.0000e-04\nEpoch 18/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.3885 - accuracy: 0.8304 - precision: 0.8066 - recall: 0.8711 - f1_score: 0.8376\nEpoch 18: val_loss improved from 0.34721 to 0.33542, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8290 - precision: 0.8052 - recall: 0.8680 - f1_score: 0.8354 - val_loss: 0.3354 - val_accuracy: 0.8520 - val_precision: 0.7750 - val_recall: 0.9920 - val_f1_score: 0.8702 - lr: 8.0000e-04\nEpoch 19/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.4034 - accuracy: 0.8211 - precision: 0.7988 - recall: 0.8575 - f1_score: 0.8271\nEpoch 19: val_loss improved from 0.33542 to 0.32631, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8190 - precision: 0.7981 - recall: 0.8540 - f1_score: 0.8251 - val_loss: 0.3263 - val_accuracy: 0.8600 - val_precision: 0.7812 - val_recall: 1.0000 - val_f1_score: 0.8772 - lr: 8.0000e-04\nEpoch 20/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3615 - accuracy: 0.8495 - precision: 0.8283 - recall: 0.8853 - f1_score: 0.8559\nEpoch 20: val_loss did not improve from 0.32631\n32/32 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8410 - precision: 0.8187 - recall: 0.8760 - f1_score: 0.8464 - val_loss: 0.3334 - val_accuracy: 0.8560 - val_precision: 0.7834 - val_recall: 0.9840 - val_f1_score: 0.8723 - lr: 8.0000e-04\nEpoch 21/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3842 - accuracy: 0.8297 - precision: 0.8112 - recall: 0.8632 - f1_score: 0.8364\nEpoch 21: val_loss did not improve from 0.32631\n32/32 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8270 - precision: 0.8079 - recall: 0.8580 - f1_score: 0.8322 - val_loss: 0.3313 - val_accuracy: 0.8520 - val_precision: 0.7716 - val_recall: 1.0000 - val_f1_score: 0.8711 - lr: 8.0000e-04\nEpoch 22/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3545 - accuracy: 0.8513 - precision: 0.8330 - recall: 0.8796 - f1_score: 0.8556\nEpoch 22: val_loss improved from 0.32631 to 0.31828, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.8500 - precision: 0.8314 - recall: 0.8780 - f1_score: 0.8541 - val_loss: 0.3183 - val_accuracy: 0.8480 - val_precision: 0.7771 - val_recall: 0.9760 - val_f1_score: 0.8652 - lr: 8.0000e-04\nEpoch 23/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3495 - accuracy: 0.8403 - precision: 0.8188 - recall: 0.8652 - f1_score: 0.8414\nEpoch 23: val_loss improved from 0.31828 to 0.30524, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.8410 - precision: 0.8298 - recall: 0.8580 - f1_score: 0.8437 - val_loss: 0.3052 - val_accuracy: 0.8720 - val_precision: 0.8079 - val_recall: 0.9760 - val_f1_score: 0.8841 - lr: 8.0000e-04\nEpoch 24/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3447 - accuracy: 0.8507 - precision: 0.8374 - recall: 0.8704 - f1_score: 0.8536\nEpoch 24: val_loss improved from 0.30524 to 0.30167, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3460 - accuracy: 0.8490 - precision: 0.8362 - recall: 0.8680 - f1_score: 0.8518 - val_loss: 0.3017 - val_accuracy: 0.8600 - val_precision: 0.7848 - val_recall: 0.9920 - val_f1_score: 0.8763 - lr: 8.0000e-04\nEpoch 25/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.3454 - accuracy: 0.8438 - precision: 0.8237 - recall: 0.8786 - f1_score: 0.8502\nEpoch 25: val_loss improved from 0.30167 to 0.28010, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.8440 - precision: 0.8209 - recall: 0.8800 - f1_score: 0.8494 - val_loss: 0.2801 - val_accuracy: 0.8760 - val_precision: 0.8013 - val_recall: 1.0000 - val_f1_score: 0.8897 - lr: 8.0000e-04\nEpoch 26/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.3655 - accuracy: 0.8371 - precision: 0.8161 - recall: 0.8674 - f1_score: 0.8410\nEpoch 26: val_loss improved from 0.28010 to 0.26290, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3573 - accuracy: 0.8420 - precision: 0.8226 - recall: 0.8720 - f1_score: 0.8466 - val_loss: 0.2629 - val_accuracy: 0.8840 - val_precision: 0.8158 - val_recall: 0.9920 - val_f1_score: 0.8953 - lr: 8.0000e-04\nEpoch 27/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3251 - accuracy: 0.8669 - precision: 0.8497 - recall: 0.8839 - f1_score: 0.8664\nEpoch 27: val_loss did not improve from 0.26290\n32/32 [==============================] - 0s 6ms/step - loss: 0.3391 - accuracy: 0.8540 - precision: 0.8457 - recall: 0.8660 - f1_score: 0.8557 - val_loss: 0.2723 - val_accuracy: 0.8720 - val_precision: 0.8079 - val_recall: 0.9760 - val_f1_score: 0.8841 - lr: 8.0000e-04\nEpoch 28/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3279 - accuracy: 0.8728 - precision: 0.8592 - recall: 0.8957 - f1_score: 0.8771\nEpoch 28: val_loss did not improve from 0.26290\n32/32 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8650 - precision: 0.8450 - recall: 0.8940 - f1_score: 0.8688 - val_loss: 0.2707 - val_accuracy: 0.8840 - val_precision: 0.8333 - val_recall: 0.9600 - val_f1_score: 0.8922 - lr: 8.0000e-04\nEpoch 29/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.8683 - precision: 0.8413 - recall: 0.9056 - f1_score: 0.8723\nEpoch 29: val_loss did not improve from 0.26290\n32/32 [==============================] - 0s 6ms/step - loss: 0.3257 - accuracy: 0.8710 - precision: 0.8467 - recall: 0.9060 - f1_score: 0.8754 - val_loss: 0.2689 - val_accuracy: 0.9000 - val_precision: 0.8378 - val_recall: 0.9920 - val_f1_score: 0.9084 - lr: 8.0000e-04\nEpoch 30/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.3031 - accuracy: 0.8772 - precision: 0.8520 - recall: 0.9097 - f1_score: 0.8799\nEpoch 30: val_loss improved from 0.26290 to 0.26272, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3036 - accuracy: 0.8740 - precision: 0.8542 - recall: 0.9020 - f1_score: 0.8774 - val_loss: 0.2627 - val_accuracy: 0.8960 - val_precision: 0.8462 - val_recall: 0.9680 - val_f1_score: 0.9030 - lr: 8.0000e-04\nEpoch 31/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3196 - accuracy: 0.8611 - precision: 0.8501 - recall: 0.8776 - f1_score: 0.8636\nEpoch 31: val_loss did not improve from 0.26272\n32/32 [==============================] - 0s 6ms/step - loss: 0.3155 - accuracy: 0.8660 - precision: 0.8519 - recall: 0.8860 - f1_score: 0.8686 - val_loss: 0.2996 - val_accuracy: 0.8760 - val_precision: 0.8052 - val_recall: 0.9920 - val_f1_score: 0.8889 - lr: 8.0000e-04\nEpoch 32/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3038 - accuracy: 0.8727 - precision: 0.8671 - recall: 0.8830 - f1_score: 0.8750\nEpoch 32: val_loss did not improve from 0.26272\n32/32 [==============================] - 0s 6ms/step - loss: 0.3042 - accuracy: 0.8690 - precision: 0.8583 - recall: 0.8840 - f1_score: 0.8709 - val_loss: 0.2796 - val_accuracy: 0.8800 - val_precision: 0.8065 - val_recall: 1.0000 - val_f1_score: 0.8929 - lr: 8.0000e-04\nEpoch 33/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.3199 - accuracy: 0.8705 - precision: 0.8364 - recall: 0.9220 - f1_score: 0.8771\nEpoch 33: val_loss did not improve from 0.26272\n32/32 [==============================] - 0s 6ms/step - loss: 0.3116 - accuracy: 0.8750 - precision: 0.8391 - recall: 0.9280 - f1_score: 0.8813 - val_loss: 0.2759 - val_accuracy: 0.8760 - val_precision: 0.8052 - val_recall: 0.9920 - val_f1_score: 0.8889 - lr: 8.0000e-04\nEpoch 34/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3213 - accuracy: 0.8610 - precision: 0.8490 - recall: 0.8832 - f1_score: 0.8658\nEpoch 34: val_loss did not improve from 0.26272\n32/32 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8640 - precision: 0.8473 - recall: 0.8880 - f1_score: 0.8672 - val_loss: 0.2704 - val_accuracy: 0.8720 - val_precision: 0.8039 - val_recall: 0.9840 - val_f1_score: 0.8849 - lr: 8.0000e-04\nEpoch 35/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3286 - accuracy: 0.8715 - precision: 0.8719 - recall: 0.8739 - f1_score: 0.8729\nEpoch 35: val_loss improved from 0.26272 to 0.26065, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3207 - accuracy: 0.8770 - precision: 0.8703 - recall: 0.8860 - f1_score: 0.8781 - val_loss: 0.2607 - val_accuracy: 0.8920 - val_precision: 0.8311 - val_recall: 0.9840 - val_f1_score: 0.9011 - lr: 8.0000e-04\nEpoch 36/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3139 - accuracy: 0.8727 - precision: 0.8458 - recall: 0.9057 - f1_score: 0.8747\nEpoch 36: val_loss improved from 0.26065 to 0.25493, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3067 - accuracy: 0.8720 - precision: 0.8550 - recall: 0.8960 - f1_score: 0.8750 - val_loss: 0.2549 - val_accuracy: 0.8800 - val_precision: 0.8276 - val_recall: 0.9600 - val_f1_score: 0.8889 - lr: 8.0000e-04\nEpoch 37/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2931 - accuracy: 0.8772 - precision: 0.8651 - recall: 0.8958 - f1_score: 0.8802\nEpoch 37: val_loss did not improve from 0.25493\n32/32 [==============================] - 0s 6ms/step - loss: 0.2993 - accuracy: 0.8770 - precision: 0.8590 - recall: 0.9020 - f1_score: 0.8800 - val_loss: 0.2790 - val_accuracy: 0.8800 - val_precision: 0.8105 - val_recall: 0.9920 - val_f1_score: 0.8921 - lr: 8.0000e-04\nEpoch 38/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2983 - accuracy: 0.8727 - precision: 0.8559 - recall: 0.8991 - f1_score: 0.8770\nEpoch 38: val_loss did not improve from 0.25493\n32/32 [==============================] - 0s 6ms/step - loss: 0.2921 - accuracy: 0.8810 - precision: 0.8615 - recall: 0.9080 - f1_score: 0.8841 - val_loss: 0.2632 - val_accuracy: 0.8920 - val_precision: 0.8267 - val_recall: 0.9920 - val_f1_score: 0.9018 - lr: 8.0000e-04\nEpoch 39/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2747 - accuracy: 0.8750 - precision: 0.8562 - recall: 0.8986 - f1_score: 0.8769\nEpoch 39: val_loss did not improve from 0.25493\n32/32 [==============================] - 0s 6ms/step - loss: 0.2801 - accuracy: 0.8720 - precision: 0.8591 - recall: 0.8900 - f1_score: 0.8743 - val_loss: 0.2586 - val_accuracy: 0.8960 - val_precision: 0.8414 - val_recall: 0.9760 - val_f1_score: 0.9037 - lr: 8.0000e-04\nEpoch 40/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3382 - accuracy: 0.8623 - precision: 0.8462 - recall: 0.8800 - f1_score: 0.8627\nEpoch 40: val_loss improved from 0.25493 to 0.25460, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3304 - accuracy: 0.8650 - precision: 0.8558 - recall: 0.8780 - f1_score: 0.8667 - val_loss: 0.2546 - val_accuracy: 0.8880 - val_precision: 0.8299 - val_recall: 0.9760 - val_f1_score: 0.8971 - lr: 8.0000e-04\nEpoch 41/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2811 - accuracy: 0.8783 - precision: 0.8632 - recall: 0.9031 - f1_score: 0.8827\nEpoch 41: val_loss improved from 0.25460 to 0.24772, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2751 - accuracy: 0.8790 - precision: 0.8582 - recall: 0.9080 - f1_score: 0.8824 - val_loss: 0.2477 - val_accuracy: 0.8880 - val_precision: 0.8440 - val_recall: 0.9520 - val_f1_score: 0.8947 - lr: 8.0000e-04\nEpoch 42/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.2611 - accuracy: 0.8906 - precision: 0.8806 - recall: 0.9038 - f1_score: 0.8921\nEpoch 42: val_loss improved from 0.24772 to 0.24412, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2838 - accuracy: 0.8800 - precision: 0.8668 - recall: 0.8980 - f1_score: 0.8821 - val_loss: 0.2441 - val_accuracy: 0.8920 - val_precision: 0.8311 - val_recall: 0.9840 - val_f1_score: 0.9011 - lr: 8.0000e-04\nEpoch 43/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2955 - accuracy: 0.8761 - precision: 0.8678 - recall: 0.8854 - f1_score: 0.8765\nEpoch 43: val_loss improved from 0.24412 to 0.24108, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2937 - accuracy: 0.8780 - precision: 0.8735 - recall: 0.8840 - f1_score: 0.8787 - val_loss: 0.2411 - val_accuracy: 0.8920 - val_precision: 0.8451 - val_recall: 0.9600 - val_f1_score: 0.8989 - lr: 8.0000e-04\nEpoch 44/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2955 - accuracy: 0.8750 - precision: 0.8550 - recall: 0.9011 - f1_score: 0.8775\nEpoch 44: val_loss did not improve from 0.24108\n32/32 [==============================] - 0s 6ms/step - loss: 0.2960 - accuracy: 0.8730 - precision: 0.8566 - recall: 0.8960 - f1_score: 0.8759 - val_loss: 0.2441 - val_accuracy: 0.9040 - val_precision: 0.8531 - val_recall: 0.9760 - val_f1_score: 0.9104 - lr: 8.0000e-04\nEpoch 45/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2489 - accuracy: 0.9074 - precision: 0.8996 - recall: 0.9212 - f1_score: 0.9103\nEpoch 45: val_loss did not improve from 0.24108\n32/32 [==============================] - 0s 6ms/step - loss: 0.2649 - accuracy: 0.8970 - precision: 0.8810 - recall: 0.9180 - f1_score: 0.8991 - val_loss: 0.2467 - val_accuracy: 0.8960 - val_precision: 0.8322 - val_recall: 0.9920 - val_f1_score: 0.9051 - lr: 8.0000e-04\nEpoch 46/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2818 - accuracy: 0.8772 - precision: 0.8566 - recall: 0.9079 - f1_score: 0.8815\nEpoch 46: val_loss improved from 0.24108 to 0.22714, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2826 - accuracy: 0.8770 - precision: 0.8550 - recall: 0.9080 - f1_score: 0.8807 - val_loss: 0.2271 - val_accuracy: 0.9160 - val_precision: 0.8824 - val_recall: 0.9600 - val_f1_score: 0.9195 - lr: 8.0000e-04\nEpoch 47/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.2575 - accuracy: 0.8966 - precision: 0.8807 - recall: 0.9187 - f1_score: 0.8993\nEpoch 47: val_loss did not improve from 0.22714\n32/32 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.8980 - precision: 0.8827 - recall: 0.9180 - f1_score: 0.9000 - val_loss: 0.2380 - val_accuracy: 0.9040 - val_precision: 0.8435 - val_recall: 0.9920 - val_f1_score: 0.9118 - lr: 8.0000e-04\nEpoch 48/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2821 - accuracy: 0.8782 - precision: 0.8658 - recall: 0.8939 - f1_score: 0.8797\nEpoch 48: val_loss did not improve from 0.22714\n32/32 [==============================] - 0s 6ms/step - loss: 0.2869 - accuracy: 0.8780 - precision: 0.8677 - recall: 0.8920 - f1_score: 0.8797 - val_loss: 0.2451 - val_accuracy: 0.9040 - val_precision: 0.8435 - val_recall: 0.9920 - val_f1_score: 0.9118 - lr: 8.0000e-04\nEpoch 49/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2532 - accuracy: 0.9028 - precision: 0.8837 - recall: 0.9251 - f1_score: 0.9039\nEpoch 49: val_loss did not improve from 0.22714\n32/32 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.9010 - precision: 0.8878 - recall: 0.9180 - f1_score: 0.9027 - val_loss: 0.2315 - val_accuracy: 0.9080 - val_precision: 0.8493 - val_recall: 0.9920 - val_f1_score: 0.9151 - lr: 8.0000e-04\nEpoch 50/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2924 - accuracy: 0.8773 - precision: 0.8546 - recall: 0.9065 - f1_score: 0.8798\nEpoch 50: val_loss improved from 0.22714 to 0.21697, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2877 - accuracy: 0.8760 - precision: 0.8574 - recall: 0.9020 - f1_score: 0.8791 - val_loss: 0.2170 - val_accuracy: 0.9120 - val_precision: 0.8552 - val_recall: 0.9920 - val_f1_score: 0.9185 - lr: 8.0000e-04\nEpoch 51/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2540 - accuracy: 0.8873 - precision: 0.8780 - recall: 0.8996 - f1_score: 0.8886\nEpoch 51: val_loss did not improve from 0.21697\n32/32 [==============================] - 0s 6ms/step - loss: 0.2531 - accuracy: 0.8900 - precision: 0.8809 - recall: 0.9020 - f1_score: 0.8913 - val_loss: 0.2350 - val_accuracy: 0.9040 - val_precision: 0.8435 - val_recall: 0.9920 - val_f1_score: 0.9118 - lr: 8.0000e-04\nEpoch 52/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2570 - accuracy: 0.9007 - precision: 0.8877 - recall: 0.9209 - f1_score: 0.9040\nEpoch 52: val_loss did not improve from 0.21697\n32/32 [==============================] - 0s 6ms/step - loss: 0.2590 - accuracy: 0.8990 - precision: 0.8829 - recall: 0.9200 - f1_score: 0.9011 - val_loss: 0.2217 - val_accuracy: 0.8960 - val_precision: 0.8322 - val_recall: 0.9920 - val_f1_score: 0.9051 - lr: 8.0000e-04\nEpoch 53/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2586 - accuracy: 0.8944 - precision: 0.8789 - recall: 0.9165 - f1_score: 0.8973\nEpoch 53: val_loss did not improve from 0.21697\n32/32 [==============================] - 0s 6ms/step - loss: 0.2688 - accuracy: 0.8880 - precision: 0.8702 - recall: 0.9120 - f1_score: 0.8906 - val_loss: 0.2201 - val_accuracy: 0.8960 - val_precision: 0.8322 - val_recall: 0.9920 - val_f1_score: 0.9051 - lr: 8.0000e-04\nEpoch 54/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2390 - accuracy: 0.9106 - precision: 0.9076 - recall: 0.9172 - f1_score: 0.9124\nEpoch 54: val_loss improved from 0.21697 to 0.21379, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2370 - accuracy: 0.9100 - precision: 0.9020 - recall: 0.9200 - f1_score: 0.9109 - val_loss: 0.2138 - val_accuracy: 0.9160 - val_precision: 0.8611 - val_recall: 0.9920 - val_f1_score: 0.9219 - lr: 8.0000e-04\nEpoch 55/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2305 - accuracy: 0.9118 - precision: 0.9017 - recall: 0.9275 - f1_score: 0.9144\nEpoch 55: val_loss did not improve from 0.21379\n32/32 [==============================] - 0s 6ms/step - loss: 0.2368 - accuracy: 0.9090 - precision: 0.8925 - recall: 0.9300 - f1_score: 0.9109 - val_loss: 0.2227 - val_accuracy: 0.9080 - val_precision: 0.8542 - val_recall: 0.9840 - val_f1_score: 0.9145 - lr: 8.0000e-04\nEpoch 56/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2373 - accuracy: 0.8951 - precision: 0.8758 - recall: 0.9191 - f1_score: 0.8969\nEpoch 56: val_loss did not improve from 0.21379\n32/32 [==============================] - 0s 6ms/step - loss: 0.2386 - accuracy: 0.8940 - precision: 0.8788 - recall: 0.9140 - f1_score: 0.8961 - val_loss: 0.2265 - val_accuracy: 0.8960 - val_precision: 0.8322 - val_recall: 0.9920 - val_f1_score: 0.9051 - lr: 8.0000e-04\nEpoch 57/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2478 - accuracy: 0.9106 - precision: 0.8987 - recall: 0.9241 - f1_score: 0.9112\nEpoch 57: val_loss improved from 0.21379 to 0.21284, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2446 - accuracy: 0.9090 - precision: 0.8971 - recall: 0.9240 - f1_score: 0.9103 - val_loss: 0.2128 - val_accuracy: 0.9080 - val_precision: 0.8592 - val_recall: 0.9760 - val_f1_score: 0.9139 - lr: 8.0000e-04\nEpoch 58/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2267 - accuracy: 0.9106 - precision: 0.8902 - recall: 0.9379 - f1_score: 0.9135\nEpoch 58: val_loss did not improve from 0.21284\n32/32 [==============================] - 0s 6ms/step - loss: 0.2327 - accuracy: 0.9070 - precision: 0.8861 - recall: 0.9340 - f1_score: 0.9094 - val_loss: 0.2242 - val_accuracy: 0.9200 - val_precision: 0.8723 - val_recall: 0.9840 - val_f1_score: 0.9248 - lr: 8.0000e-04\nEpoch 59/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2247 - accuracy: 0.8984 - precision: 0.8950 - recall: 0.9049 - f1_score: 0.8999\nEpoch 59: val_loss improved from 0.21284 to 0.21156, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2328 - accuracy: 0.8980 - precision: 0.8933 - recall: 0.9040 - f1_score: 0.8986 - val_loss: 0.2116 - val_accuracy: 0.9160 - val_precision: 0.8611 - val_recall: 0.9920 - val_f1_score: 0.9219 - lr: 8.0000e-04\nEpoch 60/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2309 - accuracy: 0.9174 - precision: 0.9036 - recall: 0.9357 - f1_score: 0.9194\nEpoch 60: val_loss improved from 0.21156 to 0.20289, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2294 - accuracy: 0.9200 - precision: 0.9054 - recall: 0.9380 - f1_score: 0.9214 - val_loss: 0.2029 - val_accuracy: 0.9080 - val_precision: 0.8592 - val_recall: 0.9760 - val_f1_score: 0.9139 - lr: 8.0000e-04\nEpoch 61/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2268 - accuracy: 0.9167 - precision: 0.9050 - recall: 0.9302 - f1_score: 0.9174\nEpoch 61: val_loss did not improve from 0.20289\n32/32 [==============================] - 0s 6ms/step - loss: 0.2265 - accuracy: 0.9160 - precision: 0.9047 - recall: 0.9300 - f1_score: 0.9172 - val_loss: 0.2049 - val_accuracy: 0.9120 - val_precision: 0.8552 - val_recall: 0.9920 - val_f1_score: 0.9185 - lr: 8.0000e-04\nEpoch 62/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.2623 - accuracy: 0.8966 - precision: 0.8964 - recall: 0.8964 - f1_score: 0.8964\nEpoch 62: val_loss did not improve from 0.20289\n32/32 [==============================] - 0s 6ms/step - loss: 0.2662 - accuracy: 0.8960 - precision: 0.8976 - recall: 0.8940 - f1_score: 0.8958 - val_loss: 0.2257 - val_accuracy: 0.8960 - val_precision: 0.8322 - val_recall: 0.9920 - val_f1_score: 0.9051 - lr: 8.0000e-04\nEpoch 63/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2455 - accuracy: 0.9030 - precision: 0.8905 - recall: 0.9209 - f1_score: 0.9055\nEpoch 63: val_loss improved from 0.20289 to 0.20210, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2527 - accuracy: 0.8990 - precision: 0.8844 - recall: 0.9180 - f1_score: 0.9009 - val_loss: 0.2021 - val_accuracy: 0.9160 - val_precision: 0.8611 - val_recall: 0.9920 - val_f1_score: 0.9219 - lr: 8.0000e-04\nEpoch 64/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2355 - accuracy: 0.9085 - precision: 0.8868 - recall: 0.9347 - f1_score: 0.9101\nEpoch 64: val_loss improved from 0.20210 to 0.18801, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2290 - accuracy: 0.9100 - precision: 0.8927 - recall: 0.9320 - f1_score: 0.9119 - val_loss: 0.1880 - val_accuracy: 0.9200 - val_precision: 0.8777 - val_recall: 0.9760 - val_f1_score: 0.9242 - lr: 8.0000e-04\nEpoch 65/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2338 - accuracy: 0.9159 - precision: 0.8988 - recall: 0.9375 - f1_score: 0.9177\nEpoch 65: val_loss did not improve from 0.18801\n32/32 [==============================] - 0s 6ms/step - loss: 0.2330 - accuracy: 0.9180 - precision: 0.8989 - recall: 0.9420 - f1_score: 0.9199 - val_loss: 0.2101 - val_accuracy: 0.9040 - val_precision: 0.8435 - val_recall: 0.9920 - val_f1_score: 0.9118 - lr: 8.0000e-04\nEpoch 66/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2412 - accuracy: 0.8987 - precision: 0.8797 - recall: 0.9217 - f1_score: 0.9002\nEpoch 66: val_loss improved from 0.18801 to 0.17473, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.9010 - precision: 0.8848 - recall: 0.9220 - f1_score: 0.9030 - val_loss: 0.1747 - val_accuracy: 0.9200 - val_precision: 0.8671 - val_recall: 0.9920 - val_f1_score: 0.9254 - lr: 8.0000e-04\nEpoch 67/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2141 - accuracy: 0.8970 - precision: 0.8717 - recall: 0.9271 - f1_score: 0.8985\nEpoch 67: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2159 - accuracy: 0.9020 - precision: 0.8836 - recall: 0.9260 - f1_score: 0.9043 - val_loss: 0.1942 - val_accuracy: 0.9120 - val_precision: 0.8552 - val_recall: 0.9920 - val_f1_score: 0.9185 - lr: 8.0000e-04\nEpoch 68/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2231 - accuracy: 0.9074 - precision: 0.8936 - recall: 0.9264 - f1_score: 0.9097\nEpoch 68: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2227 - accuracy: 0.9060 - precision: 0.8874 - recall: 0.9300 - f1_score: 0.9082 - val_loss: 0.1766 - val_accuracy: 0.9320 - val_precision: 0.8913 - val_recall: 0.9840 - val_f1_score: 0.9354 - lr: 8.0000e-04\nEpoch 69/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2283 - accuracy: 0.9074 - precision: 0.9027 - recall: 0.9151 - f1_score: 0.9089\nEpoch 69: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2332 - accuracy: 0.9050 - precision: 0.8947 - recall: 0.9180 - f1_score: 0.9062 - val_loss: 0.1997 - val_accuracy: 0.9200 - val_precision: 0.8671 - val_recall: 0.9920 - val_f1_score: 0.9254 - lr: 8.0000e-04\nEpoch 70/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2136 - accuracy: 0.9084 - precision: 0.8966 - recall: 0.9219 - f1_score: 0.9091\nEpoch 70: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2150 - accuracy: 0.9080 - precision: 0.9016 - recall: 0.9160 - f1_score: 0.9087 - val_loss: 0.1874 - val_accuracy: 0.9160 - val_precision: 0.8611 - val_recall: 0.9920 - val_f1_score: 0.9219 - lr: 8.0000e-04\nEpoch 71/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2158 - accuracy: 0.9241 - precision: 0.9056 - recall: 0.9462 - f1_score: 0.9254\nEpoch 71: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2158 - accuracy: 0.9220 - precision: 0.9073 - recall: 0.9400 - f1_score: 0.9234 - val_loss: 0.1949 - val_accuracy: 0.9360 - val_precision: 0.8921 - val_recall: 0.9920 - val_f1_score: 0.9394 - lr: 8.0000e-04\nEpoch 72/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1934 - accuracy: 0.9163 - precision: 0.9002 - recall: 0.9381 - f1_score: 0.9187\nEpoch 72: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2072 - accuracy: 0.9110 - precision: 0.8929 - recall: 0.9340 - f1_score: 0.9130 - val_loss: 0.1938 - val_accuracy: 0.9200 - val_precision: 0.8832 - val_recall: 0.9680 - val_f1_score: 0.9237 - lr: 8.0000e-04\nEpoch 73/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1919 - accuracy: 0.9201 - precision: 0.9108 - recall: 0.9299 - f1_score: 0.9202\nEpoch 73: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2002 - accuracy: 0.9170 - precision: 0.9096 - recall: 0.9260 - f1_score: 0.9177 - val_loss: 0.1897 - val_accuracy: 0.9280 - val_precision: 0.8794 - val_recall: 0.9920 - val_f1_score: 0.9323 - lr: 8.0000e-04\nEpoch 74/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2317 - accuracy: 0.8993 - precision: 0.8945 - recall: 0.9049 - f1_score: 0.8997\nEpoch 74: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2356 - accuracy: 0.9000 - precision: 0.8953 - recall: 0.9060 - f1_score: 0.9006 - val_loss: 0.1865 - val_accuracy: 0.9280 - val_precision: 0.8849 - val_recall: 0.9840 - val_f1_score: 0.9318 - lr: 8.0000e-04\nEpoch 75/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1990 - accuracy: 0.9144 - precision: 0.9130 - recall: 0.9172 - f1_score: 0.9151\nEpoch 75: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2077 - accuracy: 0.9130 - precision: 0.9089 - recall: 0.9180 - f1_score: 0.9134 - val_loss: 0.2025 - val_accuracy: 0.9240 - val_precision: 0.8786 - val_recall: 0.9840 - val_f1_score: 0.9283 - lr: 8.0000e-04\nEpoch 76/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.2009 - accuracy: 0.9306 - precision: 0.9053 - recall: 0.9603 - f1_score: 0.9320\nEpoch 76: ReduceLROnPlateau reducing learning rate to 0.00039999998989515007.\n\nEpoch 76: val_loss did not improve from 0.17473\n32/32 [==============================] - 0s 6ms/step - loss: 0.2103 - accuracy: 0.9270 - precision: 0.9021 - recall: 0.9580 - f1_score: 0.9292 - val_loss: 0.1786 - val_accuracy: 0.9400 - val_precision: 0.9044 - val_recall: 0.9840 - val_f1_score: 0.9425 - lr: 8.0000e-04\nEpoch 77/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1790 - accuracy: 0.9332 - precision: 0.9205 - recall: 0.9483 - f1_score: 0.9342\nEpoch 77: val_loss improved from 0.17473 to 0.17388, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1744 - accuracy: 0.9350 - precision: 0.9223 - recall: 0.9500 - f1_score: 0.9360 - val_loss: 0.1739 - val_accuracy: 0.9320 - val_precision: 0.8857 - val_recall: 0.9920 - val_f1_score: 0.9358 - lr: 4.0000e-04\nEpoch 78/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1906 - accuracy: 0.9275 - precision: 0.9051 - recall: 0.9555 - f1_score: 0.9296\nEpoch 78: val_loss improved from 0.17388 to 0.16284, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1849 - accuracy: 0.9320 - precision: 0.9122 - recall: 0.9560 - f1_score: 0.9336 - val_loss: 0.1628 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 4.0000e-04\nEpoch 79/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1789 - accuracy: 0.9282 - precision: 0.9220 - recall: 0.9349 - f1_score: 0.9284\nEpoch 79: val_loss did not improve from 0.16284\n32/32 [==============================] - 0s 6ms/step - loss: 0.1767 - accuracy: 0.9290 - precision: 0.9248 - recall: 0.9340 - f1_score: 0.9294 - val_loss: 0.1647 - val_accuracy: 0.9320 - val_precision: 0.8913 - val_recall: 0.9840 - val_f1_score: 0.9354 - lr: 4.0000e-04\nEpoch 80/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1868 - accuracy: 0.9235 - precision: 0.9137 - recall: 0.9353 - f1_score: 0.9244\nEpoch 80: val_loss did not improve from 0.16284\n32/32 [==============================] - 0s 5ms/step - loss: 0.1889 - accuracy: 0.9240 - precision: 0.9125 - recall: 0.9380 - f1_score: 0.9250 - val_loss: 0.1629 - val_accuracy: 0.9400 - val_precision: 0.9044 - val_recall: 0.9840 - val_f1_score: 0.9425 - lr: 4.0000e-04\nEpoch 81/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2110 - accuracy: 0.9170 - precision: 0.9091 - recall: 0.9267 - f1_score: 0.9178\nEpoch 81: val_loss did not improve from 0.16284\n32/32 [==============================] - 0s 6ms/step - loss: 0.2158 - accuracy: 0.9160 - precision: 0.9078 - recall: 0.9260 - f1_score: 0.9168 - val_loss: 0.1634 - val_accuracy: 0.9320 - val_precision: 0.8913 - val_recall: 0.9840 - val_f1_score: 0.9354 - lr: 4.0000e-04\nEpoch 82/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1935 - accuracy: 0.9201 - precision: 0.9114 - recall: 0.9304 - f1_score: 0.9208\nEpoch 82: val_loss did not improve from 0.16284\n32/32 [==============================] - 0s 6ms/step - loss: 0.1889 - accuracy: 0.9210 - precision: 0.9136 - recall: 0.9300 - f1_score: 0.9217 - val_loss: 0.1642 - val_accuracy: 0.9400 - val_precision: 0.8986 - val_recall: 0.9920 - val_f1_score: 0.9430 - lr: 4.0000e-04\nEpoch 83/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2181 - accuracy: 0.9084 - precision: 0.8909 - recall: 0.9312 - f1_score: 0.9106\nEpoch 83: val_loss improved from 0.16284 to 0.16164, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2129 - accuracy: 0.9110 - precision: 0.8914 - recall: 0.9360 - f1_score: 0.9132 - val_loss: 0.1616 - val_accuracy: 0.9400 - val_precision: 0.9044 - val_recall: 0.9840 - val_f1_score: 0.9425 - lr: 4.0000e-04\nEpoch 84/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1884 - accuracy: 0.9286 - precision: 0.9258 - recall: 0.9339 - f1_score: 0.9298\nEpoch 84: val_loss did not improve from 0.16164\n32/32 [==============================] - 0s 6ms/step - loss: 0.1918 - accuracy: 0.9260 - precision: 0.9176 - recall: 0.9360 - f1_score: 0.9267 - val_loss: 0.1683 - val_accuracy: 0.9320 - val_precision: 0.8913 - val_recall: 0.9840 - val_f1_score: 0.9354 - lr: 4.0000e-04\nEpoch 85/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1660 - accuracy: 0.9398 - precision: 0.9330 - recall: 0.9500 - f1_score: 0.9414\nEpoch 85: val_loss did not improve from 0.16164\n32/32 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.9400 - precision: 0.9280 - recall: 0.9540 - f1_score: 0.9408 - val_loss: 0.1733 - val_accuracy: 0.9360 - val_precision: 0.8978 - val_recall: 0.9840 - val_f1_score: 0.9389 - lr: 4.0000e-04\nEpoch 86/200\n25/32 [======================>.......] - ETA: 0s - loss: 0.1897 - accuracy: 0.9312 - precision: 0.9387 - recall: 0.9274 - f1_score: 0.9330\nEpoch 86: val_loss did not improve from 0.16164\n32/32 [==============================] - 0s 6ms/step - loss: 0.1984 - accuracy: 0.9280 - precision: 0.9229 - recall: 0.9340 - f1_score: 0.9284 - val_loss: 0.1735 - val_accuracy: 0.9280 - val_precision: 0.8794 - val_recall: 0.9920 - val_f1_score: 0.9323 - lr: 4.0000e-04\nEpoch 87/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1680 - accuracy: 0.9410 - precision: 0.9315 - recall: 0.9510 - f1_score: 0.9412\nEpoch 87: val_loss did not improve from 0.16164\n32/32 [==============================] - 0s 6ms/step - loss: 0.1697 - accuracy: 0.9390 - precision: 0.9295 - recall: 0.9500 - f1_score: 0.9397 - val_loss: 0.1741 - val_accuracy: 0.9360 - val_precision: 0.8921 - val_recall: 0.9920 - val_f1_score: 0.9394 - lr: 4.0000e-04\nEpoch 88/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1827 - accuracy: 0.9271 - precision: 0.9258 - recall: 0.9321 - f1_score: 0.9290\nEpoch 88: val_loss did not improve from 0.16164\n32/32 [==============================] - 0s 6ms/step - loss: 0.1879 - accuracy: 0.9250 - precision: 0.9159 - recall: 0.9360 - f1_score: 0.9258 - val_loss: 0.1736 - val_accuracy: 0.9440 - val_precision: 0.9051 - val_recall: 0.9920 - val_f1_score: 0.9466 - lr: 4.0000e-04\nEpoch 89/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1809 - accuracy: 0.9248 - precision: 0.9126 - recall: 0.9363 - f1_score: 0.9243\nEpoch 89: val_loss did not improve from 0.16164\n32/32 [==============================] - 0s 6ms/step - loss: 0.1781 - accuracy: 0.9270 - precision: 0.9228 - recall: 0.9320 - f1_score: 0.9274 - val_loss: 0.1628 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 4.0000e-04\nEpoch 90/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1630 - accuracy: 0.9317 - precision: 0.9168 - recall: 0.9523 - f1_score: 0.9342\nEpoch 90: val_loss improved from 0.16164 to 0.15951, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1738 - accuracy: 0.9290 - precision: 0.9133 - recall: 0.9480 - f1_score: 0.9303 - val_loss: 0.1595 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 4.0000e-04\nEpoch 91/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1645 - accuracy: 0.9397 - precision: 0.9244 - recall: 0.9575 - f1_score: 0.9407\nEpoch 91: val_loss improved from 0.15951 to 0.15840, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1686 - accuracy: 0.9380 - precision: 0.9212 - recall: 0.9580 - f1_score: 0.9392 - val_loss: 0.1584 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 4.0000e-04\nEpoch 92/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1722 - accuracy: 0.9286 - precision: 0.9194 - recall: 0.9399 - f1_score: 0.9295\nEpoch 92: val_loss improved from 0.15840 to 0.15593, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1749 - accuracy: 0.9270 - precision: 0.9178 - recall: 0.9380 - f1_score: 0.9278 - val_loss: 0.1559 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 4.0000e-04\nEpoch 93/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1695 - accuracy: 0.9364 - precision: 0.9279 - recall: 0.9465 - f1_score: 0.9372\nEpoch 93: val_loss improved from 0.15593 to 0.15582, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1711 - accuracy: 0.9370 - precision: 0.9276 - recall: 0.9480 - f1_score: 0.9377 - val_loss: 0.1558 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 4.0000e-04\nEpoch 94/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1765 - accuracy: 0.9364 - precision: 0.9159 - recall: 0.9594 - f1_score: 0.9372\nEpoch 94: val_loss did not improve from 0.15582\n32/32 [==============================] - 0s 6ms/step - loss: 0.1718 - accuracy: 0.9380 - precision: 0.9212 - recall: 0.9580 - f1_score: 0.9392 - val_loss: 0.1564 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 4.0000e-04\nEpoch 95/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1600 - accuracy: 0.9321 - precision: 0.9231 - recall: 0.9447 - f1_score: 0.9338\nEpoch 95: val_loss did not improve from 0.15582\n32/32 [==============================] - 0s 6ms/step - loss: 0.1652 - accuracy: 0.9340 - precision: 0.9222 - recall: 0.9480 - f1_score: 0.9349 - val_loss: 0.1637 - val_accuracy: 0.9440 - val_precision: 0.9111 - val_recall: 0.9840 - val_f1_score: 0.9462 - lr: 4.0000e-04\nEpoch 96/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1789 - accuracy: 0.9352 - precision: 0.9297 - recall: 0.9425 - f1_score: 0.9361\nEpoch 96: val_loss improved from 0.15582 to 0.15352, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1814 - accuracy: 0.9340 - precision: 0.9255 - recall: 0.9440 - f1_score: 0.9347 - val_loss: 0.1535 - val_accuracy: 0.9440 - val_precision: 0.9051 - val_recall: 0.9920 - val_f1_score: 0.9466 - lr: 4.0000e-04\nEpoch 97/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.1535 - accuracy: 0.9435 - precision: 0.9412 - recall: 0.9479 - f1_score: 0.9445\nEpoch 97: val_loss improved from 0.15352 to 0.15027, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1516 - accuracy: 0.9450 - precision: 0.9389 - recall: 0.9520 - f1_score: 0.9454 - val_loss: 0.1503 - val_accuracy: 0.9360 - val_precision: 0.8921 - val_recall: 0.9920 - val_f1_score: 0.9394 - lr: 4.0000e-04\nEpoch 98/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.1584 - accuracy: 0.9411 - precision: 0.9385 - recall: 0.9452 - f1_score: 0.9419\nEpoch 98: val_loss did not improve from 0.15027\n32/32 [==============================] - 0s 6ms/step - loss: 0.1572 - accuracy: 0.9410 - precision: 0.9366 - recall: 0.9460 - f1_score: 0.9413 - val_loss: 0.1572 - val_accuracy: 0.9360 - val_precision: 0.8921 - val_recall: 0.9920 - val_f1_score: 0.9394 - lr: 4.0000e-04\nEpoch 99/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.1615 - accuracy: 0.9399 - precision: 0.9163 - recall: 0.9657 - f1_score: 0.9403\nEpoch 99: val_loss did not improve from 0.15027\n32/32 [==============================] - 0s 6ms/step - loss: 0.1667 - accuracy: 0.9410 - precision: 0.9249 - recall: 0.9600 - f1_score: 0.9421 - val_loss: 0.1571 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 4.0000e-04\nEpoch 100/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1644 - accuracy: 0.9352 - precision: 0.9281 - recall: 0.9451 - f1_score: 0.9365\nEpoch 100: val_loss improved from 0.15027 to 0.14829, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1625 - accuracy: 0.9350 - precision: 0.9273 - recall: 0.9440 - f1_score: 0.9356 - val_loss: 0.1483 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 4.0000e-04\nEpoch 101/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1650 - accuracy: 0.9444 - precision: 0.9379 - recall: 0.9510 - f1_score: 0.9444\nEpoch 101: val_loss did not improve from 0.14829\n32/32 [==============================] - 0s 6ms/step - loss: 0.1707 - accuracy: 0.9410 - precision: 0.9349 - recall: 0.9480 - f1_score: 0.9414 - val_loss: 0.1532 - val_accuracy: 0.9560 - val_precision: 0.9254 - val_recall: 0.9920 - val_f1_score: 0.9575 - lr: 4.0000e-04\nEpoch 102/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1498 - accuracy: 0.9498 - precision: 0.9427 - recall: 0.9575 - f1_score: 0.9501\nEpoch 102: val_loss did not improve from 0.14829\n32/32 [==============================] - 0s 6ms/step - loss: 0.1560 - accuracy: 0.9460 - precision: 0.9390 - recall: 0.9540 - f1_score: 0.9464 - val_loss: 0.1542 - val_accuracy: 0.9560 - val_precision: 0.9254 - val_recall: 0.9920 - val_f1_score: 0.9575 - lr: 4.0000e-04\nEpoch 103/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1501 - accuracy: 0.9418 - precision: 0.9328 - recall: 0.9528 - f1_score: 0.9427\nEpoch 103: val_loss did not improve from 0.14829\n32/32 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.9410 - precision: 0.9315 - recall: 0.9520 - f1_score: 0.9416 - val_loss: 0.1529 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 4.0000e-04\nEpoch 104/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1747 - accuracy: 0.9363 - precision: 0.9329 - recall: 0.9394 - f1_score: 0.9361\nEpoch 104: val_loss did not improve from 0.14829\n32/32 [==============================] - 0s 6ms/step - loss: 0.1763 - accuracy: 0.9360 - precision: 0.9343 - recall: 0.9380 - f1_score: 0.9361 - val_loss: 0.1558 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 4.0000e-04\nEpoch 105/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1376 - accuracy: 0.9397 - precision: 0.9214 - recall: 0.9591 - f1_score: 0.9399\nEpoch 105: val_loss did not improve from 0.14829\n32/32 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.9400 - precision: 0.9264 - recall: 0.9560 - f1_score: 0.9409 - val_loss: 0.1486 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 4.0000e-04\nEpoch 106/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1725 - accuracy: 0.9408 - precision: 0.9297 - recall: 0.9527 - f1_score: 0.9410\nEpoch 106: val_loss did not improve from 0.14829\n32/32 [==============================] - 0s 6ms/step - loss: 0.1767 - accuracy: 0.9400 - precision: 0.9314 - recall: 0.9500 - f1_score: 0.9406 - val_loss: 0.1515 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 4.0000e-04\nEpoch 107/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1659 - accuracy: 0.9397 - precision: 0.9335 - recall: 0.9498 - f1_score: 0.9416\nEpoch 107: val_loss did not improve from 0.14829\n32/32 [==============================] - 0s 6ms/step - loss: 0.1697 - accuracy: 0.9380 - precision: 0.9261 - recall: 0.9520 - f1_score: 0.9389 - val_loss: 0.1601 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 4.0000e-04\nEpoch 108/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1653 - accuracy: 0.9319 - precision: 0.9279 - recall: 0.9382 - f1_score: 0.9330\nEpoch 108: val_loss did not improve from 0.14829\n32/32 [==============================] - 0s 6ms/step - loss: 0.1744 - accuracy: 0.9280 - precision: 0.9163 - recall: 0.9420 - f1_score: 0.9290 - val_loss: 0.1490 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 4.0000e-04\nEpoch 109/200\n25/32 [======================>.......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9600 - precision: 0.9505 - recall: 0.9697 - f1_score: 0.9600\nEpoch 109: val_loss improved from 0.14829 to 0.14333, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.1416 - accuracy: 0.9480 - precision: 0.9375 - recall: 0.9600 - f1_score: 0.9486 - val_loss: 0.1433 - val_accuracy: 0.9560 - val_precision: 0.9254 - val_recall: 0.9920 - val_f1_score: 0.9575 - lr: 4.0000e-04\nEpoch 110/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1653 - accuracy: 0.9387 - precision: 0.9323 - recall: 0.9472 - f1_score: 0.9397\nEpoch 110: val_loss did not improve from 0.14333\n32/32 [==============================] - 0s 6ms/step - loss: 0.1570 - accuracy: 0.9420 - precision: 0.9333 - recall: 0.9520 - f1_score: 0.9426 - val_loss: 0.1572 - val_accuracy: 0.9440 - val_precision: 0.9051 - val_recall: 0.9920 - val_f1_score: 0.9466 - lr: 4.0000e-04\nEpoch 111/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.1648 - accuracy: 0.9339 - precision: 0.9346 - recall: 0.9324 - f1_score: 0.9335\nEpoch 111: val_loss did not improve from 0.14333\n32/32 [==============================] - 0s 6ms/step - loss: 0.1697 - accuracy: 0.9320 - precision: 0.9320 - recall: 0.9320 - f1_score: 0.9320 - val_loss: 0.1566 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 4.0000e-04\nEpoch 112/200\n22/32 [===================>..........] - ETA: 0s - loss: 0.1629 - accuracy: 0.9361 - precision: 0.9288 - recall: 0.9469 - f1_score: 0.9378\nEpoch 112: val_loss did not improve from 0.14333\n32/32 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.9420 - precision: 0.9350 - recall: 0.9500 - f1_score: 0.9425 - val_loss: 0.1491 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 4.0000e-04\nEpoch 113/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1567 - accuracy: 0.9464 - precision: 0.9370 - recall: 0.9578 - f1_score: 0.9473\nEpoch 113: val_loss did not improve from 0.14333\n32/32 [==============================] - 0s 6ms/step - loss: 0.1600 - accuracy: 0.9410 - precision: 0.9349 - recall: 0.9480 - f1_score: 0.9414 - val_loss: 0.1526 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 4.0000e-04\nEpoch 114/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1666 - accuracy: 0.9330 - precision: 0.9249 - recall: 0.9416 - f1_score: 0.9332\nEpoch 114: val_loss did not improve from 0.14333\n32/32 [==============================] - 0s 6ms/step - loss: 0.1659 - accuracy: 0.9330 - precision: 0.9287 - recall: 0.9380 - f1_score: 0.9333 - val_loss: 0.1474 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 4.0000e-04\nEpoch 115/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1661 - accuracy: 0.9475 - precision: 0.9365 - recall: 0.9596 - f1_score: 0.9480\nEpoch 115: val_loss did not improve from 0.14333\n32/32 [==============================] - 0s 6ms/step - loss: 0.1621 - accuracy: 0.9480 - precision: 0.9375 - recall: 0.9600 - f1_score: 0.9486 - val_loss: 0.1443 - val_accuracy: 0.9560 - val_precision: 0.9254 - val_recall: 0.9920 - val_f1_score: 0.9575 - lr: 4.0000e-04\nEpoch 116/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1551 - accuracy: 0.9410 - precision: 0.9385 - recall: 0.9450 - f1_score: 0.9417\nEpoch 116: val_loss improved from 0.14333 to 0.14326, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1643 - accuracy: 0.9360 - precision: 0.9291 - recall: 0.9440 - f1_score: 0.9365 - val_loss: 0.1433 - val_accuracy: 0.9560 - val_precision: 0.9254 - val_recall: 0.9920 - val_f1_score: 0.9575 - lr: 4.0000e-04\nEpoch 117/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1583 - accuracy: 0.9297 - precision: 0.9263 - recall: 0.9326 - f1_score: 0.9295\nEpoch 117: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1546 - accuracy: 0.9310 - precision: 0.9319 - recall: 0.9300 - f1_score: 0.9309 - val_loss: 0.1497 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 4.0000e-04\nEpoch 118/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1636 - accuracy: 0.9386 - precision: 0.9317 - recall: 0.9463 - f1_score: 0.9390\nEpoch 118: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1665 - accuracy: 0.9370 - precision: 0.9327 - recall: 0.9420 - f1_score: 0.9373 - val_loss: 0.1465 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 4.0000e-04\nEpoch 119/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1604 - accuracy: 0.9330 - precision: 0.9124 - recall: 0.9574 - f1_score: 0.9344\nEpoch 119: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n\nEpoch 119: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1565 - accuracy: 0.9360 - precision: 0.9192 - recall: 0.9560 - f1_score: 0.9373 - val_loss: 0.1527 - val_accuracy: 0.9480 - val_precision: 0.9242 - val_recall: 0.9760 - val_f1_score: 0.9494 - lr: 4.0000e-04\nEpoch 120/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1501 - accuracy: 0.9472 - precision: 0.9368 - recall: 0.9591 - f1_score: 0.9478\nEpoch 120: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.9490 - precision: 0.9411 - recall: 0.9580 - f1_score: 0.9495 - val_loss: 0.1502 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 2.0000e-04\nEpoch 121/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.1426 - accuracy: 0.9459 - precision: 0.9458 - recall: 0.9480 - f1_score: 0.9469\nEpoch 121: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.9450 - precision: 0.9406 - recall: 0.9500 - f1_score: 0.9453 - val_loss: 0.1446 - val_accuracy: 0.9560 - val_precision: 0.9318 - val_recall: 0.9840 - val_f1_score: 0.9572 - lr: 2.0000e-04\nEpoch 122/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1513 - accuracy: 0.9464 - precision: 0.9487 - recall: 0.9444 - f1_score: 0.9465\nEpoch 122: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1444 - accuracy: 0.9480 - precision: 0.9516 - recall: 0.9440 - f1_score: 0.9478 - val_loss: 0.1444 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 2.0000e-04\nEpoch 123/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1747 - accuracy: 0.9306 - precision: 0.9343 - recall: 0.9256 - f1_score: 0.9299\nEpoch 123: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1750 - accuracy: 0.9300 - precision: 0.9317 - recall: 0.9280 - f1_score: 0.9299 - val_loss: 0.1442 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 2.0000e-04\nEpoch 124/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1591 - accuracy: 0.9375 - precision: 0.9311 - recall: 0.9480 - f1_score: 0.9395\nEpoch 124: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9340 - precision: 0.9222 - recall: 0.9480 - f1_score: 0.9349 - val_loss: 0.1449 - val_accuracy: 0.9440 - val_precision: 0.9111 - val_recall: 0.9840 - val_f1_score: 0.9462 - lr: 2.0000e-04\nEpoch 125/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1368 - accuracy: 0.9433 - precision: 0.9421 - recall: 0.9443 - f1_score: 0.9432\nEpoch 125: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1395 - accuracy: 0.9430 - precision: 0.9457 - recall: 0.9400 - f1_score: 0.9428 - val_loss: 0.1461 - val_accuracy: 0.9440 - val_precision: 0.9051 - val_recall: 0.9920 - val_f1_score: 0.9466 - lr: 2.0000e-04\nEpoch 126/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1473 - accuracy: 0.9502 - precision: 0.9448 - recall: 0.9558 - f1_score: 0.9503\nEpoch 126: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1581 - accuracy: 0.9470 - precision: 0.9391 - recall: 0.9560 - f1_score: 0.9475 - val_loss: 0.1476 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 2.0000e-04\nEpoch 127/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1462 - accuracy: 0.9386 - precision: 0.9254 - recall: 0.9526 - f1_score: 0.9388\nEpoch 127: val_loss did not improve from 0.14326\n32/32 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 0.9350 - precision: 0.9273 - recall: 0.9440 - f1_score: 0.9356 - val_loss: 0.1460 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 2.0000e-04\nEpoch 128/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1696 - accuracy: 0.9308 - precision: 0.9347 - recall: 0.9263 - f1_score: 0.9305\nEpoch 128: val_loss improved from 0.14326 to 0.13922, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9330 - precision: 0.9339 - recall: 0.9320 - f1_score: 0.9329 - val_loss: 0.1392 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 2.0000e-04\nEpoch 129/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1509 - accuracy: 0.9410 - precision: 0.9345 - recall: 0.9495 - f1_score: 0.9420\nEpoch 129: val_loss improved from 0.13922 to 0.13908, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9330 - precision: 0.9253 - recall: 0.9420 - f1_score: 0.9336 - val_loss: 0.1391 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 2.0000e-04\nEpoch 130/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1639 - accuracy: 0.9431 - precision: 0.9397 - recall: 0.9461 - f1_score: 0.9429\nEpoch 130: val_loss did not improve from 0.13908\n32/32 [==============================] - 0s 6ms/step - loss: 0.1632 - accuracy: 0.9430 - precision: 0.9386 - recall: 0.9480 - f1_score: 0.9433 - val_loss: 0.1402 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 2.0000e-04\nEpoch 131/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1420 - accuracy: 0.9514 - precision: 0.9389 - recall: 0.9651 - f1_score: 0.9518\nEpoch 131: val_loss improved from 0.13908 to 0.13651, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.9490 - precision: 0.9376 - recall: 0.9620 - f1_score: 0.9497 - val_loss: 0.1365 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 2.0000e-04\nEpoch 132/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1559 - accuracy: 0.9408 - precision: 0.9264 - recall: 0.9575 - f1_score: 0.9417\nEpoch 132: val_loss improved from 0.13651 to 0.13515, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1636 - accuracy: 0.9340 - precision: 0.9205 - recall: 0.9500 - f1_score: 0.9350 - val_loss: 0.1352 - val_accuracy: 0.9440 - val_precision: 0.9111 - val_recall: 0.9840 - val_f1_score: 0.9462 - lr: 2.0000e-04\nEpoch 133/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1400 - accuracy: 0.9515 - precision: 0.9529 - recall: 0.9509 - f1_score: 0.9519\nEpoch 133: val_loss improved from 0.13515 to 0.13215, saving model to best_dnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.9480 - precision: 0.9462 - recall: 0.9500 - f1_score: 0.9481 - val_loss: 0.1322 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 2.0000e-04\nEpoch 134/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1327 - accuracy: 0.9565 - precision: 0.9520 - recall: 0.9625 - f1_score: 0.9572\nEpoch 134: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1317 - accuracy: 0.9560 - precision: 0.9488 - recall: 0.9640 - f1_score: 0.9563 - val_loss: 0.1330 - val_accuracy: 0.9440 - val_precision: 0.9111 - val_recall: 0.9840 - val_f1_score: 0.9462 - lr: 2.0000e-04\nEpoch 135/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1308 - accuracy: 0.9464 - precision: 0.9375 - recall: 0.9581 - f1_score: 0.9477\nEpoch 135: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1408 - accuracy: 0.9440 - precision: 0.9319 - recall: 0.9580 - f1_score: 0.9448 - val_loss: 0.1372 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 2.0000e-04\nEpoch 136/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1306 - accuracy: 0.9520 - precision: 0.9497 - recall: 0.9559 - f1_score: 0.9528\nEpoch 136: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1283 - accuracy: 0.9540 - precision: 0.9504 - recall: 0.9580 - f1_score: 0.9542 - val_loss: 0.1381 - val_accuracy: 0.9600 - val_precision: 0.9323 - val_recall: 0.9920 - val_f1_score: 0.9612 - lr: 2.0000e-04\nEpoch 137/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1481 - accuracy: 0.9375 - precision: 0.9289 - recall: 0.9463 - f1_score: 0.9375\nEpoch 137: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1401 - accuracy: 0.9410 - precision: 0.9366 - recall: 0.9460 - f1_score: 0.9413 - val_loss: 0.1402 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 2.0000e-04\nEpoch 138/200\n26/32 [=======================>......] - ETA: 0s - loss: 0.1306 - accuracy: 0.9543 - precision: 0.9362 - recall: 0.9730 - f1_score: 0.9542\nEpoch 138: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1265 - accuracy: 0.9560 - precision: 0.9419 - recall: 0.9720 - f1_score: 0.9567 - val_loss: 0.1392 - val_accuracy: 0.9480 - val_precision: 0.9179 - val_recall: 0.9840 - val_f1_score: 0.9498 - lr: 2.0000e-04\nEpoch 139/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1490 - accuracy: 0.9421 - precision: 0.9336 - recall: 0.9510 - f1_score: 0.9423\nEpoch 139: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1500 - accuracy: 0.9410 - precision: 0.9384 - recall: 0.9440 - f1_score: 0.9412 - val_loss: 0.1336 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 2.0000e-04\nEpoch 140/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1402 - accuracy: 0.9491 - precision: 0.9305 - recall: 0.9696 - f1_score: 0.9497\nEpoch 140: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1401 - accuracy: 0.9480 - precision: 0.9341 - recall: 0.9640 - f1_score: 0.9488 - val_loss: 0.1329 - val_accuracy: 0.9560 - val_precision: 0.9318 - val_recall: 0.9840 - val_f1_score: 0.9572 - lr: 2.0000e-04\nEpoch 141/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1493 - accuracy: 0.9433 - precision: 0.9464 - recall: 0.9398 - f1_score: 0.9431\nEpoch 141: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1592 - accuracy: 0.9400 - precision: 0.9472 - recall: 0.9320 - f1_score: 0.9395 - val_loss: 0.1397 - val_accuracy: 0.9560 - val_precision: 0.9318 - val_recall: 0.9840 - val_f1_score: 0.9572 - lr: 2.0000e-04\nEpoch 142/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1329 - accuracy: 0.9494 - precision: 0.9485 - recall: 0.9505 - f1_score: 0.9495\nEpoch 142: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1373 - accuracy: 0.9500 - precision: 0.9482 - recall: 0.9520 - f1_score: 0.9501 - val_loss: 0.1408 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 2.0000e-04\nEpoch 143/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1491 - accuracy: 0.9398 - precision: 0.9284 - recall: 0.9504 - f1_score: 0.9393\nEpoch 143: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\nEpoch 143: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1554 - accuracy: 0.9380 - precision: 0.9363 - recall: 0.9400 - f1_score: 0.9381 - val_loss: 0.1399 - val_accuracy: 0.9560 - val_precision: 0.9254 - val_recall: 0.9920 - val_f1_score: 0.9575 - lr: 2.0000e-04\nEpoch 144/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1443 - accuracy: 0.9453 - precision: 0.9344 - recall: 0.9574 - f1_score: 0.9457\nEpoch 144: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1529 - accuracy: 0.9430 - precision: 0.9335 - recall: 0.9540 - f1_score: 0.9436 - val_loss: 0.1419 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 145/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1400 - accuracy: 0.9431 - precision: 0.9426 - recall: 0.9447 - f1_score: 0.9436\nEpoch 145: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1361 - accuracy: 0.9460 - precision: 0.9442 - recall: 0.9480 - f1_score: 0.9461 - val_loss: 0.1416 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 146/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1406 - accuracy: 0.9456 - precision: 0.9347 - recall: 0.9584 - f1_score: 0.9464\nEpoch 146: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1423 - accuracy: 0.9460 - precision: 0.9355 - recall: 0.9580 - f1_score: 0.9466 - val_loss: 0.1409 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 147/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1415 - accuracy: 0.9429 - precision: 0.9284 - recall: 0.9587 - f1_score: 0.9433\nEpoch 147: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 5ms/step - loss: 0.1422 - accuracy: 0.9440 - precision: 0.9319 - recall: 0.9580 - f1_score: 0.9448 - val_loss: 0.1387 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 148/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1490 - accuracy: 0.9408 - precision: 0.9400 - recall: 0.9421 - f1_score: 0.9410\nEpoch 148: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9440 - precision: 0.9405 - recall: 0.9480 - f1_score: 0.9442 - val_loss: 0.1387 - val_accuracy: 0.9560 - val_precision: 0.9254 - val_recall: 0.9920 - val_f1_score: 0.9575 - lr: 1.0000e-04\nEpoch 149/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1396 - accuracy: 0.9468 - precision: 0.9402 - recall: 0.9534 - f1_score: 0.9468\nEpoch 149: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1365 - accuracy: 0.9470 - precision: 0.9443 - recall: 0.9500 - f1_score: 0.9472 - val_loss: 0.1365 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 150/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1265 - accuracy: 0.9520 - precision: 0.9514 - recall: 0.9535 - f1_score: 0.9525\nEpoch 150: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9520 - precision: 0.9484 - recall: 0.9560 - f1_score: 0.9522 - val_loss: 0.1368 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 151/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.1417 - accuracy: 0.9386 - precision: 0.9332 - recall: 0.9475 - f1_score: 0.9403\nEpoch 151: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1479 - accuracy: 0.9380 - precision: 0.9261 - recall: 0.9520 - f1_score: 0.9389 - val_loss: 0.1362 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 152/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.1190 - accuracy: 0.9618 - precision: 0.9612 - recall: 0.9634 - f1_score: 0.9623\nEpoch 152: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9610 - precision: 0.9583 - recall: 0.9640 - f1_score: 0.9611 - val_loss: 0.1360 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 153/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.1431 - accuracy: 0.9472 - precision: 0.9343 - recall: 0.9608 - f1_score: 0.9474Restoring model weights from the end of the best epoch: 133.\n\nEpoch 153: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 153: val_loss did not improve from 0.13215\n32/32 [==============================] - 0s 6ms/step - loss: 0.1453 - accuracy: 0.9470 - precision: 0.9374 - recall: 0.9580 - f1_score: 0.9476 - val_loss: 0.1355 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 1.0000e-04\nEpoch 153: early stopping\n\nTraining Custom CNN...\nEpoch 1/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.6864 - accuracy: 0.5279 - precision: 0.5647 - recall: 0.3158 - f1_score: 0.4051\nEpoch 1: val_loss improved from inf to 0.67467, saving model to best_cnn_model.h5\n32/32 [==============================] - 3s 21ms/step - loss: 0.6867 - accuracy: 0.5250 - precision: 0.5413 - recall: 0.3280 - f1_score: 0.4085 - val_loss: 0.6747 - val_accuracy: 0.6040 - val_precision: 0.7955 - val_recall: 0.2800 - val_f1_score: 0.4142 - lr: 8.0000e-04\nEpoch 2/200\n31/32 [============================>.] - ETA: 0s - loss: 0.6727 - accuracy: 0.5706 - precision: 0.6606 - recall: 0.2903 - f1_score: 0.4034\nEpoch 2: val_loss improved from 0.67467 to 0.65897, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.6720 - accuracy: 0.5730 - precision: 0.6652 - recall: 0.2940 - f1_score: 0.4078 - val_loss: 0.6590 - val_accuracy: 0.6200 - val_precision: 0.6744 - val_recall: 0.4640 - val_f1_score: 0.5498 - lr: 8.0000e-04\nEpoch 3/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.6585 - accuracy: 0.5635 - precision: 0.6109 - recall: 0.3298 - f1_score: 0.4284\nEpoch 3: val_loss improved from 0.65897 to 0.63912, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.6571 - accuracy: 0.5740 - precision: 0.6350 - recall: 0.3480 - f1_score: 0.4496 - val_loss: 0.6391 - val_accuracy: 0.6600 - val_precision: 0.6724 - val_recall: 0.6240 - val_f1_score: 0.6473 - lr: 8.0000e-04\nEpoch 4/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.6465 - accuracy: 0.6094 - precision: 0.6138 - recall: 0.6074 - f1_score: 0.6106\nEpoch 4: val_loss improved from 0.63912 to 0.62947, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.6458 - accuracy: 0.6080 - precision: 0.6055 - recall: 0.6200 - f1_score: 0.6126 - val_loss: 0.6295 - val_accuracy: 0.6560 - val_precision: 0.6000 - val_recall: 0.9360 - val_f1_score: 0.7313 - lr: 8.0000e-04\nEpoch 5/200\n31/32 [============================>.] - ETA: 0s - loss: 0.6231 - accuracy: 0.6542 - precision: 0.6835 - recall: 0.5746 - f1_score: 0.6243\nEpoch 5: val_loss improved from 0.62947 to 0.62041, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.6225 - accuracy: 0.6560 - precision: 0.6848 - recall: 0.5780 - f1_score: 0.6269 - val_loss: 0.6204 - val_accuracy: 0.6680 - val_precision: 0.6082 - val_recall: 0.9440 - val_f1_score: 0.7398 - lr: 8.0000e-04\nEpoch 6/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.6134 - accuracy: 0.6735 - precision: 0.6640 - recall: 0.7054 - f1_score: 0.6840\nEpoch 6: val_loss improved from 0.62041 to 0.60216, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.6710 - precision: 0.6592 - recall: 0.7080 - f1_score: 0.6827 - val_loss: 0.6022 - val_accuracy: 0.7000 - val_precision: 0.6389 - val_recall: 0.9200 - val_f1_score: 0.7541 - lr: 8.0000e-04\nEpoch 7/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.6005 - accuracy: 0.6713 - precision: 0.6613 - recall: 0.7026 - f1_score: 0.6813\nEpoch 7: val_loss improved from 0.60216 to 0.59511, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5978 - accuracy: 0.6730 - precision: 0.6576 - recall: 0.7220 - f1_score: 0.6883 - val_loss: 0.5951 - val_accuracy: 0.6800 - val_precision: 0.6190 - val_recall: 0.9360 - val_f1_score: 0.7452 - lr: 8.0000e-04\nEpoch 8/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.5886 - accuracy: 0.7058 - precision: 0.6869 - recall: 0.7565 - f1_score: 0.7200\nEpoch 8: val_loss improved from 0.59511 to 0.57948, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.5853 - accuracy: 0.7090 - precision: 0.6897 - recall: 0.7600 - f1_score: 0.7231 - val_loss: 0.5795 - val_accuracy: 0.7480 - val_precision: 0.7039 - val_recall: 0.8560 - val_f1_score: 0.7726 - lr: 8.0000e-04\nEpoch 9/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.5675 - accuracy: 0.7054 - precision: 0.6721 - recall: 0.8146 - f1_score: 0.7365\nEpoch 9: val_loss improved from 0.57948 to 0.56115, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5658 - accuracy: 0.7050 - precision: 0.6700 - recall: 0.8080 - f1_score: 0.7325 - val_loss: 0.5611 - val_accuracy: 0.7680 - val_precision: 0.7638 - val_recall: 0.7760 - val_f1_score: 0.7698 - lr: 8.0000e-04\nEpoch 10/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.5599 - accuracy: 0.7281 - precision: 0.7210 - recall: 0.7406 - f1_score: 0.7307\nEpoch 10: val_loss improved from 0.56115 to 0.55624, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5570 - accuracy: 0.7320 - precision: 0.7275 - recall: 0.7420 - f1_score: 0.7347 - val_loss: 0.5562 - val_accuracy: 0.7440 - val_precision: 0.6784 - val_recall: 0.9280 - val_f1_score: 0.7838 - lr: 8.0000e-04\nEpoch 11/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.5408 - accuracy: 0.7385 - precision: 0.7086 - recall: 0.8104 - f1_score: 0.7561\nEpoch 11: val_loss improved from 0.55624 to 0.53640, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7380 - precision: 0.7073 - recall: 0.8120 - f1_score: 0.7561 - val_loss: 0.5364 - val_accuracy: 0.7760 - val_precision: 0.7379 - val_recall: 0.8560 - val_f1_score: 0.7926 - lr: 8.0000e-04\nEpoch 12/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.5412 - accuracy: 0.7333 - precision: 0.7291 - recall: 0.7405 - f1_score: 0.7347\nEpoch 12: val_loss did not improve from 0.53640\n32/32 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7380 - precision: 0.7288 - recall: 0.7580 - f1_score: 0.7431 - val_loss: 0.5760 - val_accuracy: 0.6760 - val_precision: 0.6122 - val_recall: 0.9600 - val_f1_score: 0.7477 - lr: 8.0000e-04\nEpoch 13/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.5262 - accuracy: 0.7583 - precision: 0.7317 - recall: 0.8142 - f1_score: 0.7708\nEpoch 13: val_loss improved from 0.53640 to 0.50871, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7610 - precision: 0.7335 - recall: 0.8200 - f1_score: 0.7743 - val_loss: 0.5087 - val_accuracy: 0.7760 - val_precision: 0.7634 - val_recall: 0.8000 - val_f1_score: 0.7812 - lr: 8.0000e-04\nEpoch 14/200\n31/32 [============================>.] - ETA: 0s - loss: 0.4830 - accuracy: 0.7863 - precision: 0.7752 - recall: 0.8065 - f1_score: 0.7905\nEpoch 14: val_loss did not improve from 0.50871\n32/32 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7860 - precision: 0.7750 - recall: 0.8060 - f1_score: 0.7902 - val_loss: 0.5149 - val_accuracy: 0.7800 - val_precision: 0.7108 - val_recall: 0.9440 - val_f1_score: 0.8110 - lr: 8.0000e-04\nEpoch 15/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.4867 - accuracy: 0.7651 - precision: 0.7647 - recall: 0.7745 - f1_score: 0.7696\nEpoch 15: val_loss improved from 0.50871 to 0.50280, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7670 - precision: 0.7613 - recall: 0.7780 - f1_score: 0.7695 - val_loss: 0.5028 - val_accuracy: 0.7800 - val_precision: 0.7134 - val_recall: 0.9360 - val_f1_score: 0.8097 - lr: 8.0000e-04\nEpoch 16/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.4620 - accuracy: 0.7865 - precision: 0.7713 - recall: 0.8206 - f1_score: 0.7952\nEpoch 16: val_loss improved from 0.50280 to 0.48190, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7850 - precision: 0.7654 - recall: 0.8220 - f1_score: 0.7927 - val_loss: 0.4819 - val_accuracy: 0.8000 - val_precision: 0.7863 - val_recall: 0.8240 - val_f1_score: 0.8047 - lr: 8.0000e-04\nEpoch 17/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.4564 - accuracy: 0.7937 - precision: 0.7739 - recall: 0.8288 - f1_score: 0.8004\nEpoch 17: val_loss improved from 0.48190 to 0.47118, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7920 - precision: 0.7776 - recall: 0.8180 - f1_score: 0.7973 - val_loss: 0.4712 - val_accuracy: 0.8040 - val_precision: 0.8065 - val_recall: 0.8000 - val_f1_score: 0.8032 - lr: 8.0000e-04\nEpoch 18/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.4413 - accuracy: 0.7974 - precision: 0.7791 - recall: 0.8326 - f1_score: 0.8050\nEpoch 18: val_loss improved from 0.47118 to 0.46296, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7990 - precision: 0.7774 - recall: 0.8380 - f1_score: 0.8065 - val_loss: 0.4630 - val_accuracy: 0.8120 - val_precision: 0.8482 - val_recall: 0.7600 - val_f1_score: 0.8017 - lr: 8.0000e-04\nEpoch 19/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.4397 - accuracy: 0.7917 - precision: 0.7911 - recall: 0.7878 - f1_score: 0.7895\nEpoch 19: val_loss improved from 0.46296 to 0.45180, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7930 - precision: 0.7960 - recall: 0.7880 - f1_score: 0.7920 - val_loss: 0.4518 - val_accuracy: 0.8320 - val_precision: 0.8268 - val_recall: 0.8400 - val_f1_score: 0.8333 - lr: 8.0000e-04\nEpoch 20/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.4043 - accuracy: 0.8281 - precision: 0.8031 - recall: 0.8714 - f1_score: 0.8358\nEpoch 20: val_loss improved from 0.45180 to 0.44261, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8270 - precision: 0.8011 - recall: 0.8700 - f1_score: 0.8341 - val_loss: 0.4426 - val_accuracy: 0.8440 - val_precision: 0.8258 - val_recall: 0.8720 - val_f1_score: 0.8482 - lr: 8.0000e-04\nEpoch 21/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.4047 - accuracy: 0.8359 - precision: 0.8254 - recall: 0.8630 - f1_score: 0.8438\nEpoch 21: val_loss improved from 0.44261 to 0.43964, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8310 - precision: 0.8140 - recall: 0.8580 - f1_score: 0.8354 - val_loss: 0.4396 - val_accuracy: 0.8400 - val_precision: 0.8899 - val_recall: 0.7760 - val_f1_score: 0.8291 - lr: 8.0000e-04\nEpoch 22/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3842 - accuracy: 0.8448 - precision: 0.8216 - recall: 0.8817 - f1_score: 0.8506\nEpoch 22: val_loss improved from 0.43964 to 0.43743, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8420 - precision: 0.8214 - recall: 0.8740 - f1_score: 0.8469 - val_loss: 0.4374 - val_accuracy: 0.8480 - val_precision: 0.9143 - val_recall: 0.7680 - val_f1_score: 0.8348 - lr: 8.0000e-04\nEpoch 23/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3661 - accuracy: 0.8438 - precision: 0.8274 - recall: 0.8652 - f1_score: 0.8459\nEpoch 23: val_loss did not improve from 0.43743\n32/32 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8440 - precision: 0.8308 - recall: 0.8640 - f1_score: 0.8471 - val_loss: 0.4396 - val_accuracy: 0.8080 - val_precision: 0.7516 - val_recall: 0.9200 - val_f1_score: 0.8273 - lr: 8.0000e-04\nEpoch 24/200\n31/32 [============================>.] - ETA: 0s - loss: 0.3710 - accuracy: 0.8448 - precision: 0.8200 - recall: 0.8858 - f1_score: 0.8516\nEpoch 24: val_loss improved from 0.43743 to 0.42349, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8450 - precision: 0.8189 - recall: 0.8860 - f1_score: 0.8511 - val_loss: 0.4235 - val_accuracy: 0.8520 - val_precision: 0.8793 - val_recall: 0.8160 - val_f1_score: 0.8465 - lr: 8.0000e-04\nEpoch 25/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3539 - accuracy: 0.8524 - precision: 0.8553 - recall: 0.8498 - f1_score: 0.8525\nEpoch 25: val_loss improved from 0.42349 to 0.41624, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3554 - accuracy: 0.8530 - precision: 0.8551 - recall: 0.8500 - f1_score: 0.8526 - val_loss: 0.4162 - val_accuracy: 0.8560 - val_precision: 0.8504 - val_recall: 0.8640 - val_f1_score: 0.8571 - lr: 8.0000e-04\nEpoch 26/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.3609 - accuracy: 0.8333 - precision: 0.8090 - recall: 0.8700 - f1_score: 0.8384\nEpoch 26: val_loss did not improve from 0.41624\n32/32 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8310 - precision: 0.8117 - recall: 0.8620 - f1_score: 0.8361 - val_loss: 0.4614 - val_accuracy: 0.7920 - val_precision: 0.9294 - val_recall: 0.6320 - val_f1_score: 0.7524 - lr: 8.0000e-04\nEpoch 27/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3484 - accuracy: 0.8610 - precision: 0.8406 - recall: 0.8865 - f1_score: 0.8629\nEpoch 27: val_loss did not improve from 0.41624\n32/32 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8600 - precision: 0.8448 - recall: 0.8820 - f1_score: 0.8630 - val_loss: 0.4483 - val_accuracy: 0.8040 - val_precision: 0.7346 - val_recall: 0.9520 - val_f1_score: 0.8293 - lr: 8.0000e-04\nEpoch 28/200\n27/32 [========================>.....] - ETA: 0s - loss: 0.3344 - accuracy: 0.8519 - precision: 0.8290 - recall: 0.8866 - f1_score: 0.8568\nEpoch 28: val_loss did not improve from 0.41624\n32/32 [==============================] - 0s 6ms/step - loss: 0.3305 - accuracy: 0.8530 - precision: 0.8324 - recall: 0.8840 - f1_score: 0.8574 - val_loss: 0.4592 - val_accuracy: 0.8120 - val_precision: 0.7349 - val_recall: 0.9760 - val_f1_score: 0.8385 - lr: 8.0000e-04\nEpoch 29/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3047 - accuracy: 0.8707 - precision: 0.8634 - recall: 0.8820 - f1_score: 0.8726\nEpoch 29: val_loss improved from 0.41624 to 0.40739, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3077 - accuracy: 0.8720 - precision: 0.8633 - recall: 0.8840 - f1_score: 0.8735 - val_loss: 0.4074 - val_accuracy: 0.8680 - val_precision: 0.8485 - val_recall: 0.8960 - val_f1_score: 0.8716 - lr: 8.0000e-04\nEpoch 30/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.3040 - accuracy: 0.8885 - precision: 0.8730 - recall: 0.9110 - f1_score: 0.8916\nEpoch 30: val_loss improved from 0.40739 to 0.40032, saving model to best_cnn_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3073 - accuracy: 0.8860 - precision: 0.8655 - recall: 0.9140 - f1_score: 0.8891 - val_loss: 0.4003 - val_accuracy: 0.8920 - val_precision: 0.8952 - val_recall: 0.8880 - val_f1_score: 0.8916 - lr: 8.0000e-04\nEpoch 31/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.3064 - accuracy: 0.8696 - precision: 0.8515 - recall: 0.8939 - f1_score: 0.8722\nEpoch 31: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.3060 - accuracy: 0.8700 - precision: 0.8585 - recall: 0.8860 - f1_score: 0.8720 - val_loss: 0.4110 - val_accuracy: 0.8560 - val_precision: 0.9083 - val_recall: 0.7920 - val_f1_score: 0.8462 - lr: 8.0000e-04\nEpoch 32/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.3046 - accuracy: 0.8708 - precision: 0.8518 - recall: 0.8979 - f1_score: 0.8742\nEpoch 32: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8710 - precision: 0.8507 - recall: 0.9000 - f1_score: 0.8746 - val_loss: 0.4098 - val_accuracy: 0.8720 - val_precision: 0.8720 - val_recall: 0.8720 - val_f1_score: 0.8720 - lr: 8.0000e-04\nEpoch 33/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.2864 - accuracy: 0.8833 - precision: 0.8636 - recall: 0.9104 - f1_score: 0.8864\nEpoch 33: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 5ms/step - loss: 0.2850 - accuracy: 0.8840 - precision: 0.8650 - recall: 0.9100 - f1_score: 0.8869 - val_loss: 0.4153 - val_accuracy: 0.8720 - val_precision: 0.9189 - val_recall: 0.8160 - val_f1_score: 0.8644 - lr: 8.0000e-04\nEpoch 34/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2876 - accuracy: 0.8772 - precision: 0.8680 - recall: 0.8938 - f1_score: 0.8808\nEpoch 34: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2864 - accuracy: 0.8770 - precision: 0.8646 - recall: 0.8940 - f1_score: 0.8791 - val_loss: 0.4084 - val_accuracy: 0.8800 - val_precision: 0.9130 - val_recall: 0.8400 - val_f1_score: 0.8750 - lr: 8.0000e-04\nEpoch 35/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2720 - accuracy: 0.8976 - precision: 0.8830 - recall: 0.9188 - f1_score: 0.9005\nEpoch 35: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2691 - accuracy: 0.9010 - precision: 0.8863 - recall: 0.9200 - f1_score: 0.9028 - val_loss: 0.4681 - val_accuracy: 0.8360 - val_precision: 0.9667 - val_recall: 0.6960 - val_f1_score: 0.8093 - lr: 8.0000e-04\nEpoch 36/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2724 - accuracy: 0.8869 - precision: 0.8812 - recall: 0.8908 - f1_score: 0.8860\nEpoch 36: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2712 - accuracy: 0.8900 - precision: 0.8839 - recall: 0.8980 - f1_score: 0.8909 - val_loss: 0.5060 - val_accuracy: 0.8280 - val_precision: 0.7500 - val_recall: 0.9840 - val_f1_score: 0.8512 - lr: 8.0000e-04\nEpoch 37/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2669 - accuracy: 0.8879 - precision: 0.8692 - recall: 0.9172 - f1_score: 0.8926\nEpoch 37: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2701 - accuracy: 0.8880 - precision: 0.8660 - recall: 0.9180 - f1_score: 0.8913 - val_loss: 0.4181 - val_accuracy: 0.8760 - val_precision: 0.9123 - val_recall: 0.8320 - val_f1_score: 0.8703 - lr: 8.0000e-04\nEpoch 38/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.2518 - accuracy: 0.9083 - precision: 0.8891 - recall: 0.9335 - f1_score: 0.9108\nEpoch 38: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9060 - precision: 0.8919 - recall: 0.9240 - f1_score: 0.9077 - val_loss: 0.4680 - val_accuracy: 0.8520 - val_precision: 0.9583 - val_recall: 0.7360 - val_f1_score: 0.8326 - lr: 8.0000e-04\nEpoch 39/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2849 - accuracy: 0.8828 - precision: 0.8742 - recall: 0.8919 - f1_score: 0.8829\nEpoch 39: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2823 - accuracy: 0.8790 - precision: 0.8610 - recall: 0.9040 - f1_score: 0.8820 - val_loss: 0.4146 - val_accuracy: 0.8840 - val_precision: 0.8871 - val_recall: 0.8800 - val_f1_score: 0.8835 - lr: 8.0000e-04\nEpoch 40/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2580 - accuracy: 0.9040 - precision: 0.8923 - recall: 0.9165 - f1_score: 0.9042\nEpoch 40: ReduceLROnPlateau reducing learning rate to 0.00039999998989515007.\n\nEpoch 40: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2584 - accuracy: 0.9050 - precision: 0.8994 - recall: 0.9120 - f1_score: 0.9057 - val_loss: 0.4318 - val_accuracy: 0.8560 - val_precision: 0.8248 - val_recall: 0.9040 - val_f1_score: 0.8626 - lr: 8.0000e-04\nEpoch 41/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2333 - accuracy: 0.9129 - precision: 0.9000 - recall: 0.9317 - f1_score: 0.9156\nEpoch 41: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2286 - accuracy: 0.9150 - precision: 0.8967 - recall: 0.9380 - f1_score: 0.9169 - val_loss: 0.4106 - val_accuracy: 0.8920 - val_precision: 0.9153 - val_recall: 0.8640 - val_f1_score: 0.8889 - lr: 4.0000e-04\nEpoch 42/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2279 - accuracy: 0.9163 - precision: 0.9052 - recall: 0.9313 - f1_score: 0.9180\nEpoch 42: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2239 - accuracy: 0.9170 - precision: 0.9064 - recall: 0.9300 - f1_score: 0.9181 - val_loss: 0.4209 - val_accuracy: 0.8720 - val_precision: 0.9189 - val_recall: 0.8160 - val_f1_score: 0.8644 - lr: 4.0000e-04\nEpoch 43/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2326 - accuracy: 0.9116 - precision: 0.8960 - recall: 0.9309 - f1_score: 0.9131\nEpoch 43: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 5ms/step - loss: 0.2355 - accuracy: 0.9100 - precision: 0.8988 - recall: 0.9240 - f1_score: 0.9112 - val_loss: 0.4453 - val_accuracy: 0.8760 - val_precision: 0.9434 - val_recall: 0.8000 - val_f1_score: 0.8658 - lr: 4.0000e-04\nEpoch 44/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2308 - accuracy: 0.9138 - precision: 0.8926 - recall: 0.9391 - f1_score: 0.9153\nEpoch 44: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2262 - accuracy: 0.9170 - precision: 0.8956 - recall: 0.9440 - f1_score: 0.9192 - val_loss: 0.4179 - val_accuracy: 0.8800 - val_precision: 0.9204 - val_recall: 0.8320 - val_f1_score: 0.8739 - lr: 4.0000e-04\nEpoch 45/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2131 - accuracy: 0.9235 - precision: 0.9095 - recall: 0.9424 - f1_score: 0.9257\nEpoch 45: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2149 - accuracy: 0.9220 - precision: 0.9058 - recall: 0.9420 - f1_score: 0.9235 - val_loss: 0.4470 - val_accuracy: 0.8720 - val_precision: 0.9429 - val_recall: 0.7920 - val_f1_score: 0.8609 - lr: 4.0000e-04\nEpoch 46/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.2336 - accuracy: 0.9042 - precision: 0.8939 - recall: 0.9163 - f1_score: 0.9050\nEpoch 46: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.9050 - precision: 0.8963 - recall: 0.9160 - f1_score: 0.9060 - val_loss: 0.4249 - val_accuracy: 0.8880 - val_precision: 0.9076 - val_recall: 0.8640 - val_f1_score: 0.8852 - lr: 4.0000e-04\nEpoch 47/200\n28/32 [=========================>....] - ETA: 0s - loss: 0.2060 - accuracy: 0.9319 - precision: 0.9232 - recall: 0.9418 - f1_score: 0.9324\nEpoch 47: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2122 - accuracy: 0.9290 - precision: 0.9181 - recall: 0.9420 - f1_score: 0.9299 - val_loss: 0.4202 - val_accuracy: 0.8840 - val_precision: 0.8810 - val_recall: 0.8880 - val_f1_score: 0.8845 - lr: 4.0000e-04\nEpoch 48/200\n24/32 [=====================>........] - ETA: 0s - loss: 0.2145 - accuracy: 0.9206 - precision: 0.9111 - recall: 0.9365 - f1_score: 0.9237\nEpoch 48: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2124 - accuracy: 0.9240 - precision: 0.9141 - recall: 0.9360 - f1_score: 0.9249 - val_loss: 0.4178 - val_accuracy: 0.8840 - val_precision: 0.9000 - val_recall: 0.8640 - val_f1_score: 0.8816 - lr: 4.0000e-04\nEpoch 49/200\n17/32 [==============>...............] - ETA: 0s - loss: 0.2057 - accuracy: 0.9301 - precision: 0.9225 - recall: 0.9363 - f1_score: 0.9294\nEpoch 49: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 5ms/step - loss: 0.2019 - accuracy: 0.9360 - precision: 0.9291 - recall: 0.9440 - f1_score: 0.9365 - val_loss: 0.4362 - val_accuracy: 0.8920 - val_precision: 0.8603 - val_recall: 0.9360 - val_f1_score: 0.8966 - lr: 4.0000e-04\nEpoch 50/200\n29/32 [==========================>...] - ETA: 0s - loss: 0.2091 - accuracy: 0.9267 - precision: 0.9165 - recall: 0.9365 - f1_score: 0.9264Restoring model weights from the end of the best epoch: 30.\n\nEpoch 50: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n\nEpoch 50: val_loss did not improve from 0.40032\n32/32 [==============================] - 0s 6ms/step - loss: 0.2079 - accuracy: 0.9290 - precision: 0.9214 - recall: 0.9380 - f1_score: 0.9296 - val_loss: 0.4278 - val_accuracy: 0.8920 - val_precision: 0.8769 - val_recall: 0.9120 - val_f1_score: 0.8941 - lr: 4.0000e-04\nEpoch 50: early stopping\n\nTraining Hybrid Model...\nEpoch 1/200\n20/32 [=================>............] - ETA: 0s - loss: 0.8392 - accuracy: 0.5234 - precision: 0.5410 - recall: 0.5361 - f1_score: 0.5386  \nEpoch 1: val_loss improved from inf to 0.65222, saving model to best_hybrid_model.h5\n32/32 [==============================] - 3s 20ms/step - loss: 0.7924 - accuracy: 0.5440 - precision: 0.5431 - recall: 0.5540 - f1_score: 0.5485 - val_loss: 0.6522 - val_accuracy: 0.5880 - val_precision: 0.6964 - val_recall: 0.3120 - val_f1_score: 0.4309 - lr: 8.0000e-04\nEpoch 2/200\n19/32 [================>.............] - ETA: 0s - loss: 0.6933 - accuracy: 0.5954 - precision: 0.6064 - recall: 0.5588 - f1_score: 0.5816\nEpoch 2: val_loss improved from 0.65222 to 0.62938, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.6050 - precision: 0.6096 - recall: 0.5840 - f1_score: 0.5965 - val_loss: 0.6294 - val_accuracy: 0.6440 - val_precision: 0.8462 - val_recall: 0.3520 - val_f1_score: 0.4972 - lr: 8.0000e-04\nEpoch 3/200\n19/32 [================>.............] - ETA: 0s - loss: 0.6282 - accuracy: 0.6299 - precision: 0.6162 - recall: 0.6224 - f1_score: 0.6193\nEpoch 3: val_loss improved from 0.62938 to 0.61172, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.6340 - accuracy: 0.6330 - precision: 0.6377 - recall: 0.6160 - f1_score: 0.6267 - val_loss: 0.6117 - val_accuracy: 0.6400 - val_precision: 0.7869 - val_recall: 0.3840 - val_f1_score: 0.5161 - lr: 8.0000e-04\nEpoch 4/200\n19/32 [================>.............] - ETA: 0s - loss: 0.5890 - accuracy: 0.6743 - precision: 0.6404 - recall: 0.7073 - f1_score: 0.6722\nEpoch 4: val_loss improved from 0.61172 to 0.58173, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.6830 - precision: 0.6717 - recall: 0.7160 - f1_score: 0.6931 - val_loss: 0.5817 - val_accuracy: 0.7400 - val_precision: 0.8000 - val_recall: 0.6400 - val_f1_score: 0.7111 - lr: 8.0000e-04\nEpoch 5/200\n20/32 [=================>............] - ETA: 0s - loss: 0.5606 - accuracy: 0.6969 - precision: 0.6535 - recall: 0.7288 - f1_score: 0.6891\nEpoch 5: val_loss improved from 0.58173 to 0.55472, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5662 - accuracy: 0.6980 - precision: 0.6988 - recall: 0.6960 - f1_score: 0.6974 - val_loss: 0.5547 - val_accuracy: 0.7880 - val_precision: 0.8333 - val_recall: 0.7200 - val_f1_score: 0.7725 - lr: 8.0000e-04\nEpoch 6/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.5611 - accuracy: 0.7188 - precision: 0.6875 - recall: 0.7801 - f1_score: 0.7309\nEpoch 6: val_loss improved from 0.55472 to 0.53151, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7310 - precision: 0.7104 - recall: 0.7800 - f1_score: 0.7436 - val_loss: 0.5315 - val_accuracy: 0.8080 - val_precision: 0.8407 - val_recall: 0.7600 - val_f1_score: 0.7983 - lr: 8.0000e-04\nEpoch 7/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.4930 - accuracy: 0.7604 - precision: 0.7432 - recall: 0.7750 - f1_score: 0.7587\nEpoch 7: val_loss improved from 0.53151 to 0.50138, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7440 - precision: 0.7346 - recall: 0.7640 - f1_score: 0.7490 - val_loss: 0.5014 - val_accuracy: 0.8360 - val_precision: 0.8088 - val_recall: 0.8800 - val_f1_score: 0.8429 - lr: 8.0000e-04\nEpoch 8/200\n20/32 [=================>............] - ETA: 0s - loss: 0.4886 - accuracy: 0.7734 - precision: 0.7529 - recall: 0.8076 - f1_score: 0.7793\nEpoch 8: val_loss improved from 0.50138 to 0.48033, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7520 - precision: 0.7405 - recall: 0.7760 - f1_score: 0.7578 - val_loss: 0.4803 - val_accuracy: 0.8480 - val_precision: 0.8372 - val_recall: 0.8640 - val_f1_score: 0.8504 - lr: 8.0000e-04\nEpoch 9/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.4753 - accuracy: 0.7743 - precision: 0.7770 - recall: 0.7926 - f1_score: 0.7848\nEpoch 9: val_loss improved from 0.48033 to 0.45968, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7520 - precision: 0.7368 - recall: 0.7840 - f1_score: 0.7597 - val_loss: 0.4597 - val_accuracy: 0.8440 - val_precision: 0.8308 - val_recall: 0.8640 - val_f1_score: 0.8471 - lr: 8.0000e-04\nEpoch 10/200\n19/32 [================>.............] - ETA: 0s - loss: 0.4851 - accuracy: 0.7549 - precision: 0.7551 - recall: 0.7425 - f1_score: 0.7487\nEpoch 10: val_loss improved from 0.45968 to 0.42960, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7870 - precision: 0.7842 - recall: 0.7920 - f1_score: 0.7881 - val_loss: 0.4296 - val_accuracy: 0.8480 - val_precision: 0.8042 - val_recall: 0.9200 - val_f1_score: 0.8582 - lr: 8.0000e-04\nEpoch 11/200\n19/32 [================>.............] - ETA: 0s - loss: 0.4458 - accuracy: 0.7862 - precision: 0.7702 - recall: 0.8158 - f1_score: 0.7923\nEpoch 11: val_loss improved from 0.42960 to 0.40780, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7730 - precision: 0.7600 - recall: 0.7980 - f1_score: 0.7785 - val_loss: 0.4078 - val_accuracy: 0.8600 - val_precision: 0.8309 - val_recall: 0.9040 - val_f1_score: 0.8659 - lr: 8.0000e-04\nEpoch 12/200\n19/32 [================>.............] - ETA: 0s - loss: 0.4467 - accuracy: 0.7796 - precision: 0.7732 - recall: 0.7679 - f1_score: 0.7705\nEpoch 12: val_loss improved from 0.40780 to 0.39106, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7910 - precision: 0.7963 - recall: 0.7820 - f1_score: 0.7891 - val_loss: 0.3911 - val_accuracy: 0.8600 - val_precision: 0.8125 - val_recall: 0.9360 - val_f1_score: 0.8699 - lr: 8.0000e-04\nEpoch 13/200\n17/32 [==============>...............] - ETA: 0s - loss: 0.4607 - accuracy: 0.7739 - precision: 0.7292 - recall: 0.8713 - f1_score: 0.7940\nEpoch 13: val_loss improved from 0.39106 to 0.37955, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7880 - precision: 0.7609 - recall: 0.8400 - f1_score: 0.7985 - val_loss: 0.3796 - val_accuracy: 0.8640 - val_precision: 0.8273 - val_recall: 0.9200 - val_f1_score: 0.8712 - lr: 8.0000e-04\nEpoch 14/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.4271 - accuracy: 0.8142 - precision: 0.7742 - recall: 0.8664 - f1_score: 0.8177\nEpoch 14: val_loss improved from 0.37955 to 0.36516, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.8040 - precision: 0.7857 - recall: 0.8360 - f1_score: 0.8101 - val_loss: 0.3652 - val_accuracy: 0.8600 - val_precision: 0.8169 - val_recall: 0.9280 - val_f1_score: 0.8689 - lr: 8.0000e-04\nEpoch 15/200\n20/32 [=================>............] - ETA: 0s - loss: 0.4165 - accuracy: 0.8156 - precision: 0.7890 - recall: 0.8585 - f1_score: 0.8223\nEpoch 15: val_loss improved from 0.36516 to 0.35290, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8150 - precision: 0.7911 - recall: 0.8560 - f1_score: 0.8223 - val_loss: 0.3529 - val_accuracy: 0.8640 - val_precision: 0.8054 - val_recall: 0.9600 - val_f1_score: 0.8759 - lr: 8.0000e-04\nEpoch 16/200\n20/32 [=================>............] - ETA: 0s - loss: 0.3956 - accuracy: 0.8219 - precision: 0.8039 - recall: 0.8671 - f1_score: 0.8343\nEpoch 16: val_loss improved from 0.35290 to 0.34266, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8180 - precision: 0.7860 - recall: 0.8740 - f1_score: 0.8277 - val_loss: 0.3427 - val_accuracy: 0.8600 - val_precision: 0.8169 - val_recall: 0.9280 - val_f1_score: 0.8689 - lr: 8.0000e-04\nEpoch 17/200\n20/32 [=================>............] - ETA: 0s - loss: 0.4043 - accuracy: 0.8141 - precision: 0.7920 - recall: 0.8580 - f1_score: 0.8237\nEpoch 17: val_loss improved from 0.34266 to 0.33291, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8250 - precision: 0.8060 - recall: 0.8560 - f1_score: 0.8303 - val_loss: 0.3329 - val_accuracy: 0.8600 - val_precision: 0.8214 - val_recall: 0.9200 - val_f1_score: 0.8679 - lr: 8.0000e-04\nEpoch 18/200\n19/32 [================>.............] - ETA: 0s - loss: 0.4184 - accuracy: 0.8191 - precision: 0.7859 - recall: 0.8653 - f1_score: 0.8237\nEpoch 18: val_loss improved from 0.33291 to 0.32248, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8140 - precision: 0.7951 - recall: 0.8460 - f1_score: 0.8198 - val_loss: 0.3225 - val_accuracy: 0.8680 - val_precision: 0.8382 - val_recall: 0.9120 - val_f1_score: 0.8736 - lr: 8.0000e-04\nEpoch 19/200\n19/32 [================>.............] - ETA: 0s - loss: 0.4114 - accuracy: 0.7961 - precision: 0.7702 - recall: 0.8322 - f1_score: 0.8000\nEpoch 19: val_loss improved from 0.32248 to 0.31327, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8100 - precision: 0.7958 - recall: 0.8340 - f1_score: 0.8145 - val_loss: 0.3133 - val_accuracy: 0.8840 - val_precision: 0.8288 - val_recall: 0.9680 - val_f1_score: 0.8930 - lr: 8.0000e-04\nEpoch 20/200\n19/32 [================>.............] - ETA: 0s - loss: 0.3351 - accuracy: 0.8799 - precision: 0.8611 - recall: 0.9088 - f1_score: 0.8843\nEpoch 20: val_loss improved from 0.31327 to 0.30618, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3485 - accuracy: 0.8680 - precision: 0.8407 - recall: 0.9080 - f1_score: 0.8731 - val_loss: 0.3062 - val_accuracy: 0.8600 - val_precision: 0.8082 - val_recall: 0.9440 - val_f1_score: 0.8708 - lr: 8.0000e-04\nEpoch 21/200\n20/32 [=================>............] - ETA: 0s - loss: 0.3659 - accuracy: 0.8484 - precision: 0.8435 - recall: 0.8713 - f1_score: 0.8571\nEpoch 21: val_loss did not improve from 0.30618\n32/32 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8490 - precision: 0.8324 - recall: 0.8740 - f1_score: 0.8527 - val_loss: 0.3087 - val_accuracy: 0.8600 - val_precision: 0.8041 - val_recall: 0.9520 - val_f1_score: 0.8718 - lr: 8.0000e-04\nEpoch 22/200\n19/32 [================>.............] - ETA: 0s - loss: 0.3766 - accuracy: 0.8438 - precision: 0.8102 - recall: 0.8937 - f1_score: 0.8499\nEpoch 22: val_loss improved from 0.30618 to 0.29070, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8470 - precision: 0.8219 - recall: 0.8860 - f1_score: 0.8527 - val_loss: 0.2907 - val_accuracy: 0.8720 - val_precision: 0.8298 - val_recall: 0.9360 - val_f1_score: 0.8797 - lr: 8.0000e-04\nEpoch 23/200\n20/32 [=================>............] - ETA: 0s - loss: 0.3550 - accuracy: 0.8375 - precision: 0.8154 - recall: 0.8576 - f1_score: 0.8360\nEpoch 23: val_loss improved from 0.29070 to 0.28909, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8440 - precision: 0.8320 - recall: 0.8620 - f1_score: 0.8468 - val_loss: 0.2891 - val_accuracy: 0.9000 - val_precision: 0.8425 - val_recall: 0.9840 - val_f1_score: 0.9077 - lr: 8.0000e-04\nEpoch 24/200\n19/32 [================>.............] - ETA: 0s - loss: 0.3510 - accuracy: 0.8602 - precision: 0.8452 - recall: 0.8763 - f1_score: 0.8604\nEpoch 24: val_loss improved from 0.28909 to 0.28421, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8690 - precision: 0.8488 - recall: 0.8980 - f1_score: 0.8727 - val_loss: 0.2842 - val_accuracy: 0.8920 - val_precision: 0.8311 - val_recall: 0.9840 - val_f1_score: 0.9011 - lr: 8.0000e-04\nEpoch 25/200\n19/32 [================>.............] - ETA: 0s - loss: 0.3434 - accuracy: 0.8586 - precision: 0.8498 - recall: 0.8871 - f1_score: 0.8681\nEpoch 25: val_loss improved from 0.28421 to 0.28116, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8730 - precision: 0.8593 - recall: 0.8920 - f1_score: 0.8754 - val_loss: 0.2812 - val_accuracy: 0.8760 - val_precision: 0.8357 - val_recall: 0.9360 - val_f1_score: 0.8830 - lr: 8.0000e-04\nEpoch 26/200\n19/32 [================>.............] - ETA: 0s - loss: 0.3538 - accuracy: 0.8470 - precision: 0.8261 - recall: 0.8779 - f1_score: 0.8512\nEpoch 26: val_loss improved from 0.28116 to 0.26951, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3484 - accuracy: 0.8520 - precision: 0.8284 - recall: 0.8880 - f1_score: 0.8571 - val_loss: 0.2695 - val_accuracy: 0.8960 - val_precision: 0.8722 - val_recall: 0.9280 - val_f1_score: 0.8992 - lr: 8.0000e-04\nEpoch 27/200\n19/32 [================>.............] - ETA: 0s - loss: 0.3068 - accuracy: 0.8799 - precision: 0.8722 - recall: 0.8922 - f1_score: 0.8821\nEpoch 27: val_loss improved from 0.26951 to 0.26296, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.3121 - accuracy: 0.8670 - precision: 0.8563 - recall: 0.8820 - f1_score: 0.8690 - val_loss: 0.2630 - val_accuracy: 0.9080 - val_precision: 0.8592 - val_recall: 0.9760 - val_f1_score: 0.9139 - lr: 8.0000e-04\nEpoch 28/200\n20/32 [=================>............] - ETA: 0s - loss: 0.3296 - accuracy: 0.8641 - precision: 0.8352 - recall: 0.9184 - f1_score: 0.8748\nEpoch 28: val_loss did not improve from 0.26296\n32/32 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8650 - precision: 0.8386 - recall: 0.9040 - f1_score: 0.8701 - val_loss: 0.2633 - val_accuracy: 0.8840 - val_precision: 0.8478 - val_recall: 0.9360 - val_f1_score: 0.8897 - lr: 8.0000e-04\nEpoch 29/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.3209 - accuracy: 0.8837 - precision: 0.8559 - recall: 0.9375 - f1_score: 0.8948\nEpoch 29: val_loss did not improve from 0.26296\n32/32 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8830 - precision: 0.8540 - recall: 0.9240 - f1_score: 0.8876 - val_loss: 0.2632 - val_accuracy: 0.9160 - val_precision: 0.9062 - val_recall: 0.9280 - val_f1_score: 0.9170 - lr: 8.0000e-04\nEpoch 30/200\n20/32 [=================>............] - ETA: 0s - loss: 0.3123 - accuracy: 0.8828 - precision: 0.8567 - recall: 0.9228 - f1_score: 0.8886\nEpoch 30: val_loss improved from 0.26296 to 0.25116, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2987 - accuracy: 0.8800 - precision: 0.8626 - recall: 0.9040 - f1_score: 0.8828 - val_loss: 0.2512 - val_accuracy: 0.9200 - val_precision: 0.8889 - val_recall: 0.9600 - val_f1_score: 0.9231 - lr: 8.0000e-04\nEpoch 31/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2928 - accuracy: 0.8767 - precision: 0.8521 - recall: 0.8930 - f1_score: 0.8721\nEpoch 31: val_loss did not improve from 0.25116\n32/32 [==============================] - 0s 5ms/step - loss: 0.2953 - accuracy: 0.8790 - precision: 0.8708 - recall: 0.8900 - f1_score: 0.8803 - val_loss: 0.2552 - val_accuracy: 0.9000 - val_precision: 0.8378 - val_recall: 0.9920 - val_f1_score: 0.9084 - lr: 8.0000e-04\nEpoch 32/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2853 - accuracy: 0.8941 - precision: 0.8820 - recall: 0.9150 - f1_score: 0.8982\nEpoch 32: val_loss did not improve from 0.25116\n32/32 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.8760 - precision: 0.8481 - recall: 0.9160 - f1_score: 0.8808 - val_loss: 0.2531 - val_accuracy: 0.9160 - val_precision: 0.8824 - val_recall: 0.9600 - val_f1_score: 0.9195 - lr: 8.0000e-04\nEpoch 33/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2939 - accuracy: 0.8750 - precision: 0.8581 - recall: 0.8926 - f1_score: 0.8750\nEpoch 33: val_loss improved from 0.25116 to 0.24190, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2905 - accuracy: 0.8770 - precision: 0.8646 - recall: 0.8940 - f1_score: 0.8791 - val_loss: 0.2419 - val_accuracy: 0.9120 - val_precision: 0.8652 - val_recall: 0.9760 - val_f1_score: 0.9173 - lr: 8.0000e-04\nEpoch 34/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2995 - accuracy: 0.8750 - precision: 0.8596 - recall: 0.9063 - f1_score: 0.8824\nEpoch 34: val_loss improved from 0.24190 to 0.23816, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2976 - accuracy: 0.8750 - precision: 0.8544 - recall: 0.9040 - f1_score: 0.8785 - val_loss: 0.2382 - val_accuracy: 0.9000 - val_precision: 0.8378 - val_recall: 0.9920 - val_f1_score: 0.9084 - lr: 8.0000e-04\nEpoch 35/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2970 - accuracy: 0.8819 - precision: 0.8515 - recall: 0.9181 - f1_score: 0.8836\nEpoch 35: val_loss did not improve from 0.23816\n32/32 [==============================] - 0s 5ms/step - loss: 0.2925 - accuracy: 0.8830 - precision: 0.8662 - recall: 0.9060 - f1_score: 0.8856 - val_loss: 0.2394 - val_accuracy: 0.9080 - val_precision: 0.8493 - val_recall: 0.9920 - val_f1_score: 0.9151 - lr: 8.0000e-04\nEpoch 36/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2717 - accuracy: 0.8964 - precision: 0.8868 - recall: 0.9126 - f1_score: 0.8995\nEpoch 36: val_loss improved from 0.23816 to 0.22768, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2700 - accuracy: 0.8910 - precision: 0.8781 - recall: 0.9080 - f1_score: 0.8928 - val_loss: 0.2277 - val_accuracy: 0.9160 - val_precision: 0.9000 - val_recall: 0.9360 - val_f1_score: 0.9176 - lr: 8.0000e-04\nEpoch 37/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2822 - accuracy: 0.8832 - precision: 0.8793 - recall: 0.8987 - f1_score: 0.8889\nEpoch 37: val_loss improved from 0.22768 to 0.22566, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.8920 - precision: 0.8670 - recall: 0.9260 - f1_score: 0.8956 - val_loss: 0.2257 - val_accuracy: 0.9200 - val_precision: 0.8947 - val_recall: 0.9520 - val_f1_score: 0.9225 - lr: 8.0000e-04\nEpoch 38/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2859 - accuracy: 0.8914 - precision: 0.8825 - recall: 0.9055 - f1_score: 0.8939\nEpoch 38: val_loss did not improve from 0.22566\n32/32 [==============================] - 0s 5ms/step - loss: 0.2850 - accuracy: 0.8870 - precision: 0.8728 - recall: 0.9060 - f1_score: 0.8891 - val_loss: 0.2358 - val_accuracy: 0.9120 - val_precision: 0.8815 - val_recall: 0.9520 - val_f1_score: 0.9154 - lr: 8.0000e-04\nEpoch 39/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2566 - accuracy: 0.9128 - precision: 0.9061 - recall: 0.9211 - f1_score: 0.9135\nEpoch 39: val_loss did not improve from 0.22566\n32/32 [==============================] - 0s 5ms/step - loss: 0.2718 - accuracy: 0.8990 - precision: 0.8889 - recall: 0.9120 - f1_score: 0.9003 - val_loss: 0.2272 - val_accuracy: 0.9080 - val_precision: 0.8864 - val_recall: 0.9360 - val_f1_score: 0.9105 - lr: 8.0000e-04\nEpoch 40/200\n19/32 [================>.............] - ETA: 0s - loss: 0.3002 - accuracy: 0.8766 - precision: 0.8484 - recall: 0.9038 - f1_score: 0.8752\nEpoch 40: val_loss did not improve from 0.22566\n32/32 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.8800 - precision: 0.8682 - recall: 0.8960 - f1_score: 0.8819 - val_loss: 0.2404 - val_accuracy: 0.9000 - val_precision: 0.8378 - val_recall: 0.9920 - val_f1_score: 0.9084 - lr: 8.0000e-04\nEpoch 41/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2724 - accuracy: 0.8931 - precision: 0.8653 - recall: 0.9353 - f1_score: 0.8989\nEpoch 41: val_loss improved from 0.22566 to 0.22174, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2598 - accuracy: 0.8990 - precision: 0.8688 - recall: 0.9400 - f1_score: 0.9030 - val_loss: 0.2217 - val_accuracy: 0.9200 - val_precision: 0.9070 - val_recall: 0.9360 - val_f1_score: 0.9213 - lr: 8.0000e-04\nEpoch 42/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2375 - accuracy: 0.9125 - precision: 0.9108 - recall: 0.9164 - f1_score: 0.9136\nEpoch 42: val_loss did not improve from 0.22174\n32/32 [==============================] - 0s 5ms/step - loss: 0.2543 - accuracy: 0.9050 - precision: 0.8917 - recall: 0.9220 - f1_score: 0.9066 - val_loss: 0.2251 - val_accuracy: 0.9240 - val_precision: 0.8732 - val_recall: 0.9920 - val_f1_score: 0.9288 - lr: 8.0000e-04\nEpoch 43/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2463 - accuracy: 0.9062 - precision: 0.8961 - recall: 0.9262 - f1_score: 0.9109\nEpoch 43: val_loss improved from 0.22174 to 0.21547, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2631 - accuracy: 0.8970 - precision: 0.8781 - recall: 0.9220 - f1_score: 0.8995 - val_loss: 0.2155 - val_accuracy: 0.9240 - val_precision: 0.9206 - val_recall: 0.9280 - val_f1_score: 0.9243 - lr: 8.0000e-04\nEpoch 44/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2543 - accuracy: 0.8984 - precision: 0.8710 - recall: 0.9340 - f1_score: 0.9014\nEpoch 44: val_loss improved from 0.21547 to 0.20641, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2551 - accuracy: 0.8990 - precision: 0.8771 - recall: 0.9280 - f1_score: 0.9018 - val_loss: 0.2064 - val_accuracy: 0.9280 - val_precision: 0.9023 - val_recall: 0.9600 - val_f1_score: 0.9302 - lr: 8.0000e-04\nEpoch 45/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2332 - accuracy: 0.9016 - precision: 0.8970 - recall: 0.9108 - f1_score: 0.9038\nEpoch 45: val_loss improved from 0.20641 to 0.20641, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2411 - accuracy: 0.9020 - precision: 0.8778 - recall: 0.9340 - f1_score: 0.9050 - val_loss: 0.2064 - val_accuracy: 0.9160 - val_precision: 0.8881 - val_recall: 0.9520 - val_f1_score: 0.9189 - lr: 8.0000e-04\nEpoch 46/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2365 - accuracy: 0.9109 - precision: 0.9000 - recall: 0.9301 - f1_score: 0.9148\nEpoch 46: val_loss improved from 0.20641 to 0.19762, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2331 - accuracy: 0.9170 - precision: 0.9096 - recall: 0.9260 - f1_score: 0.9177 - val_loss: 0.1976 - val_accuracy: 0.9400 - val_precision: 0.9508 - val_recall: 0.9280 - val_f1_score: 0.9393 - lr: 8.0000e-04\nEpoch 47/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2387 - accuracy: 0.8984 - precision: 0.8943 - recall: 0.9080 - f1_score: 0.9011\nEpoch 47: val_loss did not improve from 0.19762\n32/32 [==============================] - 0s 5ms/step - loss: 0.2460 - accuracy: 0.8990 - precision: 0.8874 - recall: 0.9140 - f1_score: 0.9005 - val_loss: 0.2012 - val_accuracy: 0.9360 - val_precision: 0.8978 - val_recall: 0.9840 - val_f1_score: 0.9389 - lr: 8.0000e-04\nEpoch 48/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2496 - accuracy: 0.8947 - precision: 0.8822 - recall: 0.9211 - f1_score: 0.9012\nEpoch 48: val_loss improved from 0.19762 to 0.19734, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2510 - accuracy: 0.8960 - precision: 0.8653 - recall: 0.9380 - f1_score: 0.9002 - val_loss: 0.1973 - val_accuracy: 0.9320 - val_precision: 0.9286 - val_recall: 0.9360 - val_f1_score: 0.9323 - lr: 8.0000e-04\nEpoch 49/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2718 - accuracy: 0.9030 - precision: 0.9037 - recall: 0.9007 - f1_score: 0.9022\nEpoch 49: val_loss did not improve from 0.19734\n32/32 [==============================] - 0s 5ms/step - loss: 0.2589 - accuracy: 0.9030 - precision: 0.8959 - recall: 0.9120 - f1_score: 0.9039 - val_loss: 0.2110 - val_accuracy: 0.9360 - val_precision: 0.8921 - val_recall: 0.9920 - val_f1_score: 0.9394 - lr: 8.0000e-04\nEpoch 50/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2478 - accuracy: 0.8958 - precision: 0.8645 - recall: 0.9371 - f1_score: 0.8993\nEpoch 50: val_loss did not improve from 0.19734\n32/32 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9010 - precision: 0.8776 - recall: 0.9320 - f1_score: 0.9040 - val_loss: 0.2034 - val_accuracy: 0.9320 - val_precision: 0.9030 - val_recall: 0.9680 - val_f1_score: 0.9344 - lr: 8.0000e-04\nEpoch 51/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2627 - accuracy: 0.8785 - precision: 0.8361 - recall: 0.9273 - f1_score: 0.8793\nEpoch 51: val_loss improved from 0.19734 to 0.19705, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2414 - accuracy: 0.8980 - precision: 0.8658 - recall: 0.9420 - f1_score: 0.9023 - val_loss: 0.1970 - val_accuracy: 0.9440 - val_precision: 0.9173 - val_recall: 0.9760 - val_f1_score: 0.9457 - lr: 8.0000e-04\nEpoch 52/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2269 - accuracy: 0.9167 - precision: 0.8962 - recall: 0.9500 - f1_score: 0.9223\nEpoch 52: val_loss did not improve from 0.19705\n32/32 [==============================] - 0s 5ms/step - loss: 0.2397 - accuracy: 0.9080 - precision: 0.8878 - recall: 0.9340 - f1_score: 0.9103 - val_loss: 0.1998 - val_accuracy: 0.9360 - val_precision: 0.9431 - val_recall: 0.9280 - val_f1_score: 0.9355 - lr: 8.0000e-04\nEpoch 53/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2186 - accuracy: 0.9219 - precision: 0.8938 - recall: 0.9558 - f1_score: 0.9238\nEpoch 53: val_loss improved from 0.19705 to 0.19060, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2283 - accuracy: 0.9210 - precision: 0.8949 - recall: 0.9540 - f1_score: 0.9235 - val_loss: 0.1906 - val_accuracy: 0.9480 - val_precision: 0.9516 - val_recall: 0.9440 - val_f1_score: 0.9478 - lr: 8.0000e-04\nEpoch 54/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2408 - accuracy: 0.9095 - precision: 0.8952 - recall: 0.9276 - f1_score: 0.9111\nEpoch 54: val_loss did not improve from 0.19060\n32/32 [==============================] - 0s 5ms/step - loss: 0.2217 - accuracy: 0.9190 - precision: 0.9084 - recall: 0.9320 - f1_score: 0.9200 - val_loss: 0.1975 - val_accuracy: 0.9360 - val_precision: 0.9098 - val_recall: 0.9680 - val_f1_score: 0.9380 - lr: 8.0000e-04\nEpoch 55/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2208 - accuracy: 0.9167 - precision: 0.9121 - recall: 0.9302 - f1_score: 0.9211\nEpoch 55: val_loss improved from 0.19060 to 0.18640, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2420 - accuracy: 0.9100 - precision: 0.8912 - recall: 0.9340 - f1_score: 0.9121 - val_loss: 0.1864 - val_accuracy: 0.9400 - val_precision: 0.9297 - val_recall: 0.9520 - val_f1_score: 0.9407 - lr: 8.0000e-04\nEpoch 56/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2206 - accuracy: 0.9178 - precision: 0.9088 - recall: 0.9269 - f1_score: 0.9178\nEpoch 56: val_loss did not improve from 0.18640\n32/32 [==============================] - 0s 5ms/step - loss: 0.2325 - accuracy: 0.9090 - precision: 0.9018 - recall: 0.9180 - f1_score: 0.9098 - val_loss: 0.2036 - val_accuracy: 0.9240 - val_precision: 0.8897 - val_recall: 0.9680 - val_f1_score: 0.9272 - lr: 8.0000e-04\nEpoch 57/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2447 - accuracy: 0.9047 - precision: 0.8750 - recall: 0.9436 - f1_score: 0.9080\nEpoch 57: val_loss did not improve from 0.18640\n32/32 [==============================] - 0s 5ms/step - loss: 0.2445 - accuracy: 0.8980 - precision: 0.8741 - recall: 0.9300 - f1_score: 0.9012 - val_loss: 0.1882 - val_accuracy: 0.9480 - val_precision: 0.9242 - val_recall: 0.9760 - val_f1_score: 0.9494 - lr: 8.0000e-04\nEpoch 58/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2115 - accuracy: 0.9312 - precision: 0.9196 - recall: 0.9479 - f1_score: 0.9335\nEpoch 58: val_loss did not improve from 0.18640\n32/32 [==============================] - 0s 5ms/step - loss: 0.2282 - accuracy: 0.9210 - precision: 0.9010 - recall: 0.9460 - f1_score: 0.9229 - val_loss: 0.1867 - val_accuracy: 0.9560 - val_precision: 0.9318 - val_recall: 0.9840 - val_f1_score: 0.9572 - lr: 8.0000e-04\nEpoch 59/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2170 - accuracy: 0.9187 - precision: 0.9049 - recall: 0.9335 - f1_score: 0.9190\nEpoch 59: val_loss did not improve from 0.18640\n32/32 [==============================] - 0s 5ms/step - loss: 0.2228 - accuracy: 0.9130 - precision: 0.9089 - recall: 0.9180 - f1_score: 0.9134 - val_loss: 0.1982 - val_accuracy: 0.9440 - val_precision: 0.9051 - val_recall: 0.9920 - val_f1_score: 0.9466 - lr: 8.0000e-04\nEpoch 60/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2346 - accuracy: 0.9172 - precision: 0.8839 - recall: 0.9630 - f1_score: 0.9217\nEpoch 60: val_loss did not improve from 0.18640\n32/32 [==============================] - 0s 4ms/step - loss: 0.2179 - accuracy: 0.9230 - precision: 0.8909 - recall: 0.9640 - f1_score: 0.9260 - val_loss: 0.1980 - val_accuracy: 0.9400 - val_precision: 0.9231 - val_recall: 0.9600 - val_f1_score: 0.9412 - lr: 8.0000e-04\nEpoch 61/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2152 - accuracy: 0.9141 - precision: 0.8915 - recall: 0.9441 - f1_score: 0.9170\nEpoch 61: val_loss improved from 0.18640 to 0.18612, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2225 - accuracy: 0.9130 - precision: 0.8904 - recall: 0.9420 - f1_score: 0.9155 - val_loss: 0.1861 - val_accuracy: 0.9480 - val_precision: 0.9308 - val_recall: 0.9680 - val_f1_score: 0.9490 - lr: 8.0000e-04\nEpoch 62/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2245 - accuracy: 0.9172 - precision: 0.9062 - recall: 0.9265 - f1_score: 0.9163\nEpoch 62: val_loss improved from 0.18612 to 0.18455, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2208 - accuracy: 0.9200 - precision: 0.9086 - recall: 0.9340 - f1_score: 0.9211 - val_loss: 0.1846 - val_accuracy: 0.9520 - val_precision: 0.9313 - val_recall: 0.9760 - val_f1_score: 0.9531 - lr: 8.0000e-04\nEpoch 63/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2397 - accuracy: 0.9046 - precision: 0.8840 - recall: 0.9307 - f1_score: 0.9068\nEpoch 63: val_loss improved from 0.18455 to 0.17867, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2297 - accuracy: 0.9040 - precision: 0.8885 - recall: 0.9240 - f1_score: 0.9059 - val_loss: 0.1787 - val_accuracy: 0.9440 - val_precision: 0.9173 - val_recall: 0.9760 - val_f1_score: 0.9457 - lr: 8.0000e-04\nEpoch 64/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2206 - accuracy: 0.9079 - precision: 0.8857 - recall: 0.9331 - f1_score: 0.9088\nEpoch 64: val_loss improved from 0.17867 to 0.17661, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2005 - accuracy: 0.9220 - precision: 0.9073 - recall: 0.9400 - f1_score: 0.9234 - val_loss: 0.1766 - val_accuracy: 0.9480 - val_precision: 0.9444 - val_recall: 0.9520 - val_f1_score: 0.9482 - lr: 8.0000e-04\nEpoch 65/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1904 - accuracy: 0.9234 - precision: 0.9022 - recall: 0.9408 - f1_score: 0.9211\nEpoch 65: val_loss did not improve from 0.17661\n32/32 [==============================] - 0s 5ms/step - loss: 0.1932 - accuracy: 0.9210 - precision: 0.8979 - recall: 0.9500 - f1_score: 0.9232 - val_loss: 0.1872 - val_accuracy: 0.9320 - val_precision: 0.8857 - val_recall: 0.9920 - val_f1_score: 0.9358 - lr: 8.0000e-04\nEpoch 66/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1852 - accuracy: 0.9219 - precision: 0.9032 - recall: 0.9477 - f1_score: 0.9249\nEpoch 66: val_loss improved from 0.17661 to 0.16856, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1862 - accuracy: 0.9260 - precision: 0.9128 - recall: 0.9420 - f1_score: 0.9272 - val_loss: 0.1686 - val_accuracy: 0.9520 - val_precision: 0.9313 - val_recall: 0.9760 - val_f1_score: 0.9531 - lr: 8.0000e-04\nEpoch 67/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1961 - accuracy: 0.9141 - precision: 0.8798 - recall: 0.9554 - f1_score: 0.9160\nEpoch 67: val_loss did not improve from 0.16856\n32/32 [==============================] - 0s 5ms/step - loss: 0.2068 - accuracy: 0.9140 - precision: 0.8950 - recall: 0.9380 - f1_score: 0.9160 - val_loss: 0.1710 - val_accuracy: 0.9440 - val_precision: 0.9051 - val_recall: 0.9920 - val_f1_score: 0.9466 - lr: 8.0000e-04\nEpoch 68/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2057 - accuracy: 0.9115 - precision: 0.8867 - recall: 0.9448 - f1_score: 0.9149\nEpoch 68: val_loss did not improve from 0.16856\n32/32 [==============================] - 0s 5ms/step - loss: 0.2088 - accuracy: 0.9140 - precision: 0.8876 - recall: 0.9480 - f1_score: 0.9168 - val_loss: 0.1758 - val_accuracy: 0.9480 - val_precision: 0.9444 - val_recall: 0.9520 - val_f1_score: 0.9482 - lr: 8.0000e-04\nEpoch 69/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2020 - accuracy: 0.9236 - precision: 0.9097 - recall: 0.9463 - f1_score: 0.9276\nEpoch 69: val_loss did not improve from 0.16856\n32/32 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9240 - precision: 0.9061 - recall: 0.9460 - f1_score: 0.9256 - val_loss: 0.1738 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 8.0000e-04\nEpoch 70/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1930 - accuracy: 0.9178 - precision: 0.9114 - recall: 0.9290 - f1_score: 0.9201\nEpoch 70: val_loss did not improve from 0.16856\n32/32 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9220 - precision: 0.9089 - recall: 0.9380 - f1_score: 0.9232 - val_loss: 0.1691 - val_accuracy: 0.9520 - val_precision: 0.9380 - val_recall: 0.9680 - val_f1_score: 0.9528 - lr: 8.0000e-04\nEpoch 71/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1998 - accuracy: 0.9211 - precision: 0.9180 - recall: 0.9241 - f1_score: 0.9211\nEpoch 71: val_loss improved from 0.16856 to 0.16666, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.2062 - accuracy: 0.9190 - precision: 0.9084 - recall: 0.9320 - f1_score: 0.9200 - val_loss: 0.1667 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 8.0000e-04\nEpoch 72/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.2242 - accuracy: 0.9201 - precision: 0.8930 - recall: 0.9502 - f1_score: 0.9207\nEpoch 72: val_loss did not improve from 0.16666\n32/32 [==============================] - 0s 5ms/step - loss: 0.2279 - accuracy: 0.9180 - precision: 0.8943 - recall: 0.9480 - f1_score: 0.9204 - val_loss: 0.1733 - val_accuracy: 0.9560 - val_precision: 0.9254 - val_recall: 0.9920 - val_f1_score: 0.9575 - lr: 8.0000e-04\nEpoch 73/200\n20/32 [=================>............] - ETA: 0s - loss: 0.2037 - accuracy: 0.9187 - precision: 0.8926 - recall: 0.9448 - f1_score: 0.9180\nEpoch 73: val_loss did not improve from 0.16666\n32/32 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9270 - precision: 0.9082 - recall: 0.9500 - f1_score: 0.9286 - val_loss: 0.1679 - val_accuracy: 0.9520 - val_precision: 0.9313 - val_recall: 0.9760 - val_f1_score: 0.9531 - lr: 8.0000e-04\nEpoch 74/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1801 - accuracy: 0.9326 - precision: 0.9103 - recall: 0.9562 - f1_score: 0.9327\nEpoch 74: val_loss did not improve from 0.16666\n32/32 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.9370 - precision: 0.9194 - recall: 0.9580 - f1_score: 0.9383 - val_loss: 0.1691 - val_accuracy: 0.9600 - val_precision: 0.9389 - val_recall: 0.9840 - val_f1_score: 0.9609 - lr: 8.0000e-04\nEpoch 75/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1798 - accuracy: 0.9340 - precision: 0.9153 - recall: 0.9590 - f1_score: 0.9367\nEpoch 75: val_loss did not improve from 0.16666\n32/32 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9350 - precision: 0.9191 - recall: 0.9540 - f1_score: 0.9362 - val_loss: 0.1667 - val_accuracy: 0.9440 - val_precision: 0.9302 - val_recall: 0.9600 - val_f1_score: 0.9449 - lr: 8.0000e-04\nEpoch 76/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1673 - accuracy: 0.9427 - precision: 0.9301 - recall: 0.9534 - f1_score: 0.9416\nEpoch 76: val_loss improved from 0.16666 to 0.16619, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1911 - accuracy: 0.9360 - precision: 0.9208 - recall: 0.9540 - f1_score: 0.9371 - val_loss: 0.1662 - val_accuracy: 0.9520 - val_precision: 0.9380 - val_recall: 0.9680 - val_f1_score: 0.9528 - lr: 8.0000e-04\nEpoch 77/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1737 - accuracy: 0.9359 - precision: 0.9083 - recall: 0.9643 - f1_score: 0.9354\nEpoch 77: val_loss improved from 0.16619 to 0.16119, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1755 - accuracy: 0.9340 - precision: 0.9173 - recall: 0.9540 - f1_score: 0.9353 - val_loss: 0.1612 - val_accuracy: 0.9520 - val_precision: 0.9313 - val_recall: 0.9760 - val_f1_score: 0.9531 - lr: 8.0000e-04\nEpoch 78/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1689 - accuracy: 0.9375 - precision: 0.9187 - recall: 0.9591 - f1_score: 0.9385\nEpoch 78: val_loss improved from 0.16119 to 0.15979, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 0.9390 - precision: 0.9149 - recall: 0.9680 - f1_score: 0.9407 - val_loss: 0.1598 - val_accuracy: 0.9520 - val_precision: 0.9313 - val_recall: 0.9760 - val_f1_score: 0.9531 - lr: 8.0000e-04\nEpoch 79/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1645 - accuracy: 0.9309 - precision: 0.9373 - recall: 0.9251 - f1_score: 0.9311\nEpoch 79: val_loss did not improve from 0.15979\n32/32 [==============================] - 0s 5ms/step - loss: 0.1828 - accuracy: 0.9270 - precision: 0.9211 - recall: 0.9340 - f1_score: 0.9275 - val_loss: 0.1621 - val_accuracy: 0.9440 - val_precision: 0.9051 - val_recall: 0.9920 - val_f1_score: 0.9466 - lr: 8.0000e-04\nEpoch 80/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1980 - accuracy: 0.9326 - precision: 0.9094 - recall: 0.9604 - f1_score: 0.9342\nEpoch 80: val_loss did not improve from 0.15979\n32/32 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.9300 - precision: 0.9087 - recall: 0.9560 - f1_score: 0.9318 - val_loss: 0.1602 - val_accuracy: 0.9440 - val_precision: 0.9370 - val_recall: 0.9520 - val_f1_score: 0.9444 - lr: 8.0000e-04\nEpoch 81/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1734 - accuracy: 0.9342 - precision: 0.9167 - recall: 0.9533 - f1_score: 0.9346\nEpoch 81: val_loss improved from 0.15979 to 0.15397, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1819 - accuracy: 0.9330 - precision: 0.9171 - recall: 0.9520 - f1_score: 0.9342 - val_loss: 0.1540 - val_accuracy: 0.9440 - val_precision: 0.9302 - val_recall: 0.9600 - val_f1_score: 0.9449 - lr: 8.0000e-04\nEpoch 82/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1984 - accuracy: 0.9194 - precision: 0.8954 - recall: 0.9510 - f1_score: 0.9223\nEpoch 82: val_loss did not improve from 0.15397\n32/32 [==============================] - 0s 5ms/step - loss: 0.1976 - accuracy: 0.9230 - precision: 0.8968 - recall: 0.9560 - f1_score: 0.9255 - val_loss: 0.1552 - val_accuracy: 0.9440 - val_precision: 0.9370 - val_recall: 0.9520 - val_f1_score: 0.9444 - lr: 8.0000e-04\nEpoch 83/200\n19/32 [================>.............] - ETA: 0s - loss: 0.2051 - accuracy: 0.9227 - precision: 0.9221 - recall: 0.9308 - f1_score: 0.9264\nEpoch 83: val_loss did not improve from 0.15397\n32/32 [==============================] - 0s 5ms/step - loss: 0.1940 - accuracy: 0.9250 - precision: 0.9110 - recall: 0.9420 - f1_score: 0.9263 - val_loss: 0.1555 - val_accuracy: 0.9400 - val_precision: 0.9365 - val_recall: 0.9440 - val_f1_score: 0.9402 - lr: 8.0000e-04\nEpoch 84/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1725 - accuracy: 0.9340 - precision: 0.9147 - recall: 0.9537 - f1_score: 0.9338\nEpoch 84: val_loss did not improve from 0.15397\n32/32 [==============================] - 0s 5ms/step - loss: 0.1748 - accuracy: 0.9310 - precision: 0.9152 - recall: 0.9500 - f1_score: 0.9323 - val_loss: 0.1576 - val_accuracy: 0.9440 - val_precision: 0.9237 - val_recall: 0.9680 - val_f1_score: 0.9453 - lr: 8.0000e-04\nEpoch 85/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1499 - accuracy: 0.9408 - precision: 0.9152 - recall: 0.9742 - f1_score: 0.9437\nEpoch 85: val_loss did not improve from 0.15397\n32/32 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9320 - precision: 0.9075 - recall: 0.9620 - f1_score: 0.9340 - val_loss: 0.1548 - val_accuracy: 0.9480 - val_precision: 0.9308 - val_recall: 0.9680 - val_f1_score: 0.9490 - lr: 8.0000e-04\nEpoch 86/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1577 - accuracy: 0.9539 - precision: 0.9484 - recall: 0.9608 - f1_score: 0.9545\nEpoch 86: val_loss did not improve from 0.15397\n32/32 [==============================] - 0s 5ms/step - loss: 0.1686 - accuracy: 0.9450 - precision: 0.9304 - recall: 0.9620 - f1_score: 0.9459 - val_loss: 0.1572 - val_accuracy: 0.9400 - val_precision: 0.9104 - val_recall: 0.9760 - val_f1_score: 0.9421 - lr: 8.0000e-04\nEpoch 87/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1573 - accuracy: 0.9375 - precision: 0.9367 - recall: 0.9367 - f1_score: 0.9367\nEpoch 87: val_loss did not improve from 0.15397\n32/32 [==============================] - 0s 5ms/step - loss: 0.1602 - accuracy: 0.9350 - precision: 0.9290 - recall: 0.9420 - f1_score: 0.9355 - val_loss: 0.1547 - val_accuracy: 0.9440 - val_precision: 0.9051 - val_recall: 0.9920 - val_f1_score: 0.9466 - lr: 8.0000e-04\nEpoch 88/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1511 - accuracy: 0.9457 - precision: 0.9396 - recall: 0.9599 - f1_score: 0.9496\nEpoch 88: val_loss improved from 0.15397 to 0.15110, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1649 - accuracy: 0.9400 - precision: 0.9247 - recall: 0.9580 - f1_score: 0.9411 - val_loss: 0.1511 - val_accuracy: 0.9640 - val_precision: 0.9531 - val_recall: 0.9760 - val_f1_score: 0.9644 - lr: 8.0000e-04\nEpoch 89/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1812 - accuracy: 0.9342 - precision: 0.9414 - recall: 0.9293 - f1_score: 0.9353\nEpoch 89: val_loss did not improve from 0.15110\n32/32 [==============================] - 0s 5ms/step - loss: 0.1753 - accuracy: 0.9370 - precision: 0.9344 - recall: 0.9400 - f1_score: 0.9372 - val_loss: 0.1525 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 8.0000e-04\nEpoch 90/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1875 - accuracy: 0.9276 - precision: 0.9068 - recall: 0.9542 - f1_score: 0.9299\nEpoch 90: val_loss improved from 0.15110 to 0.14570, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1881 - accuracy: 0.9270 - precision: 0.9114 - recall: 0.9460 - f1_score: 0.9284 - val_loss: 0.1457 - val_accuracy: 0.9560 - val_precision: 0.9385 - val_recall: 0.9760 - val_f1_score: 0.9569 - lr: 8.0000e-04\nEpoch 91/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1621 - accuracy: 0.9309 - precision: 0.9063 - recall: 0.9646 - f1_score: 0.9346\nEpoch 91: val_loss did not improve from 0.14570\n32/32 [==============================] - 0s 5ms/step - loss: 0.1790 - accuracy: 0.9260 - precision: 0.9034 - recall: 0.9540 - f1_score: 0.9280 - val_loss: 0.1528 - val_accuracy: 0.9400 - val_precision: 0.9365 - val_recall: 0.9440 - val_f1_score: 0.9402 - lr: 8.0000e-04\nEpoch 92/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1503 - accuracy: 0.9359 - precision: 0.9255 - recall: 0.9521 - f1_score: 0.9386\nEpoch 92: val_loss improved from 0.14570 to 0.14542, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1643 - accuracy: 0.9320 - precision: 0.9138 - recall: 0.9540 - f1_score: 0.9335 - val_loss: 0.1454 - val_accuracy: 0.9520 - val_precision: 0.9520 - val_recall: 0.9520 - val_f1_score: 0.9520 - lr: 8.0000e-04\nEpoch 93/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1969 - accuracy: 0.9184 - precision: 0.9107 - recall: 0.9266 - f1_score: 0.9185\nEpoch 93: val_loss did not improve from 0.14542\n32/32 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9290 - precision: 0.9198 - recall: 0.9400 - f1_score: 0.9298 - val_loss: 0.1535 - val_accuracy: 0.9480 - val_precision: 0.9118 - val_recall: 0.9920 - val_f1_score: 0.9502 - lr: 8.0000e-04\nEpoch 94/200\n30/32 [===========================>..] - ETA: 0s - loss: 0.1554 - accuracy: 0.9406 - precision: 0.9237 - recall: 0.9603 - f1_score: 0.9417\nEpoch 94: val_loss did not improve from 0.14542\n32/32 [==============================] - 0s 5ms/step - loss: 0.1587 - accuracy: 0.9380 - precision: 0.9244 - recall: 0.9540 - f1_score: 0.9390 - val_loss: 0.1485 - val_accuracy: 0.9480 - val_precision: 0.9516 - val_recall: 0.9440 - val_f1_score: 0.9478 - lr: 8.0000e-04\nEpoch 95/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1601 - accuracy: 0.9406 - precision: 0.9231 - recall: 0.9630 - f1_score: 0.9426\nEpoch 95: val_loss did not improve from 0.14542\n32/32 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9310 - precision: 0.9074 - recall: 0.9600 - f1_score: 0.9329 - val_loss: 0.1469 - val_accuracy: 0.9480 - val_precision: 0.9444 - val_recall: 0.9520 - val_f1_score: 0.9482 - lr: 8.0000e-04\nEpoch 96/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1655 - accuracy: 0.9326 - precision: 0.9299 - recall: 0.9389 - f1_score: 0.9344\nEpoch 96: val_loss did not improve from 0.14542\n32/32 [==============================] - 0s 5ms/step - loss: 0.1762 - accuracy: 0.9290 - precision: 0.9214 - recall: 0.9380 - f1_score: 0.9296 - val_loss: 0.1515 - val_accuracy: 0.9480 - val_precision: 0.9444 - val_recall: 0.9520 - val_f1_score: 0.9482 - lr: 8.0000e-04\nEpoch 97/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1698 - accuracy: 0.9424 - precision: 0.9395 - recall: 0.9486 - f1_score: 0.9440\nEpoch 97: val_loss did not improve from 0.14542\n32/32 [==============================] - 0s 5ms/step - loss: 0.1676 - accuracy: 0.9430 - precision: 0.9386 - recall: 0.9480 - f1_score: 0.9433 - val_loss: 0.1483 - val_accuracy: 0.9440 - val_precision: 0.9302 - val_recall: 0.9600 - val_f1_score: 0.9449 - lr: 8.0000e-04\nEpoch 98/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1796 - accuracy: 0.9260 - precision: 0.9079 - recall: 0.9470 - f1_score: 0.9271\nEpoch 98: val_loss did not improve from 0.14542\n32/32 [==============================] - 0s 5ms/step - loss: 0.1578 - accuracy: 0.9370 - precision: 0.9259 - recall: 0.9500 - f1_score: 0.9378 - val_loss: 0.1507 - val_accuracy: 0.9480 - val_precision: 0.9242 - val_recall: 0.9760 - val_f1_score: 0.9494 - lr: 8.0000e-04\nEpoch 99/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1499 - accuracy: 0.9358 - precision: 0.8960 - recall: 0.9780 - f1_score: 0.9352\nEpoch 99: val_loss improved from 0.14542 to 0.14336, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.9340 - precision: 0.9079 - recall: 0.9660 - f1_score: 0.9360 - val_loss: 0.1434 - val_accuracy: 0.9440 - val_precision: 0.9370 - val_recall: 0.9520 - val_f1_score: 0.9444 - lr: 8.0000e-04\nEpoch 100/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1723 - accuracy: 0.9243 - precision: 0.9233 - recall: 0.9293 - f1_score: 0.9263\nEpoch 100: val_loss improved from 0.14336 to 0.14230, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1829 - accuracy: 0.9250 - precision: 0.9175 - recall: 0.9340 - f1_score: 0.9257 - val_loss: 0.1423 - val_accuracy: 0.9440 - val_precision: 0.9302 - val_recall: 0.9600 - val_f1_score: 0.9449 - lr: 8.0000e-04\nEpoch 101/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1581 - accuracy: 0.9359 - precision: 0.9184 - recall: 0.9604 - f1_score: 0.9389\nEpoch 101: val_loss improved from 0.14230 to 0.13985, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1584 - accuracy: 0.9360 - precision: 0.9144 - recall: 0.9620 - f1_score: 0.9376 - val_loss: 0.1399 - val_accuracy: 0.9520 - val_precision: 0.9520 - val_recall: 0.9520 - val_f1_score: 0.9520 - lr: 8.0000e-04\nEpoch 102/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1774 - accuracy: 0.9359 - precision: 0.9184 - recall: 0.9560 - f1_score: 0.9368\nEpoch 102: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9350 - precision: 0.9207 - recall: 0.9520 - f1_score: 0.9361 - val_loss: 0.1562 - val_accuracy: 0.9480 - val_precision: 0.9444 - val_recall: 0.9520 - val_f1_score: 0.9482 - lr: 8.0000e-04\nEpoch 103/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1602 - accuracy: 0.9406 - precision: 0.9228 - recall: 0.9583 - f1_score: 0.9403\nEpoch 103: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9400 - precision: 0.9280 - recall: 0.9540 - f1_score: 0.9408 - val_loss: 0.1566 - val_accuracy: 0.9520 - val_precision: 0.9248 - val_recall: 0.9840 - val_f1_score: 0.9535 - lr: 8.0000e-04\nEpoch 104/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1415 - accuracy: 0.9457 - precision: 0.9238 - recall: 0.9700 - f1_score: 0.9463\nEpoch 104: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.9380 - precision: 0.9179 - recall: 0.9620 - f1_score: 0.9395 - val_loss: 0.1530 - val_accuracy: 0.9400 - val_precision: 0.9231 - val_recall: 0.9600 - val_f1_score: 0.9412 - lr: 8.0000e-04\nEpoch 105/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1512 - accuracy: 0.9547 - precision: 0.9399 - recall: 0.9674 - f1_score: 0.9535\nEpoch 105: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.9500 - precision: 0.9395 - recall: 0.9620 - f1_score: 0.9506 - val_loss: 0.1451 - val_accuracy: 0.9480 - val_precision: 0.9242 - val_recall: 0.9760 - val_f1_score: 0.9494 - lr: 8.0000e-04\nEpoch 106/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1317 - accuracy: 0.9549 - precision: 0.9371 - recall: 0.9759 - f1_score: 0.9561\nEpoch 106: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.9450 - precision: 0.9254 - recall: 0.9680 - f1_score: 0.9462 - val_loss: 0.1463 - val_accuracy: 0.9480 - val_precision: 0.9308 - val_recall: 0.9680 - val_f1_score: 0.9490 - lr: 8.0000e-04\nEpoch 107/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1367 - accuracy: 0.9444 - precision: 0.9263 - recall: 0.9698 - f1_score: 0.9475\nEpoch 107: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1385 - accuracy: 0.9480 - precision: 0.9242 - recall: 0.9760 - f1_score: 0.9494 - val_loss: 0.1403 - val_accuracy: 0.9520 - val_precision: 0.9380 - val_recall: 0.9680 - val_f1_score: 0.9528 - lr: 8.0000e-04\nEpoch 108/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1428 - accuracy: 0.9539 - precision: 0.9508 - recall: 0.9626 - f1_score: 0.9567\nEpoch 108: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.9420 - precision: 0.9234 - recall: 0.9640 - f1_score: 0.9432 - val_loss: 0.1491 - val_accuracy: 0.9440 - val_precision: 0.9302 - val_recall: 0.9600 - val_f1_score: 0.9449 - lr: 8.0000e-04\nEpoch 109/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1451 - accuracy: 0.9462 - precision: 0.9336 - recall: 0.9623 - f1_score: 0.9477\nEpoch 109: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.9430 - precision: 0.9284 - recall: 0.9600 - f1_score: 0.9440 - val_loss: 0.1441 - val_accuracy: 0.9520 - val_precision: 0.9520 - val_recall: 0.9520 - val_f1_score: 0.9520 - lr: 8.0000e-04\nEpoch 110/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1356 - accuracy: 0.9457 - precision: 0.9455 - recall: 0.9486 - f1_score: 0.9470\nEpoch 110: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1396 - accuracy: 0.9410 - precision: 0.9366 - recall: 0.9460 - f1_score: 0.9413 - val_loss: 0.1575 - val_accuracy: 0.9520 - val_precision: 0.9185 - val_recall: 0.9920 - val_f1_score: 0.9538 - lr: 8.0000e-04\nEpoch 111/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1587 - accuracy: 0.9410 - precision: 0.9283 - recall: 0.9544 - f1_score: 0.9412\nEpoch 111: ReduceLROnPlateau reducing learning rate to 0.00039999998989515007.\n\nEpoch 111: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1613 - accuracy: 0.9380 - precision: 0.9244 - recall: 0.9540 - f1_score: 0.9390 - val_loss: 0.1506 - val_accuracy: 0.9400 - val_precision: 0.9231 - val_recall: 0.9600 - val_f1_score: 0.9412 - lr: 8.0000e-04\nEpoch 112/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1609 - accuracy: 0.9344 - precision: 0.9358 - recall: 0.9358 - f1_score: 0.9358\nEpoch 112: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9380 - precision: 0.9294 - recall: 0.9480 - f1_score: 0.9386 - val_loss: 0.1512 - val_accuracy: 0.9360 - val_precision: 0.9160 - val_recall: 0.9600 - val_f1_score: 0.9375 - lr: 4.0000e-04\nEpoch 113/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1359 - accuracy: 0.9531 - precision: 0.9429 - recall: 0.9662 - f1_score: 0.9544\nEpoch 113: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1421 - accuracy: 0.9530 - precision: 0.9450 - recall: 0.9620 - f1_score: 0.9534 - val_loss: 0.1514 - val_accuracy: 0.9440 - val_precision: 0.9302 - val_recall: 0.9600 - val_f1_score: 0.9449 - lr: 4.0000e-04\nEpoch 114/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1467 - accuracy: 0.9453 - precision: 0.9333 - recall: 0.9595 - f1_score: 0.9462\nEpoch 114: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9450 - precision: 0.9337 - recall: 0.9580 - f1_score: 0.9457 - val_loss: 0.1484 - val_accuracy: 0.9520 - val_precision: 0.9380 - val_recall: 0.9680 - val_f1_score: 0.9528 - lr: 4.0000e-04\nEpoch 115/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1366 - accuracy: 0.9549 - precision: 0.9444 - recall: 0.9645 - f1_score: 0.9544\nEpoch 115: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9560 - precision: 0.9471 - recall: 0.9660 - f1_score: 0.9564 - val_loss: 0.1476 - val_accuracy: 0.9480 - val_precision: 0.9308 - val_recall: 0.9680 - val_f1_score: 0.9490 - lr: 4.0000e-04\nEpoch 116/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1314 - accuracy: 0.9547 - precision: 0.9290 - recall: 0.9843 - f1_score: 0.9559\nEpoch 116: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.9480 - precision: 0.9242 - recall: 0.9760 - f1_score: 0.9494 - val_loss: 0.1410 - val_accuracy: 0.9560 - val_precision: 0.9385 - val_recall: 0.9760 - val_f1_score: 0.9569 - lr: 4.0000e-04\nEpoch 117/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1298 - accuracy: 0.9556 - precision: 0.9487 - recall: 0.9642 - f1_score: 0.9564\nEpoch 117: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.9510 - precision: 0.9396 - recall: 0.9640 - f1_score: 0.9516 - val_loss: 0.1421 - val_accuracy: 0.9520 - val_precision: 0.9380 - val_recall: 0.9680 - val_f1_score: 0.9528 - lr: 4.0000e-04\nEpoch 118/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1391 - accuracy: 0.9424 - precision: 0.9238 - recall: 0.9636 - f1_score: 0.9433\nEpoch 118: val_loss did not improve from 0.13985\n32/32 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9330 - precision: 0.9204 - recall: 0.9480 - f1_score: 0.9340 - val_loss: 0.1417 - val_accuracy: 0.9480 - val_precision: 0.9308 - val_recall: 0.9680 - val_f1_score: 0.9490 - lr: 4.0000e-04\nEpoch 119/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1387 - accuracy: 0.9406 - precision: 0.9190 - recall: 0.9609 - f1_score: 0.9395\nEpoch 119: val_loss improved from 0.13985 to 0.13911, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.9360 - precision: 0.9241 - recall: 0.9500 - f1_score: 0.9369 - val_loss: 0.1391 - val_accuracy: 0.9520 - val_precision: 0.9449 - val_recall: 0.9600 - val_f1_score: 0.9524 - lr: 4.0000e-04\nEpoch 120/200\n21/32 [==================>...........] - ETA: 0s - loss: 0.1350 - accuracy: 0.9539 - precision: 0.9420 - recall: 0.9673 - f1_score: 0.9545\nEpoch 120: val_loss did not improve from 0.13911\n32/32 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9550 - precision: 0.9417 - recall: 0.9700 - f1_score: 0.9557 - val_loss: 0.1417 - val_accuracy: 0.9600 - val_precision: 0.9457 - val_recall: 0.9760 - val_f1_score: 0.9606 - lr: 4.0000e-04\nEpoch 121/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1416 - accuracy: 0.9438 - precision: 0.9292 - recall: 0.9633 - f1_score: 0.9459\nEpoch 121: val_loss did not improve from 0.13911\n32/32 [==============================] - 0s 5ms/step - loss: 0.1461 - accuracy: 0.9390 - precision: 0.9246 - recall: 0.9560 - f1_score: 0.9400 - val_loss: 0.1431 - val_accuracy: 0.9520 - val_precision: 0.9313 - val_recall: 0.9760 - val_f1_score: 0.9531 - lr: 4.0000e-04\nEpoch 122/200\n21/32 [==================>...........] - ETA: 0s - loss: 0.1276 - accuracy: 0.9494 - precision: 0.9322 - recall: 0.9706 - f1_score: 0.9510\nEpoch 122: val_loss did not improve from 0.13911\n32/32 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9470 - precision: 0.9273 - recall: 0.9700 - f1_score: 0.9482 - val_loss: 0.1454 - val_accuracy: 0.9560 - val_precision: 0.9318 - val_recall: 0.9840 - val_f1_score: 0.9572 - lr: 4.0000e-04\nEpoch 123/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1499 - accuracy: 0.9441 - precision: 0.9344 - recall: 0.9532 - f1_score: 0.9437\nEpoch 123: val_loss did not improve from 0.13911\n32/32 [==============================] - 0s 5ms/step - loss: 0.1401 - accuracy: 0.9510 - precision: 0.9413 - recall: 0.9620 - f1_score: 0.9515 - val_loss: 0.1419 - val_accuracy: 0.9480 - val_precision: 0.9242 - val_recall: 0.9760 - val_f1_score: 0.9494 - lr: 4.0000e-04\nEpoch 124/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1369 - accuracy: 0.9474 - precision: 0.9279 - recall: 0.9748 - f1_score: 0.9508\nEpoch 124: val_loss did not improve from 0.13911\n32/32 [==============================] - 0s 5ms/step - loss: 0.1332 - accuracy: 0.9490 - precision: 0.9342 - recall: 0.9660 - f1_score: 0.9499 - val_loss: 0.1398 - val_accuracy: 0.9440 - val_precision: 0.9302 - val_recall: 0.9600 - val_f1_score: 0.9449 - lr: 4.0000e-04\nEpoch 125/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1087 - accuracy: 0.9622 - precision: 0.9527 - recall: 0.9742 - f1_score: 0.9633\nEpoch 125: val_loss improved from 0.13911 to 0.13855, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 0.9460 - precision: 0.9272 - recall: 0.9680 - f1_score: 0.9472 - val_loss: 0.1385 - val_accuracy: 0.9440 - val_precision: 0.9302 - val_recall: 0.9600 - val_f1_score: 0.9449 - lr: 4.0000e-04\nEpoch 126/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1323 - accuracy: 0.9484 - precision: 0.9281 - recall: 0.9674 - f1_score: 0.9474\nEpoch 126: val_loss improved from 0.13855 to 0.13496, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1391 - accuracy: 0.9440 - precision: 0.9302 - recall: 0.9600 - f1_score: 0.9449 - val_loss: 0.1350 - val_accuracy: 0.9480 - val_precision: 0.9375 - val_recall: 0.9600 - val_f1_score: 0.9486 - lr: 4.0000e-04\nEpoch 127/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1250 - accuracy: 0.9516 - precision: 0.9486 - recall: 0.9573 - f1_score: 0.9530\nEpoch 127: val_loss did not improve from 0.13496\n32/32 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9450 - precision: 0.9320 - recall: 0.9600 - f1_score: 0.9458 - val_loss: 0.1367 - val_accuracy: 0.9520 - val_precision: 0.9380 - val_recall: 0.9680 - val_f1_score: 0.9528 - lr: 4.0000e-04\nEpoch 128/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1541 - accuracy: 0.9391 - precision: 0.9391 - recall: 0.9421 - f1_score: 0.9406\nEpoch 128: val_loss did not improve from 0.13496\n32/32 [==============================] - 0s 5ms/step - loss: 0.1351 - accuracy: 0.9460 - precision: 0.9407 - recall: 0.9520 - f1_score: 0.9463 - val_loss: 0.1464 - val_accuracy: 0.9400 - val_precision: 0.9231 - val_recall: 0.9600 - val_f1_score: 0.9412 - lr: 4.0000e-04\nEpoch 129/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1305 - accuracy: 0.9578 - precision: 0.9386 - recall: 0.9817 - f1_score: 0.9596\nEpoch 129: val_loss did not improve from 0.13496\n32/32 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9510 - precision: 0.9328 - recall: 0.9720 - f1_score: 0.9520 - val_loss: 0.1380 - val_accuracy: 0.9480 - val_precision: 0.9375 - val_recall: 0.9600 - val_f1_score: 0.9486 - lr: 4.0000e-04\nEpoch 130/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1254 - accuracy: 0.9539 - precision: 0.9353 - recall: 0.9731 - f1_score: 0.9538\nEpoch 130: val_loss did not improve from 0.13496\n32/32 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9540 - precision: 0.9416 - recall: 0.9680 - f1_score: 0.9546 - val_loss: 0.1372 - val_accuracy: 0.9560 - val_precision: 0.9524 - val_recall: 0.9600 - val_f1_score: 0.9562 - lr: 4.0000e-04\nEpoch 131/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1407 - accuracy: 0.9457 - precision: 0.9391 - recall: 0.9544 - f1_score: 0.9467\nEpoch 131: val_loss did not improve from 0.13496\n32/32 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9460 - precision: 0.9390 - recall: 0.9540 - f1_score: 0.9464 - val_loss: 0.1418 - val_accuracy: 0.9560 - val_precision: 0.9385 - val_recall: 0.9760 - val_f1_score: 0.9569 - lr: 4.0000e-04\nEpoch 132/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1541 - accuracy: 0.9424 - precision: 0.9228 - recall: 0.9631 - f1_score: 0.9425\nEpoch 132: val_loss did not improve from 0.13496\n32/32 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.9460 - precision: 0.9355 - recall: 0.9580 - f1_score: 0.9466 - val_loss: 0.1420 - val_accuracy: 0.9600 - val_precision: 0.9457 - val_recall: 0.9760 - val_f1_score: 0.9606 - lr: 4.0000e-04\nEpoch 133/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1116 - accuracy: 0.9539 - precision: 0.9474 - recall: 0.9653 - f1_score: 0.9563\nEpoch 133: val_loss did not improve from 0.13496\n32/32 [==============================] - 0s 5ms/step - loss: 0.1267 - accuracy: 0.9570 - precision: 0.9472 - recall: 0.9680 - f1_score: 0.9575 - val_loss: 0.1369 - val_accuracy: 0.9560 - val_precision: 0.9385 - val_recall: 0.9760 - val_f1_score: 0.9569 - lr: 4.0000e-04\nEpoch 134/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1416 - accuracy: 0.9410 - precision: 0.9236 - recall: 0.9619 - f1_score: 0.9424\nEpoch 134: val_loss improved from 0.13496 to 0.13351, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1413 - accuracy: 0.9430 - precision: 0.9301 - recall: 0.9580 - f1_score: 0.9438 - val_loss: 0.1335 - val_accuracy: 0.9520 - val_precision: 0.9449 - val_recall: 0.9600 - val_f1_score: 0.9524 - lr: 4.0000e-04\nEpoch 135/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1664 - accuracy: 0.9358 - precision: 0.9153 - recall: 0.9574 - f1_score: 0.9359\nEpoch 135: val_loss improved from 0.13351 to 0.13326, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9480 - precision: 0.9324 - recall: 0.9660 - f1_score: 0.9489 - val_loss: 0.1333 - val_accuracy: 0.9520 - val_precision: 0.9520 - val_recall: 0.9520 - val_f1_score: 0.9520 - lr: 4.0000e-04\nEpoch 136/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1260 - accuracy: 0.9605 - precision: 0.9497 - recall: 0.9742 - f1_score: 0.9618\nEpoch 136: val_loss improved from 0.13326 to 0.13139, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9610 - precision: 0.9511 - recall: 0.9720 - f1_score: 0.9614 - val_loss: 0.1314 - val_accuracy: 0.9640 - val_precision: 0.9754 - val_recall: 0.9520 - val_f1_score: 0.9636 - lr: 4.0000e-04\nEpoch 137/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1315 - accuracy: 0.9539 - precision: 0.9503 - recall: 0.9567 - f1_score: 0.9535\nEpoch 137: val_loss did not improve from 0.13139\n32/32 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.9580 - precision: 0.9544 - recall: 0.9620 - f1_score: 0.9582 - val_loss: 0.1346 - val_accuracy: 0.9560 - val_precision: 0.9524 - val_recall: 0.9600 - val_f1_score: 0.9562 - lr: 4.0000e-04\nEpoch 138/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1525 - accuracy: 0.9375 - precision: 0.9211 - recall: 0.9524 - f1_score: 0.9365\nEpoch 138: val_loss improved from 0.13139 to 0.12450, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1345 - accuracy: 0.9480 - precision: 0.9324 - recall: 0.9660 - f1_score: 0.9489 - val_loss: 0.1245 - val_accuracy: 0.9600 - val_precision: 0.9600 - val_recall: 0.9600 - val_f1_score: 0.9600 - lr: 4.0000e-04\nEpoch 139/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1115 - accuracy: 0.9641 - precision: 0.9606 - recall: 0.9694 - f1_score: 0.9650\nEpoch 139: val_loss did not improve from 0.12450\n32/32 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9560 - precision: 0.9471 - recall: 0.9660 - f1_score: 0.9564 - val_loss: 0.1270 - val_accuracy: 0.9520 - val_precision: 0.9449 - val_recall: 0.9600 - val_f1_score: 0.9524 - lr: 4.0000e-04\nEpoch 140/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1508 - accuracy: 0.9441 - precision: 0.9297 - recall: 0.9604 - f1_score: 0.9448\nEpoch 140: val_loss improved from 0.12450 to 0.12410, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1375 - accuracy: 0.9510 - precision: 0.9379 - recall: 0.9660 - f1_score: 0.9517 - val_loss: 0.1241 - val_accuracy: 0.9560 - val_precision: 0.9524 - val_recall: 0.9600 - val_f1_score: 0.9562 - lr: 4.0000e-04\nEpoch 141/200\n21/32 [==================>...........] - ETA: 0s - loss: 0.1448 - accuracy: 0.9360 - precision: 0.9249 - recall: 0.9496 - f1_score: 0.9370\nEpoch 141: val_loss did not improve from 0.12410\n32/32 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9350 - precision: 0.9191 - recall: 0.9540 - f1_score: 0.9362 - val_loss: 0.1313 - val_accuracy: 0.9600 - val_precision: 0.9600 - val_recall: 0.9600 - val_f1_score: 0.9600 - lr: 4.0000e-04\nEpoch 142/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1336 - accuracy: 0.9500 - precision: 0.9410 - recall: 0.9589 - f1_score: 0.9498\nEpoch 142: val_loss did not improve from 0.12410\n32/32 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9500 - precision: 0.9344 - recall: 0.9680 - f1_score: 0.9509 - val_loss: 0.1296 - val_accuracy: 0.9560 - val_precision: 0.9524 - val_recall: 0.9600 - val_f1_score: 0.9562 - lr: 4.0000e-04\nEpoch 143/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1019 - accuracy: 0.9655 - precision: 0.9618 - recall: 0.9652 - f1_score: 0.9635\nEpoch 143: val_loss did not improve from 0.12410\n32/32 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9480 - precision: 0.9392 - recall: 0.9580 - f1_score: 0.9485 - val_loss: 0.1277 - val_accuracy: 0.9640 - val_precision: 0.9462 - val_recall: 0.9840 - val_f1_score: 0.9647 - lr: 4.0000e-04\nEpoch 144/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1009 - accuracy: 0.9578 - precision: 0.9498 - recall: 0.9650 - f1_score: 0.9573\nEpoch 144: val_loss did not improve from 0.12410\n32/32 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.9580 - precision: 0.9455 - recall: 0.9720 - f1_score: 0.9586 - val_loss: 0.1307 - val_accuracy: 0.9600 - val_precision: 0.9323 - val_recall: 0.9920 - val_f1_score: 0.9612 - lr: 4.0000e-04\nEpoch 145/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1175 - accuracy: 0.9563 - precision: 0.9346 - recall: 0.9772 - f1_score: 0.9554\nEpoch 145: val_loss did not improve from 0.12410\n32/32 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9490 - precision: 0.9376 - recall: 0.9620 - f1_score: 0.9497 - val_loss: 0.1263 - val_accuracy: 0.9640 - val_precision: 0.9531 - val_recall: 0.9760 - val_f1_score: 0.9644 - lr: 4.0000e-04\nEpoch 146/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1273 - accuracy: 0.9453 - precision: 0.9358 - recall: 0.9563 - f1_score: 0.9459\nEpoch 146: val_loss did not improve from 0.12410\n32/32 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9510 - precision: 0.9430 - recall: 0.9600 - f1_score: 0.9514 - val_loss: 0.1306 - val_accuracy: 0.9680 - val_precision: 0.9535 - val_recall: 0.9840 - val_f1_score: 0.9685 - lr: 4.0000e-04\nEpoch 147/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1275 - accuracy: 0.9539 - precision: 0.9425 - recall: 0.9672 - f1_score: 0.9547\nEpoch 147: val_loss improved from 0.12410 to 0.12315, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.9560 - precision: 0.9419 - recall: 0.9720 - f1_score: 0.9567 - val_loss: 0.1231 - val_accuracy: 0.9720 - val_precision: 0.9609 - val_recall: 0.9840 - val_f1_score: 0.9723 - lr: 4.0000e-04\nEpoch 148/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1064 - accuracy: 0.9605 - precision: 0.9417 - recall: 0.9798 - f1_score: 0.9604\nEpoch 148: val_loss did not improve from 0.12315\n32/32 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9610 - precision: 0.9424 - recall: 0.9820 - f1_score: 0.9618 - val_loss: 0.1257 - val_accuracy: 0.9640 - val_precision: 0.9677 - val_recall: 0.9600 - val_f1_score: 0.9639 - lr: 4.0000e-04\nEpoch 149/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1067 - accuracy: 0.9563 - precision: 0.9421 - recall: 0.9717 - f1_score: 0.9567\nEpoch 149: val_loss did not improve from 0.12315\n32/32 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9570 - precision: 0.9472 - recall: 0.9680 - f1_score: 0.9575 - val_loss: 0.1252 - val_accuracy: 0.9680 - val_precision: 0.9466 - val_recall: 0.9920 - val_f1_score: 0.9688 - lr: 4.0000e-04\nEpoch 150/200\n19/32 [================>.............] - ETA: 0s - loss: 0.0931 - accuracy: 0.9688 - precision: 0.9553 - recall: 0.9836 - f1_score: 0.9692\nEpoch 150: val_loss did not improve from 0.12315\n32/32 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9610 - precision: 0.9476 - recall: 0.9760 - f1_score: 0.9616 - val_loss: 0.1296 - val_accuracy: 0.9640 - val_precision: 0.9394 - val_recall: 0.9920 - val_f1_score: 0.9650 - lr: 4.0000e-04\nEpoch 151/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1254 - accuracy: 0.9531 - precision: 0.9556 - recall: 0.9556 - f1_score: 0.9556\nEpoch 151: val_loss did not improve from 0.12315\n32/32 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9500 - precision: 0.9344 - recall: 0.9680 - f1_score: 0.9509 - val_loss: 0.1380 - val_accuracy: 0.9600 - val_precision: 0.9323 - val_recall: 0.9920 - val_f1_score: 0.9612 - lr: 4.0000e-04\nEpoch 152/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1085 - accuracy: 0.9523 - precision: 0.9494 - recall: 0.9585 - f1_score: 0.9539\nEpoch 152: val_loss did not improve from 0.12315\n32/32 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9470 - precision: 0.9340 - recall: 0.9620 - f1_score: 0.9478 - val_loss: 0.1336 - val_accuracy: 0.9640 - val_precision: 0.9394 - val_recall: 0.9920 - val_f1_score: 0.9650 - lr: 4.0000e-04\nEpoch 153/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1251 - accuracy: 0.9605 - precision: 0.9457 - recall: 0.9769 - f1_score: 0.9610\nEpoch 153: val_loss did not improve from 0.12315\n32/32 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9530 - precision: 0.9398 - recall: 0.9680 - f1_score: 0.9537 - val_loss: 0.1286 - val_accuracy: 0.9640 - val_precision: 0.9394 - val_recall: 0.9920 - val_f1_score: 0.9650 - lr: 4.0000e-04\nEpoch 154/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1215 - accuracy: 0.9539 - precision: 0.9428 - recall: 0.9622 - f1_score: 0.9524\nEpoch 154: val_loss did not improve from 0.12315\n32/32 [==============================] - 0s 5ms/step - loss: 0.1264 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - f1_score: 0.9500 - val_loss: 0.1240 - val_accuracy: 0.9640 - val_precision: 0.9394 - val_recall: 0.9920 - val_f1_score: 0.9650 - lr: 4.0000e-04\nEpoch 155/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1364 - accuracy: 0.9474 - precision: 0.9408 - recall: 0.9587 - f1_score: 0.9497\nEpoch 155: val_loss did not improve from 0.12315\n32/32 [==============================] - 0s 5ms/step - loss: 0.1257 - accuracy: 0.9510 - precision: 0.9396 - recall: 0.9640 - f1_score: 0.9516 - val_loss: 0.1306 - val_accuracy: 0.9680 - val_precision: 0.9466 - val_recall: 0.9920 - val_f1_score: 0.9688 - lr: 4.0000e-04\nEpoch 156/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1185 - accuracy: 0.9572 - precision: 0.9346 - recall: 0.9836 - f1_score: 0.9585\nEpoch 156: val_loss improved from 0.12315 to 0.12200, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.1353 - accuracy: 0.9460 - precision: 0.9272 - recall: 0.9680 - f1_score: 0.9472 - val_loss: 0.1220 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 157/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1203 - accuracy: 0.9547 - precision: 0.9524 - recall: 0.9610 - f1_score: 0.9567\nEpoch 157: val_loss did not improve from 0.12200\n32/32 [==============================] - 0s 5ms/step - loss: 0.1217 - accuracy: 0.9520 - precision: 0.9431 - recall: 0.9620 - f1_score: 0.9525 - val_loss: 0.1301 - val_accuracy: 0.9600 - val_precision: 0.9457 - val_recall: 0.9760 - val_f1_score: 0.9606 - lr: 4.0000e-04\nEpoch 158/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1221 - accuracy: 0.9497 - precision: 0.9349 - recall: 0.9647 - f1_score: 0.9496\nEpoch 158: val_loss did not improve from 0.12200\n32/32 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9530 - precision: 0.9450 - recall: 0.9620 - f1_score: 0.9534 - val_loss: 0.1286 - val_accuracy: 0.9520 - val_precision: 0.9449 - val_recall: 0.9600 - val_f1_score: 0.9524 - lr: 4.0000e-04\nEpoch 159/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1167 - accuracy: 0.9556 - precision: 0.9457 - recall: 0.9673 - f1_score: 0.9564\nEpoch 159: val_loss did not improve from 0.12200\n32/32 [==============================] - 0s 5ms/step - loss: 0.1407 - accuracy: 0.9430 - precision: 0.9268 - recall: 0.9620 - f1_score: 0.9441 - val_loss: 0.1261 - val_accuracy: 0.9680 - val_precision: 0.9535 - val_recall: 0.9840 - val_f1_score: 0.9685 - lr: 4.0000e-04\nEpoch 160/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1098 - accuracy: 0.9578 - precision: 0.9489 - recall: 0.9693 - f1_score: 0.9590\nEpoch 160: val_loss did not improve from 0.12200\n32/32 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9590 - precision: 0.9439 - recall: 0.9760 - f1_score: 0.9597 - val_loss: 0.1299 - val_accuracy: 0.9600 - val_precision: 0.9457 - val_recall: 0.9760 - val_f1_score: 0.9606 - lr: 4.0000e-04\nEpoch 161/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1453 - accuracy: 0.9408 - precision: 0.9295 - recall: 0.9539 - f1_score: 0.9416\nEpoch 161: val_loss improved from 0.12200 to 0.11816, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1381 - accuracy: 0.9430 - precision: 0.9318 - recall: 0.9560 - f1_score: 0.9437 - val_loss: 0.1182 - val_accuracy: 0.9680 - val_precision: 0.9606 - val_recall: 0.9760 - val_f1_score: 0.9683 - lr: 4.0000e-04\nEpoch 162/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1305 - accuracy: 0.9594 - precision: 0.9505 - recall: 0.9685 - f1_score: 0.9594\nEpoch 162: val_loss did not improve from 0.11816\n32/32 [==============================] - 0s 4ms/step - loss: 0.1215 - accuracy: 0.9610 - precision: 0.9528 - recall: 0.9700 - f1_score: 0.9613 - val_loss: 0.1237 - val_accuracy: 0.9600 - val_precision: 0.9600 - val_recall: 0.9600 - val_f1_score: 0.9600 - lr: 4.0000e-04\nEpoch 163/200\n19/32 [================>.............] - ETA: 0s - loss: 0.0973 - accuracy: 0.9622 - precision: 0.9548 - recall: 0.9705 - f1_score: 0.9626\nEpoch 163: val_loss did not improve from 0.11816\n32/32 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9560 - precision: 0.9471 - recall: 0.9660 - f1_score: 0.9564 - val_loss: 0.1219 - val_accuracy: 0.9720 - val_precision: 0.9683 - val_recall: 0.9760 - val_f1_score: 0.9721 - lr: 4.0000e-04\nEpoch 164/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1065 - accuracy: 0.9656 - precision: 0.9538 - recall: 0.9779 - f1_score: 0.9657\nEpoch 164: val_loss did not improve from 0.11816\n32/32 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9640 - precision: 0.9531 - recall: 0.9760 - f1_score: 0.9644 - val_loss: 0.1185 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 165/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.0957 - accuracy: 0.9583 - precision: 0.9463 - recall: 0.9724 - f1_score: 0.9592\nEpoch 165: val_loss did not improve from 0.11816\n32/32 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9530 - precision: 0.9398 - recall: 0.9680 - f1_score: 0.9537 - val_loss: 0.1190 - val_accuracy: 0.9560 - val_precision: 0.9385 - val_recall: 0.9760 - val_f1_score: 0.9569 - lr: 4.0000e-04\nEpoch 166/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1310 - accuracy: 0.9484 - precision: 0.9256 - recall: 0.9749 - f1_score: 0.9496\nEpoch 166: val_loss did not improve from 0.11816\n32/32 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9500 - precision: 0.9327 - recall: 0.9700 - f1_score: 0.9510 - val_loss: 0.1278 - val_accuracy: 0.9560 - val_precision: 0.9318 - val_recall: 0.9840 - val_f1_score: 0.9572 - lr: 4.0000e-04\nEpoch 167/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1291 - accuracy: 0.9507 - precision: 0.9302 - recall: 0.9734 - f1_score: 0.9513\nEpoch 167: val_loss did not improve from 0.11816\n32/32 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9620 - precision: 0.9459 - recall: 0.9800 - f1_score: 0.9627 - val_loss: 0.1213 - val_accuracy: 0.9600 - val_precision: 0.9528 - val_recall: 0.9680 - val_f1_score: 0.9603 - lr: 4.0000e-04\nEpoch 168/200\n20/32 [=================>............] - ETA: 0s - loss: 0.0914 - accuracy: 0.9672 - precision: 0.9559 - recall: 0.9819 - f1_score: 0.9687\nEpoch 168: val_loss did not improve from 0.11816\n32/32 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9550 - precision: 0.9487 - recall: 0.9620 - f1_score: 0.9553 - val_loss: 0.1188 - val_accuracy: 0.9640 - val_precision: 0.9531 - val_recall: 0.9760 - val_f1_score: 0.9644 - lr: 4.0000e-04\nEpoch 169/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1218 - accuracy: 0.9500 - precision: 0.9311 - recall: 0.9719 - f1_score: 0.9511\nEpoch 169: val_loss improved from 0.11816 to 0.11772, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.9570 - precision: 0.9437 - recall: 0.9720 - f1_score: 0.9576 - val_loss: 0.1177 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 170/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1170 - accuracy: 0.9507 - precision: 0.9198 - recall: 0.9868 - f1_score: 0.9521\nEpoch 170: val_loss did not improve from 0.11772\n32/32 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9540 - precision: 0.9349 - recall: 0.9760 - f1_score: 0.9550 - val_loss: 0.1197 - val_accuracy: 0.9720 - val_precision: 0.9609 - val_recall: 0.9840 - val_f1_score: 0.9723 - lr: 4.0000e-04\nEpoch 171/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1126 - accuracy: 0.9589 - precision: 0.9519 - recall: 0.9674 - f1_score: 0.9596\nEpoch 171: val_loss improved from 0.11772 to 0.11766, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9560 - precision: 0.9453 - recall: 0.9680 - f1_score: 0.9565 - val_loss: 0.1177 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 172/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1088 - accuracy: 0.9594 - precision: 0.9444 - recall: 0.9745 - f1_score: 0.9592\nEpoch 172: val_loss improved from 0.11766 to 0.11476, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9610 - precision: 0.9493 - recall: 0.9740 - f1_score: 0.9615 - val_loss: 0.1148 - val_accuracy: 0.9720 - val_precision: 0.9609 - val_recall: 0.9840 - val_f1_score: 0.9723 - lr: 4.0000e-04\nEpoch 173/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1169 - accuracy: 0.9688 - precision: 0.9487 - recall: 0.9900 - f1_score: 0.9689\nEpoch 173: val_loss did not improve from 0.11476\n32/32 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.9670 - precision: 0.9534 - recall: 0.9820 - f1_score: 0.9675 - val_loss: 0.1164 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 174/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1111 - accuracy: 0.9622 - precision: 0.9539 - recall: 0.9699 - f1_score: 0.9619\nEpoch 174: val_loss did not improve from 0.11476\n32/32 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9620 - precision: 0.9565 - recall: 0.9680 - f1_score: 0.9622 - val_loss: 0.1179 - val_accuracy: 0.9680 - val_precision: 0.9606 - val_recall: 0.9760 - val_f1_score: 0.9683 - lr: 4.0000e-04\nEpoch 175/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1198 - accuracy: 0.9453 - precision: 0.9410 - recall: 0.9498 - f1_score: 0.9454\nEpoch 175: val_loss did not improve from 0.11476\n32/32 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9510 - precision: 0.9413 - recall: 0.9620 - f1_score: 0.9515 - val_loss: 0.1200 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 176/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1178 - accuracy: 0.9516 - precision: 0.9405 - recall: 0.9664 - f1_score: 0.9532\nEpoch 176: val_loss did not improve from 0.11476\n32/32 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9540 - precision: 0.9451 - recall: 0.9640 - f1_score: 0.9545 - val_loss: 0.1221 - val_accuracy: 0.9520 - val_precision: 0.9449 - val_recall: 0.9600 - val_f1_score: 0.9524 - lr: 4.0000e-04\nEpoch 177/200\n21/32 [==================>...........] - ETA: 0s - loss: 0.1196 - accuracy: 0.9583 - precision: 0.9509 - recall: 0.9627 - f1_score: 0.9568\nEpoch 177: val_loss did not improve from 0.11476\n32/32 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9560 - precision: 0.9488 - recall: 0.9640 - f1_score: 0.9563 - val_loss: 0.1186 - val_accuracy: 0.9560 - val_precision: 0.9524 - val_recall: 0.9600 - val_f1_score: 0.9562 - lr: 4.0000e-04\nEpoch 178/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1214 - accuracy: 0.9556 - precision: 0.9351 - recall: 0.9763 - f1_score: 0.9552\nEpoch 178: val_loss improved from 0.11476 to 0.11195, saving model to best_hybrid_model.h5\n32/32 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9510 - precision: 0.9430 - recall: 0.9600 - f1_score: 0.9514 - val_loss: 0.1119 - val_accuracy: 0.9640 - val_precision: 0.9603 - val_recall: 0.9680 - val_f1_score: 0.9641 - lr: 4.0000e-04\nEpoch 179/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1116 - accuracy: 0.9605 - precision: 0.9455 - recall: 0.9768 - f1_score: 0.9609\nEpoch 179: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1244 - accuracy: 0.9590 - precision: 0.9474 - recall: 0.9720 - f1_score: 0.9595 - val_loss: 0.1224 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 180/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1466 - accuracy: 0.9484 - precision: 0.9304 - recall: 0.9639 - f1_score: 0.9469\nEpoch 180: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1319 - accuracy: 0.9540 - precision: 0.9451 - recall: 0.9640 - f1_score: 0.9545 - val_loss: 0.1216 - val_accuracy: 0.9680 - val_precision: 0.9466 - val_recall: 0.9920 - val_f1_score: 0.9688 - lr: 4.0000e-04\nEpoch 181/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1428 - accuracy: 0.9462 - precision: 0.9360 - recall: 0.9586 - f1_score: 0.9472\nEpoch 181: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.9540 - precision: 0.9399 - recall: 0.9700 - f1_score: 0.9547 - val_loss: 0.1253 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 182/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1161 - accuracy: 0.9563 - precision: 0.9426 - recall: 0.9720 - f1_score: 0.9571\nEpoch 182: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.9650 - precision: 0.9568 - recall: 0.9740 - f1_score: 0.9653 - val_loss: 0.1250 - val_accuracy: 0.9760 - val_precision: 0.9612 - val_recall: 0.9920 - val_f1_score: 0.9764 - lr: 4.0000e-04\nEpoch 183/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1228 - accuracy: 0.9479 - precision: 0.9283 - recall: 0.9680 - f1_score: 0.9477\nEpoch 183: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9510 - precision: 0.9465 - recall: 0.9560 - f1_score: 0.9512 - val_loss: 0.1230 - val_accuracy: 0.9680 - val_precision: 0.9606 - val_recall: 0.9760 - val_f1_score: 0.9683 - lr: 4.0000e-04\nEpoch 184/200\n19/32 [================>.............] - ETA: 0s - loss: 0.0939 - accuracy: 0.9605 - precision: 0.9536 - recall: 0.9664 - f1_score: 0.9600\nEpoch 184: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9590 - precision: 0.9491 - recall: 0.9700 - f1_score: 0.9594 - val_loss: 0.1210 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 185/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1164 - accuracy: 0.9638 - precision: 0.9530 - recall: 0.9775 - f1_score: 0.9651\nEpoch 185: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9650 - precision: 0.9532 - recall: 0.9780 - f1_score: 0.9654 - val_loss: 0.1207 - val_accuracy: 0.9760 - val_precision: 0.9612 - val_recall: 0.9920 - val_f1_score: 0.9764 - lr: 4.0000e-04\nEpoch 186/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1216 - accuracy: 0.9474 - precision: 0.9383 - recall: 0.9620 - f1_score: 0.9500\nEpoch 186: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9540 - precision: 0.9434 - recall: 0.9660 - f1_score: 0.9545 - val_loss: 0.1206 - val_accuracy: 0.9760 - val_precision: 0.9612 - val_recall: 0.9920 - val_f1_score: 0.9764 - lr: 4.0000e-04\nEpoch 187/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1175 - accuracy: 0.9497 - precision: 0.9453 - recall: 0.9487 - f1_score: 0.9470\nEpoch 187: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9560 - precision: 0.9542 - recall: 0.9580 - f1_score: 0.9561 - val_loss: 0.1256 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 4.0000e-04\nEpoch 188/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1087 - accuracy: 0.9622 - precision: 0.9457 - recall: 0.9801 - f1_score: 0.9626\nEpoch 188: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n\nEpoch 188: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9700 - precision: 0.9608 - recall: 0.9800 - f1_score: 0.9703 - val_loss: 0.1243 - val_accuracy: 0.9680 - val_precision: 0.9466 - val_recall: 0.9920 - val_f1_score: 0.9688 - lr: 4.0000e-04\nEpoch 189/200\n20/32 [=================>............] - ETA: 0s - loss: 0.0948 - accuracy: 0.9688 - precision: 0.9607 - recall: 0.9785 - f1_score: 0.9695\nEpoch 189: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9690 - precision: 0.9571 - recall: 0.9820 - f1_score: 0.9694 - val_loss: 0.1243 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 2.0000e-04\nEpoch 190/200\n19/32 [================>.............] - ETA: 0s - loss: 0.0920 - accuracy: 0.9688 - precision: 0.9583 - recall: 0.9803 - f1_score: 0.9692\nEpoch 190: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9610 - precision: 0.9476 - recall: 0.9760 - f1_score: 0.9616 - val_loss: 0.1222 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 2.0000e-04\nEpoch 191/200\n20/32 [=================>............] - ETA: 0s - loss: 0.0901 - accuracy: 0.9672 - precision: 0.9611 - recall: 0.9757 - f1_score: 0.9683\nEpoch 191: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.9560 - precision: 0.9419 - recall: 0.9720 - f1_score: 0.9567 - val_loss: 0.1162 - val_accuracy: 0.9640 - val_precision: 0.9462 - val_recall: 0.9840 - val_f1_score: 0.9647 - lr: 2.0000e-04\nEpoch 192/200\n20/32 [=================>............] - ETA: 0s - loss: 0.0856 - accuracy: 0.9688 - precision: 0.9619 - recall: 0.9743 - f1_score: 0.9681\nEpoch 192: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9650 - precision: 0.9659 - recall: 0.9640 - f1_score: 0.9650 - val_loss: 0.1183 - val_accuracy: 0.9680 - val_precision: 0.9535 - val_recall: 0.9840 - val_f1_score: 0.9685 - lr: 2.0000e-04\nEpoch 193/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1155 - accuracy: 0.9622 - precision: 0.9578 - recall: 0.9672 - f1_score: 0.9625\nEpoch 193: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9620 - precision: 0.9529 - recall: 0.9720 - f1_score: 0.9624 - val_loss: 0.1199 - val_accuracy: 0.9680 - val_precision: 0.9466 - val_recall: 0.9920 - val_f1_score: 0.9688 - lr: 2.0000e-04\nEpoch 194/200\n19/32 [================>.............] - ETA: 0s - loss: 0.0928 - accuracy: 0.9671 - precision: 0.9620 - recall: 0.9744 - f1_score: 0.9682\nEpoch 194: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9710 - precision: 0.9663 - recall: 0.9760 - f1_score: 0.9711 - val_loss: 0.1217 - val_accuracy: 0.9680 - val_precision: 0.9466 - val_recall: 0.9920 - val_f1_score: 0.9688 - lr: 2.0000e-04\nEpoch 195/200\n19/32 [================>.............] - ETA: 0s - loss: 0.0813 - accuracy: 0.9638 - precision: 0.9403 - recall: 0.9901 - f1_score: 0.9645\nEpoch 195: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9630 - precision: 0.9478 - recall: 0.9800 - f1_score: 0.9636 - val_loss: 0.1213 - val_accuracy: 0.9640 - val_precision: 0.9394 - val_recall: 0.9920 - val_f1_score: 0.9650 - lr: 2.0000e-04\nEpoch 196/200\n19/32 [================>.............] - ETA: 0s - loss: 0.1178 - accuracy: 0.9523 - precision: 0.9264 - recall: 0.9754 - f1_score: 0.9503\nEpoch 196: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9540 - precision: 0.9399 - recall: 0.9700 - f1_score: 0.9547 - val_loss: 0.1168 - val_accuracy: 0.9760 - val_precision: 0.9612 - val_recall: 0.9920 - val_f1_score: 0.9764 - lr: 2.0000e-04\nEpoch 197/200\n18/32 [===============>..............] - ETA: 0s - loss: 0.1010 - accuracy: 0.9601 - precision: 0.9379 - recall: 0.9819 - f1_score: 0.9594\nEpoch 197: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9550 - precision: 0.9435 - recall: 0.9680 - f1_score: 0.9556 - val_loss: 0.1138 - val_accuracy: 0.9720 - val_precision: 0.9609 - val_recall: 0.9840 - val_f1_score: 0.9723 - lr: 2.0000e-04\nEpoch 198/200\n20/32 [=================>............] - ETA: 0s - loss: 0.1008 - accuracy: 0.9641 - precision: 0.9508 - recall: 0.9778 - f1_score: 0.9641Restoring model weights from the end of the best epoch: 178.\n\nEpoch 198: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\nEpoch 198: val_loss did not improve from 0.11195\n32/32 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9670 - precision: 0.9552 - recall: 0.9800 - f1_score: 0.9674 - val_loss: 0.1125 - val_accuracy: 0.9720 - val_precision: 0.9538 - val_recall: 0.9920 - val_f1_score: 0.9725 - lr: 2.0000e-04\nEpoch 198: early stopping\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def evaluate_model_on_holdout(model, X_holdout, y_holdout, model_name):\n    \"\"\"Evaluate model on holdout set\"\"\"\n    y_pred_proba = model.predict(X_holdout)\n    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n    \n    metrics = {\n        'Model': model_name,\n        'Accuracy': accuracy_score(y_holdout, y_pred),\n        'Precision': precision_score(y_holdout, y_pred),\n        'Recall': recall_score(y_holdout, y_pred),\n        'F1-Score': f1_score(y_holdout, y_pred),\n        'AUC': roc_auc_score(y_holdout, y_pred_proba)\n    }\n    \n    return metrics, y_pred, y_pred_proba\n\n# Evaluate all models on holdout set\nmodels = [\n    (dnn_model, 'Custom DNN'),\n    (cnn_model, 'Custom CNN'),\n    (hybrid_model, 'Hybrid Model')\n]\n\nresults = []\npredictions = {}\n\nfor model, name in models:\n    metrics, y_pred, y_pred_proba = evaluate_model_on_holdout(model, X_holdout, y_holdout, name)\n    results.append(metrics)\n    predictions[name] = {'y_pred': y_pred, 'y_pred_proba': y_pred_proba}\n    \n    print(f\"\\n{name} Results on Holdout Set:\")\n    for metric, value in metrics.items():\n        if metric != 'Model':\n            print(f\"{metric}: {value:.4f}\")\n\n# Create results dataframe\nresults_df = pd.DataFrame(results)\nprint(\"\\nModel Comparison:\")\nprint(results_df.round(4))\n\n# Find best model\nbest_model_idx = results_df['AUC'].idxmax()\nbest_model_name = results_df.loc[best_model_idx, 'Model']\nbest_model = models[best_model_idx][0]\n\nprint(f\"\\nBest Model: {best_model_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:21:36.115529Z","iopub.execute_input":"2025-09-26T04:21:36.115947Z","iopub.status.idle":"2025-09-26T04:21:36.771891Z","shell.execute_reply.started":"2025-09-26T04:21:36.115919Z","shell.execute_reply":"2025-09-26T04:21:36.770798Z"}},"outputs":[{"name":"stdout","text":"6/6 [==============================] - 0s 2ms/step\n\nCustom DNN Results on Holdout Set:\nAccuracy: 0.8802\nPrecision: 0.2000\nRecall: 0.2727\nF1-Score: 0.2308\nAUC: 0.6125\n6/6 [==============================] - 0s 2ms/step\n\nCustom CNN Results on Holdout Set:\nAccuracy: 0.8084\nPrecision: 0.1111\nRecall: 0.2727\nF1-Score: 0.1579\nAUC: 0.4522\n6/6 [==============================] - 0s 2ms/step\n\nHybrid Model Results on Holdout Set:\nAccuracy: 0.9042\nPrecision: 0.2727\nRecall: 0.2727\nF1-Score: 0.2727\nAUC: 0.5880\n\nModel Comparison:\n          Model  Accuracy  Precision  Recall  F1-Score     AUC\n0    Custom DNN    0.8802     0.2000  0.2727    0.2308  0.6125\n1    Custom CNN    0.8084     0.1111  0.2727    0.1579  0.4522\n2  Hybrid Model    0.9042     0.2727  0.2727    0.2727  0.5880\n\nBest Model: Custom DNN\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def cross_validate_deep_learning(X, y, model_fn, cv_folds=5):\n    \"\"\"Perform cross-validation for deep learning models\"\"\"\n    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n    cv_scores = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        print(f\"Training fold {fold + 1}/{cv_folds}\")\n        \n        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n        \n        # Apply SMOTE to training fold\n        smote_fold = SMOTE(random_state=42)\n        X_train_balanced_fold, y_train_balanced_fold = smote_fold.fit_resample(X_train_fold, y_train_fold)\n        \n        # Create and train model\n        model = model_fn()\n        model.compile(\n            optimizer=Adam(learning_rate=0.001),\n            loss='binary_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        # Train with callbacks\n        callbacks = [\n            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n        ]\n        \n        model.fit(\n            X_train_balanced_fold, y_train_balanced_fold,\n            validation_data=(X_val_fold, y_val_fold),\n            epochs=50,\n            batch_size=16,\n            callbacks=callbacks,\n            verbose=0\n        )\n        \n        # Evaluate\n        y_pred_proba = model.predict(X_val_fold)\n        auc_score = roc_auc_score(y_val_fold, y_pred_proba)\n        cv_scores.append(auc_score)\n        print(f\"Fold {fold + 1} AUC: {auc_score:.4f}\")\n    \n    return cv_scores\n\n# Perform cross-validation on the best model\nprint(f\"\\nPerforming Cross-Validation on {best_model_name}...\")\n\nif best_model_name == 'Custom DNN':\n    best_cv_scores = cross_validate_deep_learning(X_scaled, y_dl, create_dnn, cv_folds=5)\nelif best_model_name == 'Custom CNN':\n    best_cv_scores = cross_validate_deep_learning(X_scaled, y_dl, create_cnn, cv_folds=5)\nelse:\n    best_cv_scores = cross_validate_deep_learning(X_scaled, y_dl, create_hybrid, cv_folds=5)\n\nprint(f\"\\nCross-Validation Results for {best_model_name}:\")\nprint(f\"Mean AUC: {np.mean(best_cv_scores):.4f} ± {np.std(best_cv_scores):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:21:53.234759Z","iopub.execute_input":"2025-09-26T04:21:53.235075Z","iopub.status.idle":"2025-09-26T04:23:05.735833Z","shell.execute_reply.started":"2025-09-26T04:21:53.235052Z","shell.execute_reply":"2025-09-26T04:23:05.734830Z"}},"outputs":[{"name":"stdout","text":"\nPerforming Cross-Validation on Custom DNN...\nTraining fold 1/5\n6/6 [==============================] - 0s 2ms/step\nFold 1 AUC: 0.5592\nTraining fold 2/5\n6/6 [==============================] - 0s 2ms/step\nFold 2 AUC: 0.4493\nTraining fold 3/5\n6/6 [==============================] - 0s 2ms/step\nFold 3 AUC: 0.4193\nTraining fold 4/5\n6/6 [==============================] - 0s 2ms/step\nFold 4 AUC: 0.4324\nTraining fold 5/5\n6/6 [==============================] - 0s 2ms/step\nFold 5 AUC: 0.5478\n\nCross-Validation Results for Custom DNN:\nMean AUC: 0.4816 ± 0.0596\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Generate synthetic test set using your training data\nfrom sdv.single_table import GaussianCopulaSynthesizer\nfrom sdv.metadata import SingleTableMetadata\n\n# Create metadata from your original dataframe\nmetadata = SingleTableMetadata()\nmetadata.detect_from_dataframe(data=df)\n\n# Create and fit synthesizer\nsynthesizer = GaussianCopulaSynthesizer(metadata)\nsynthesizer.fit(df)\n\n# Generate synthetic test set (same size as holdout)\nsynthetic_test = synthesizer.sample(num_rows=len(X_holdout))\n\n# Preprocess synthetic test set\nX_synthetic = synthetic_test[feature_columns].copy()\n\n# Apply the same imputation and preprocessing\nif numerical_features:\n    X_synthetic_numerical = knn_imputer.transform(X_synthetic[numerical_features])\n    X_synthetic_numerical = pd.DataFrame(X_synthetic_numerical, columns=numerical_features, index=X_synthetic.index)\nelse:\n    X_synthetic_numerical = pd.DataFrame(index=X_synthetic.index)\n\nif binary_features:\n    X_synthetic_binary = mode_imputer.transform(X_synthetic[binary_features])\n    X_synthetic_binary = pd.DataFrame(X_synthetic_binary, columns=binary_features, index=X_synthetic.index)\nelse:\n    X_synthetic_binary = pd.DataFrame(index=X_synthetic.index)\n\nX_synthetic_imputed = pd.concat([X_synthetic_numerical, X_synthetic_binary], axis=1)\n\n# Apply feature engineering\nX_synthetic_engineered = X_synthetic_imputed.copy()\nX_synthetic_engineered['Age_squared'] = X_synthetic_engineered['Age'] ** 2\nX_synthetic_engineered['Age_cubed'] = X_synthetic_engineered['Age'] ** 3\n\nif 'Number of sexual partners' in X_synthetic_engineered.columns and 'First sexual intercourse' in X_synthetic_engineered.columns:\n    X_synthetic_engineered['Years_since_first_intercourse'] = X_synthetic_engineered['Age'] - X_synthetic_engineered['First sexual intercourse']\n    X_synthetic_engineered['Partners_per_year'] = X_synthetic_engineered['Number of sexual partners'] / (X_synthetic_engineered['Years_since_first_intercourse'] + 1)\n    X_synthetic_engineered['Partners_per_year'] = X_synthetic_engineered['Partners_per_year'].replace([np.inf, -np.inf], 0)\n\nif 'Smokes (years)' in X_synthetic_engineered.columns and 'Smokes (packs/year)' in X_synthetic_engineered.columns:\n    X_synthetic_engineered['Total_packs_smoked'] = X_synthetic_engineered['Smokes (years)'] * X_synthetic_engineered['Smokes (packs/year)']\n\ncontraceptive_features = []\nif 'Hormonal Contraceptives (years)' in X_synthetic_engineered.columns:\n    contraceptive_features.append('Hormonal Contraceptives (years)')\nif 'IUD' in X_synthetic_engineered.columns:\n    X_synthetic_engineered['IUD_years'] = X_synthetic_engineered['IUD'] * 5\n    contraceptive_features.append('IUD_years')\n\nif contraceptive_features:\n    X_synthetic_engineered['Total_contraceptive_years'] = X_synthetic_engineered[contraceptive_features].sum(axis=1)\n\nif 'Smokes' in X_synthetic_engineered.columns and 'Hormonal Contraceptives' in X_synthetic_engineered.columns:\n    X_synthetic_engineered['Smoking_contraceptive_risk'] = X_synthetic_engineered['Smokes'] * X_synthetic_engineered['Hormonal Contraceptives']\n\nX_synthetic_engineered['Age_group'] = pd.cut(X_synthetic_engineered['Age'], \n                                            bins=[0, 25, 35, 45, 100], \n                                            labels=[0, 1, 2, 3])\nX_synthetic_engineered['Age_group'] = X_synthetic_engineered['Age_group'].astype(int)\n\nif 'Num of pregnancies' in X_synthetic_engineered.columns:\n    X_synthetic_engineered['High_risk_pregnancy'] = (X_synthetic_engineered['Num of pregnancies'] > 3).astype(int)\n\nX_synthetic_engineered = X_synthetic_engineered.replace([np.inf, -np.inf], 0)\nX_synthetic_engineered = X_synthetic_engineered.fillna(0)\n\n# Scale synthetic data\nX_synthetic_scaled = scaler.transform(X_synthetic_engineered)\n\n# Get synthetic target (this is for testing purposes only)\ny_synthetic = synthetic_test[target_column].fillna(0).astype(int)\n\nprint(f\"Synthetic test set shape: {X_synthetic_scaled.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:26:20.541003Z","iopub.execute_input":"2025-09-26T04:26:20.542114Z","iopub.status.idle":"2025-09-26T04:26:27.811485Z","shell.execute_reply.started":"2025-09-26T04:26:20.542084Z","shell.execute_reply":"2025-09-26T04:26:27.810537Z"}},"outputs":[{"name":"stdout","text":"Synthetic test set shape: (167, 20)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Evaluate best model on synthetic test set\ny_synthetic_pred_proba = best_model.predict(X_synthetic_scaled)\ny_synthetic_pred = (y_synthetic_pred_proba > 0.5).astype(int).flatten()\n\nsynthetic_metrics = {\n    'Accuracy': accuracy_score(y_synthetic, y_synthetic_pred),\n    'Precision': precision_score(y_synthetic, y_synthetic_pred),\n    'Recall': recall_score(y_synthetic, y_synthetic_pred),\n    'F1-Score': f1_score(y_synthetic, y_synthetic_pred),\n    'AUC': roc_auc_score(y_synthetic, y_synthetic_pred_proba)\n}\n\nprint(\"Best Model Performance on Synthetic Test Set:\")\nfor metric, value in synthetic_metrics.items():\n    print(f\"{metric}: {value:.4f}\")\n\n# Compare with holdout performance\nholdout_metrics = results_df[results_df['Model'] == best_model_name].iloc[0]\nprint(\"\\nPerformance Comparison:\")\nprint(f\"Holdout AUC: {holdout_metrics['AUC']:.4f}\")\nprint(f\"Synthetic AUC: {synthetic_metrics['AUC']:.4f}\")\nprint(f\"Difference: {abs(holdout_metrics['AUC'] - synthetic_metrics['AUC']):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:28:03.084984Z","iopub.execute_input":"2025-09-26T04:28:03.085975Z","iopub.status.idle":"2025-09-26T04:28:03.217946Z","shell.execute_reply.started":"2025-09-26T04:28:03.085945Z","shell.execute_reply":"2025-09-26T04:28:03.216974Z"}},"outputs":[{"name":"stdout","text":"6/6 [==============================] - 0s 2ms/step\nBest Model Performance on Synthetic Test Set:\nAccuracy: 0.8563\nPrecision: 0.2308\nRecall: 0.1765\nF1-Score: 0.2000\nAUC: 0.4773\n\nPerformance Comparison:\nHoldout AUC: 0.6125\nSynthetic AUC: 0.4773\nDifference: 0.1352\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Save the best model\nbest_model.save(f'best_cervical_cancer_model_{best_model_name.replace(\" \", \"_\").lower()}.h5')\nprint(f\"Best model ({best_model_name}) saved successfully!\")\n\n# Save preprocessing objects\nimport joblib\njoblib.dump(scaler, 'scaler.pkl')\njoblib.dump(knn_imputer, 'knn_imputer.pkl')\njoblib.dump(mode_imputer, 'mode_imputer.pkl')\nprint(\"Preprocessing objects saved successfully!\")\n\n# Create prediction function for deployment\ndef predict_cervical_cancer_risk(input_data):\n    \"\"\"\n    Prediction function for new patient data\n    \n    Parameters:\n    input_ dict or DataFrame with columns:\n        - Age\n        - Number of sexual partners  \n        - First sexual intercourse\n        - Num of pregnancies\n        - Smokes\n        - Smokes (years)\n        - Smokes (packs/year)\n        - Hormonal Contraceptives\n        - Hormonal Contraceptives (years)\n        - IUD\n    \n    Returns:\n    prediction: 0 or 1 (cancer risk)\n    probability: float (probability of cancer)\n    \"\"\"\n    # Load preprocessing objects and model\n    scaler = joblib.load('scaler.pkl')\n    knn_imputer = joblib.load('knn_imputer.pkl')\n    mode_imputer = joblib.load('mode_imputer.pkl')\n    model = tf.keras.models.load_model(f'best_cervical_cancer_model_{best_model_name.replace(\" \", \"_\").lower()}.h5')\n    \n    # Convert input to DataFrame if needed\n    if isinstance(input_data, dict):\n        input_df = pd.DataFrame([input_data])\n    else:\n        input_df = input_data.copy()\n    \n    # Apply the same preprocessing pipeline\n    # Imputation\n    numerical_cols = [col for col in numerical_features if col in input_df.columns]\n    binary_cols = [col for col in binary_features if col in input_df.columns]\n    \n    if numerical_cols:\n        numerical_imputed = knn_imputer.transform(input_df[numerical_cols])\n        numerical_df = pd.DataFrame(numerical_imputed, columns=numerical_cols, index=input_df.index)\n    else:\n        numerical_df = pd.DataFrame(index=input_df.index)\n    \n    if binary_cols:\n        binary_imputed = mode_imputer.transform(input_df[binary_cols])\n        binary_df = pd.DataFrame(binary_imputed, columns=binary_cols, index=input_df.index)\n    else:\n        binary_df = pd.DataFrame(index=input_df.index)\n    \n    processed_df = pd.concat([numerical_df, binary_df], axis=1)\n    \n    # Feature engineering (same as training)\n    processed_df['Age_squared'] = processed_df['Age'] ** 2\n    processed_df['Age_cubed'] = processed_df['Age'] ** 3\n    \n    if 'Number of sexual partners' in processed_df.columns and 'First sexual intercourse' in processed_df.columns:\n        processed_df['Years_since_first_intercourse'] = processed_df['Age'] - processed_df['First sexual intercourse']\n        processed_df['Partners_per_year'] = processed_df['Number of sexual partners'] / (processed_df['Years_since_first_intercourse'] + 1)\n        processed_df['Partners_per_year'] = processed_df['Partners_per_year'].replace([np.inf, -np.inf], 0)\n    \n    if 'Smokes (years)' in processed_df.columns and 'Smokes (packs/year)' in processed_df.columns:\n        processed_df['Total_packs_smoked'] = processed_df['Smokes (years)'] * processed_df['Smokes (packs/year)']\n    \n    contraceptive_features = []\n    if 'Hormonal Contraceptives (years)' in processed_df.columns:\n        contraceptive_features.append('Hormonal Contraceptives (years)')\n    if 'IUD' in processed_df.columns:\n        processed_df['IUD_years'] = processed_df['IUD'] * 5\n        contraceptive_features.append('IUD_years')\n    \n    if contraceptive_features:\n        processed_df['Total_contraceptive_years'] = processed_df[contraceptive_features].sum(axis=1)\n    \n    if 'Smokes' in processed_df.columns and 'Hormonal Contraceptives' in processed_df.columns:\n        processed_df['Smoking_contraceptive_risk'] = processed_df['Smokes'] * processed_df['Hormonal Contraceptives']\n    \n    processed_df['Age_group'] = pd.cut(processed_df['Age'], bins=[0, 25, 35, 45, 100], labels=[0, 1, 2, 3])\n    processed_df['Age_group'] = processed_df['Age_group'].astype(int)\n    \n    if 'Num of pregnancies' in processed_df.columns:\n        processed_df['High_risk_pregnancy'] = (processed_df['Num of pregnancies'] > 3).astype(int)\n    \n    processed_df = processed_df.replace([np.inf, -np.inf], 0)\n    processed_df = processed_df.fillna(0)\n    \n    # Ensure all engineered features are present\n    missing_features = set(X_engineered.columns) - set(processed_df.columns)\n    for feat in missing_features:\n        processed_df[feat] = 0\n    \n    processed_df = processed_df[X_engineered.columns]\n    \n    # Scale and predict\n    scaled_data = scaler.transform(processed_df)\n    probability = model.predict(scaled_data)[0][0]\n    prediction = int(probability > 0.5)\n    \n    return prediction, probability\n\nprint(\"Prediction function created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:28:19.609868Z","iopub.execute_input":"2025-09-26T04:28:19.610234Z","iopub.status.idle":"2025-09-26T04:28:19.677947Z","shell.execute_reply.started":"2025-09-26T04:28:19.610206Z","shell.execute_reply":"2025-09-26T04:28:19.677114Z"}},"outputs":[{"name":"stdout","text":"Best model (Custom DNN) saved successfully!\nPreprocessing objects saved successfully!\nPrediction function created successfully!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!pip install tensorflow-addons --quiet\n!pip install keras-tuner --quiet\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.optimizers import AdamW\n\n# =============================\n# 1. Custom F1 Metric\n# =============================\ndef custom_f1(y_true, y_pred):\n    y_pred = tf.round(y_pred)\n    tp = tf.reduce_sum(tf.cast(y_true * y_pred, 'float'))\n    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, 'float'))\n    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), 'float'))\n\n    precision = tp / (tp + fp + 1e-8)\n    recall = tp / (tp + fn + 1e-8)\n    return 2 * ((precision * recall) / (precision + recall + 1e-8))\n\n# =============================\n# 2. Callbacks\n# =============================\ndef create_model_callbacks(model_name):\n    return [\n        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6, verbose=1),\n        ModelCheckpoint(f'best_{model_name}_model.h5', monitor='val_loss', save_best_only=True, verbose=1),\n        LearningRateScheduler(lambda epoch: 1e-3 * (0.9 ** epoch))  # cosine could also be used\n    ]\n\n# =============================\n# 3. Model Architectures\n# =============================\ninput_dim = X_train_balanced.shape[1]\n\n# Stronger DNN\ndef create_dnn():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(input_dim,)),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.5),\n\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.4),\n\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.3),\n\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n\n# Stronger CNN\ndef create_cnn():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n        tf.keras.layers.Conv1D(128, 3, activation='relu'),\n        tf.keras.layers.Conv1D(64, 3, activation='relu'),\n        tf.keras.layers.MaxPooling1D(pool_size=2),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Conv1D(32, 3, activation='relu'),\n        tf.keras.layers.GlobalMaxPooling1D(),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n\n# Stronger Hybrid (CNN + DNN + Skip connections)\ndef create_hybrid():\n    inp = tf.keras.layers.Input(shape=(input_dim,))\n\n    # DNN branch\n    dnn = tf.keras.layers.Dense(256, activation='relu')(inp)\n    dnn = tf.keras.layers.BatchNormalization()(dnn)\n    dnn = tf.keras.layers.Dropout(0.3)(dnn)\n\n    # CNN branch\n    cnn = tf.keras.layers.Reshape((input_dim, 1))(inp)\n    cnn = tf.keras.layers.Conv1D(64, 3, activation='relu', padding=\"same\")(cnn)\n    cnn = tf.keras.layers.MaxPooling1D()(cnn)\n    cnn = tf.keras.layers.Conv1D(32, 3, activation='relu', padding=\"same\")(cnn)\n    cnn = tf.keras.layers.GlobalMaxPooling1D()(cnn)\n\n    # Merge\n    merged = tf.keras.layers.Concatenate()([dnn, cnn])\n    merged = tf.keras.layers.Dense(128, activation='relu')(merged)\n    merged = tf.keras.layers.Dropout(0.4)(merged)\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(merged)\n\n    model = tf.keras.Model(inputs=inp, outputs=out)\n    return model\n\n# =============================\n# 4. Train + Evaluate Function\n# =============================\ndef train_and_evaluate_model(model_fn, X_train, y_train, X_val, y_val, model_name, epochs=300):\n    model = model_fn()\n    model.compile(\n        optimizer=AdamW(learning_rate=1e-3, weight_decay=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), custom_f1]\n    )\n\n    callbacks = create_model_callbacks(model_name)\n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_val, y_val),\n        epochs=epochs,\n        batch_size=32,\n        callbacks=callbacks,\n        verbose=1\n    )\n    return model, history\n\n# =============================\n# 5. Stratified K-Fold Training\n# =============================\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nhistories, models = {}, {}\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X_train_balanced, y_train_balanced)):\n    print(f\"\\n===== Fold {fold+1} =====\")\n\n    X_train_fold, X_val_fold = X_train_balanced[train_idx], X_train_balanced[val_idx]\n    y_train_fold, y_val_fold = y_train_balanced[train_idx], y_train_balanced[val_idx]\n\n    print(\"Training Hybrid Model...\")\n    hybrid_model, hybrid_history = train_and_evaluate_model(\n        create_hybrid, X_train_fold, y_train_fold, X_val_fold, y_val_fold, f\"hybrid_fold{fold+1}\"\n    )\n    models[f\"hybrid_fold{fold+1}\"] = hybrid_model\n    histories[f\"hybrid_fold{fold+1}\"] = hybrid_history\n\n# =============================\n# 6. Ensemble Prediction\n# =============================\ndef ensemble_predict(models, X):\n    preds = [m.predict(X, verbose=0) for m in models.values()]\n    return np.mean(preds, axis=0).round()\n\ny_pred_ensemble = ensemble_predict(models, X_val_fold)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:29:57.805881Z","iopub.execute_input":"2025-09-26T04:29:57.806266Z","iopub.status.idle":"2025-09-26T04:32:19.784911Z","shell.execute_reply.started":"2025-09-26T04:29:57.806244Z","shell.execute_reply":"2025-09-26T04:32:19.783962Z"}},"outputs":[{"name":"stdout","text":"\n===== Fold 1 =====\nTraining Hybrid Model...\nEpoch 1/300\n22/32 [===================>..........] - ETA: 0s - loss: 0.7926 - accuracy: 0.5852 - precision: 0.5831 - recall: 0.5219 - custom_f1: 0.5207 \nEpoch 1: val_loss improved from inf to 0.64016, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 3s 23ms/step - loss: 0.7637 - accuracy: 0.5970 - precision: 0.6025 - recall: 0.5700 - custom_f1: 0.5535 - val_loss: 0.6402 - val_accuracy: 0.6400 - val_precision: 0.6842 - val_recall: 0.5200 - val_custom_f1: 0.4247 - lr: 0.0010\nEpoch 2/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.6243 - accuracy: 0.6603 - precision: 0.6607 - recall: 0.6853 - custom_f1: 0.6715\nEpoch 2: val_loss improved from 0.64016 to 0.61539, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.6043 - accuracy: 0.6680 - precision: 0.6550 - recall: 0.7100 - custom_f1: 0.6810 - val_loss: 0.6154 - val_accuracy: 0.7240 - val_precision: 0.7857 - val_recall: 0.6160 - val_custom_f1: 0.5067 - lr: 9.0000e-04\nEpoch 3/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.5357 - accuracy: 0.7337 - precision: 0.7332 - recall: 0.7371 - custom_f1: 0.7307\nEpoch 3: val_loss improved from 0.61539 to 0.57812, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.5367 - accuracy: 0.7270 - precision: 0.7230 - recall: 0.7360 - custom_f1: 0.7204 - val_loss: 0.5781 - val_accuracy: 0.7800 - val_precision: 0.7692 - val_recall: 0.8000 - val_custom_f1: 0.5360 - lr: 8.1000e-04\nEpoch 4/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.5155 - accuracy: 0.7486 - precision: 0.7263 - recall: 0.7845 - custom_f1: 0.7501\nEpoch 4: val_loss improved from 0.57812 to 0.55685, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.7540 - precision: 0.7452 - recall: 0.7720 - custom_f1: 0.7547 - val_loss: 0.5569 - val_accuracy: 0.8120 - val_precision: 0.7635 - val_recall: 0.9040 - val_custom_f1: 0.5707 - lr: 7.2900e-04\nEpoch 5/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.4865 - accuracy: 0.7539 - precision: 0.7312 - recall: 0.7947 - custom_f1: 0.7547\nEpoch 5: val_loss improved from 0.55685 to 0.53337, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4801 - accuracy: 0.7560 - precision: 0.7406 - recall: 0.7880 - custom_f1: 0.7510 - val_loss: 0.5334 - val_accuracy: 0.8120 - val_precision: 0.7532 - val_recall: 0.9280 - val_custom_f1: 0.5706 - lr: 6.5610e-04\nEpoch 6/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.4719 - accuracy: 0.7880 - precision: 0.7810 - recall: 0.8022 - custom_f1: 0.7919\nEpoch 6: val_loss improved from 0.53337 to 0.51941, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.7920 - precision: 0.7776 - recall: 0.8180 - custom_f1: 0.7943 - val_loss: 0.5194 - val_accuracy: 0.8080 - val_precision: 0.7550 - val_recall: 0.9120 - val_custom_f1: 0.5969 - lr: 5.9049e-04\nEpoch 7/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.4401 - accuracy: 0.7989 - precision: 0.7949 - recall: 0.8201 - custom_f1: 0.8045\nEpoch 7: val_loss improved from 0.51941 to 0.48687, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.8010 - precision: 0.7824 - recall: 0.8340 - custom_f1: 0.8086 - val_loss: 0.4869 - val_accuracy: 0.8120 - val_precision: 0.7532 - val_recall: 0.9280 - val_custom_f1: 0.6007 - lr: 5.3144e-04\nEpoch 8/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.4076 - accuracy: 0.8179 - precision: 0.7995 - recall: 0.8514 - custom_f1: 0.8226\nEpoch 8: val_loss improved from 0.48687 to 0.45761, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.8110 - precision: 0.7940 - recall: 0.8400 - custom_f1: 0.8091 - val_loss: 0.4576 - val_accuracy: 0.8240 - val_precision: 0.7718 - val_recall: 0.9200 - val_custom_f1: 0.6110 - lr: 4.7830e-04\nEpoch 9/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3771 - accuracy: 0.8263 - precision: 0.8200 - recall: 0.8304 - custom_f1: 0.8256\nEpoch 9: val_loss improved from 0.45761 to 0.43700, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3947 - accuracy: 0.8170 - precision: 0.8151 - recall: 0.8200 - custom_f1: 0.8090 - val_loss: 0.4370 - val_accuracy: 0.8160 - val_precision: 0.7616 - val_recall: 0.9200 - val_custom_f1: 0.6039 - lr: 4.3047e-04\nEpoch 10/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3991 - accuracy: 0.8203 - precision: 0.8030 - recall: 0.8451 - custom_f1: 0.8229\nEpoch 10: val_loss improved from 0.43700 to 0.41179, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8220 - precision: 0.8084 - recall: 0.8440 - custom_f1: 0.8235 - val_loss: 0.4118 - val_accuracy: 0.8200 - val_precision: 0.7632 - val_recall: 0.9280 - val_custom_f1: 0.6085 - lr: 3.8742e-04\nEpoch 11/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3856 - accuracy: 0.8247 - precision: 0.8074 - recall: 0.8651 - custom_f1: 0.8331\nEpoch 11: val_loss improved from 0.41179 to 0.40306, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8290 - precision: 0.8098 - recall: 0.8600 - custom_f1: 0.8299 - val_loss: 0.4031 - val_accuracy: 0.8280 - val_precision: 0.7733 - val_recall: 0.9280 - val_custom_f1: 0.6156 - lr: 3.4868e-04\nEpoch 12/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3611 - accuracy: 0.8529 - precision: 0.8497 - recall: 0.8564 - custom_f1: 0.8503\nEpoch 12: val_loss improved from 0.40306 to 0.38213, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3630 - accuracy: 0.8450 - precision: 0.8389 - recall: 0.8540 - custom_f1: 0.8444 - val_loss: 0.3821 - val_accuracy: 0.8200 - val_precision: 0.7632 - val_recall: 0.9280 - val_custom_f1: 0.6087 - lr: 3.1381e-04\nEpoch 13/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3646 - accuracy: 0.8359 - precision: 0.8111 - recall: 0.8889 - custom_f1: 0.8481\nEpoch 13: val_loss improved from 0.38213 to 0.36969, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3647 - accuracy: 0.8360 - precision: 0.8100 - recall: 0.8780 - custom_f1: 0.8428 - val_loss: 0.3697 - val_accuracy: 0.8200 - val_precision: 0.7667 - val_recall: 0.9200 - val_custom_f1: 0.6051 - lr: 2.8243e-04\nEpoch 14/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3567 - accuracy: 0.8568 - precision: 0.8483 - recall: 0.8744 - custom_f1: 0.8523\nEpoch 14: val_loss improved from 0.36969 to 0.36732, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8570 - precision: 0.8413 - recall: 0.8800 - custom_f1: 0.8527 - val_loss: 0.3673 - val_accuracy: 0.8200 - val_precision: 0.7564 - val_recall: 0.9440 - val_custom_f1: 0.6049 - lr: 2.5419e-04\nEpoch 15/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3416 - accuracy: 0.8600 - precision: 0.8407 - recall: 0.8795 - custom_f1: 0.8547\nEpoch 15: val_loss improved from 0.36732 to 0.34734, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8470 - precision: 0.8395 - recall: 0.8580 - custom_f1: 0.8461 - val_loss: 0.3473 - val_accuracy: 0.8360 - val_precision: 0.7838 - val_recall: 0.9280 - val_custom_f1: 0.6218 - lr: 2.2877e-04\nEpoch 16/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3723 - accuracy: 0.8342 - precision: 0.8073 - recall: 0.8850 - custom_f1: 0.8404\nEpoch 16: val_loss improved from 0.34734 to 0.34458, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3674 - accuracy: 0.8380 - precision: 0.8051 - recall: 0.8920 - custom_f1: 0.8413 - val_loss: 0.3446 - val_accuracy: 0.8360 - val_precision: 0.7800 - val_recall: 0.9360 - val_custom_f1: 0.6213 - lr: 2.0589e-04\nEpoch 17/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3668 - accuracy: 0.8492 - precision: 0.8430 - recall: 0.8717 - custom_f1: 0.8540\nEpoch 17: val_loss improved from 0.34458 to 0.33711, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3568 - accuracy: 0.8500 - precision: 0.8277 - recall: 0.8840 - custom_f1: 0.8510 - val_loss: 0.3371 - val_accuracy: 0.8320 - val_precision: 0.7785 - val_recall: 0.9280 - val_custom_f1: 0.6191 - lr: 1.8530e-04\nEpoch 18/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3109 - accuracy: 0.8750 - precision: 0.8542 - recall: 0.9011 - custom_f1: 0.8757\nEpoch 18: val_loss improved from 0.33711 to 0.33197, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3298 - accuracy: 0.8650 - precision: 0.8489 - recall: 0.8880 - custom_f1: 0.8624 - val_loss: 0.3320 - val_accuracy: 0.8480 - val_precision: 0.7919 - val_recall: 0.9440 - val_custom_f1: 0.6345 - lr: 1.6677e-04\nEpoch 19/300\n31/32 [============================>.] - ETA: 0s - loss: 0.3416 - accuracy: 0.8538 - precision: 0.8311 - recall: 0.8896 - custom_f1: 0.8578\nEpoch 19: val_loss improved from 0.33197 to 0.32220, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.8530 - precision: 0.8299 - recall: 0.8880 - custom_f1: 0.8466 - val_loss: 0.3222 - val_accuracy: 0.8600 - val_precision: 0.8000 - val_recall: 0.9600 - val_custom_f1: 0.6446 - lr: 1.5009e-04\nEpoch 20/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3337 - accuracy: 0.8587 - precision: 0.8507 - recall: 0.8692 - custom_f1: 0.8570\nEpoch 20: val_loss improved from 0.32220 to 0.31982, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3340 - accuracy: 0.8530 - precision: 0.8414 - recall: 0.8700 - custom_f1: 0.8530 - val_loss: 0.3198 - val_accuracy: 0.8480 - val_precision: 0.7843 - val_recall: 0.9600 - val_custom_f1: 0.6244 - lr: 1.3509e-04\nEpoch 21/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3107 - accuracy: 0.8750 - precision: 0.8450 - recall: 0.9185 - custom_f1: 0.8778\nEpoch 21: val_loss improved from 0.31982 to 0.31806, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.8610 - precision: 0.8336 - recall: 0.9020 - custom_f1: 0.8529 - val_loss: 0.3181 - val_accuracy: 0.8480 - val_precision: 0.7881 - val_recall: 0.9520 - val_custom_f1: 0.6234 - lr: 1.2158e-04\nEpoch 22/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3330 - accuracy: 0.8601 - precision: 0.8303 - recall: 0.8933 - custom_f1: 0.8596\nEpoch 22: val_loss improved from 0.31806 to 0.30699, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3411 - accuracy: 0.8610 - precision: 0.8412 - recall: 0.8900 - custom_f1: 0.8668 - val_loss: 0.3070 - val_accuracy: 0.8640 - val_precision: 0.8095 - val_recall: 0.9520 - val_custom_f1: 0.6561 - lr: 1.0942e-04\nEpoch 23/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3403 - accuracy: 0.8505 - precision: 0.8400 - recall: 0.8796 - custom_f1: 0.8570\nEpoch 23: val_loss improved from 0.30699 to 0.30349, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3453 - accuracy: 0.8430 - precision: 0.8254 - recall: 0.8700 - custom_f1: 0.8486 - val_loss: 0.3035 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 9.8477e-05\nEpoch 24/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3416 - accuracy: 0.8410 - precision: 0.8070 - recall: 0.8895 - custom_f1: 0.8407\nEpoch 24: val_loss improved from 0.30349 to 0.30097, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3403 - accuracy: 0.8480 - precision: 0.8246 - recall: 0.8840 - custom_f1: 0.8485 - val_loss: 0.3010 - val_accuracy: 0.8640 - val_precision: 0.8095 - val_recall: 0.9520 - val_custom_f1: 0.6561 - lr: 8.8629e-05\nEpoch 25/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3341 - accuracy: 0.8465 - precision: 0.8364 - recall: 0.8656 - custom_f1: 0.8454\nEpoch 25: val_loss did not improve from 0.30097\n32/32 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.8450 - precision: 0.8261 - recall: 0.8740 - custom_f1: 0.8450 - val_loss: 0.3013 - val_accuracy: 0.8640 - val_precision: 0.8095 - val_recall: 0.9520 - val_custom_f1: 0.6561 - lr: 7.9766e-05\nEpoch 26/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3319 - accuracy: 0.8601 - precision: 0.8512 - recall: 0.8763 - custom_f1: 0.8624\nEpoch 26: val_loss improved from 0.30097 to 0.29789, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3376 - accuracy: 0.8560 - precision: 0.8423 - recall: 0.8760 - custom_f1: 0.8539 - val_loss: 0.2979 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 7.1790e-05\nEpoch 27/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3145 - accuracy: 0.8776 - precision: 0.8571 - recall: 0.9062 - custom_f1: 0.8772\nEpoch 27: val_loss did not improve from 0.29789\n32/32 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.8730 - precision: 0.8526 - recall: 0.9020 - custom_f1: 0.8673 - val_loss: 0.2987 - val_accuracy: 0.8640 - val_precision: 0.8095 - val_recall: 0.9520 - val_custom_f1: 0.6561 - lr: 6.4611e-05\nEpoch 28/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3216 - accuracy: 0.8492 - precision: 0.8125 - recall: 0.9003 - custom_f1: 0.8497\nEpoch 28: val_loss improved from 0.29789 to 0.29425, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.8520 - precision: 0.8212 - recall: 0.9000 - custom_f1: 0.8550 - val_loss: 0.2942 - val_accuracy: 0.8760 - val_precision: 0.8264 - val_recall: 0.9520 - val_custom_f1: 0.6642 - lr: 5.8150e-05\nEpoch 29/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3427 - accuracy: 0.8516 - precision: 0.8168 - recall: 0.8919 - custom_f1: 0.8500\nEpoch 29: val_loss improved from 0.29425 to 0.29394, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8580 - precision: 0.8390 - recall: 0.8860 - custom_f1: 0.8587 - val_loss: 0.2939 - val_accuracy: 0.8760 - val_precision: 0.8264 - val_recall: 0.9520 - val_custom_f1: 0.6642 - lr: 5.2335e-05\nEpoch 30/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3290 - accuracy: 0.8682 - precision: 0.8383 - recall: 0.9133 - custom_f1: 0.8721\nEpoch 30: val_loss did not improve from 0.29394\n32/32 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8610 - precision: 0.8374 - recall: 0.8960 - custom_f1: 0.8651 - val_loss: 0.2949 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 4.7101e-05\nEpoch 31/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3275 - accuracy: 0.8659 - precision: 0.8412 - recall: 0.8968 - custom_f1: 0.8644\nEpoch 31: val_loss improved from 0.29394 to 0.29210, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3218 - accuracy: 0.8670 - precision: 0.8456 - recall: 0.8980 - custom_f1: 0.8670 - val_loss: 0.2921 - val_accuracy: 0.8760 - val_precision: 0.8264 - val_recall: 0.9520 - val_custom_f1: 0.6642 - lr: 4.2391e-05\nEpoch 32/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3246 - accuracy: 0.8737 - precision: 0.8554 - recall: 0.8979 - custom_f1: 0.8720\nEpoch 32: val_loss improved from 0.29210 to 0.29060, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.8700 - precision: 0.8491 - recall: 0.9000 - custom_f1: 0.8725 - val_loss: 0.2906 - val_accuracy: 0.8760 - val_precision: 0.8264 - val_recall: 0.9520 - val_custom_f1: 0.6642 - lr: 3.8152e-05\nEpoch 33/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2989 - accuracy: 0.8832 - precision: 0.8711 - recall: 0.8995 - custom_f1: 0.8845\nEpoch 33: val_loss improved from 0.29060 to 0.29005, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3116 - accuracy: 0.8780 - precision: 0.8663 - recall: 0.8940 - custom_f1: 0.8768 - val_loss: 0.2900 - val_accuracy: 0.8760 - val_precision: 0.8264 - val_recall: 0.9520 - val_custom_f1: 0.6642 - lr: 3.4337e-05\nEpoch 34/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3334 - accuracy: 0.8641 - precision: 0.8418 - recall: 0.8967 - custom_f1: 0.8631\nEpoch 34: val_loss did not improve from 0.29005\n32/32 [==============================] - 0s 7ms/step - loss: 0.3343 - accuracy: 0.8580 - precision: 0.8377 - recall: 0.8880 - custom_f1: 0.8575 - val_loss: 0.2901 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 3.0903e-05\nEpoch 35/300\n22/32 [===================>..........] - ETA: 0s - loss: 0.3341 - accuracy: 0.8523 - precision: 0.8231 - recall: 0.8899 - custom_f1: 0.8486\nEpoch 35: val_loss did not improve from 0.29005\n32/32 [==============================] - 0s 7ms/step - loss: 0.3222 - accuracy: 0.8610 - precision: 0.8374 - recall: 0.8960 - custom_f1: 0.8556 - val_loss: 0.2901 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 2.7813e-05\nEpoch 36/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3564 - accuracy: 0.8519 - precision: 0.8203 - recall: 0.8950 - custom_f1: 0.8545\nEpoch 36: val_loss did not improve from 0.29005\n32/32 [==============================] - 0s 6ms/step - loss: 0.3390 - accuracy: 0.8560 - precision: 0.8309 - recall: 0.8940 - custom_f1: 0.8585 - val_loss: 0.2916 - val_accuracy: 0.8760 - val_precision: 0.8219 - val_recall: 0.9600 - val_custom_f1: 0.6628 - lr: 2.5032e-05\nEpoch 37/300\n22/32 [===================>..........] - ETA: 0s - loss: 0.3239 - accuracy: 0.8608 - precision: 0.8541 - recall: 0.8822 - custom_f1: 0.8662\nEpoch 37: val_loss did not improve from 0.29005\n32/32 [==============================] - 0s 7ms/step - loss: 0.3221 - accuracy: 0.8610 - precision: 0.8425 - recall: 0.8880 - custom_f1: 0.8493 - val_loss: 0.2913 - val_accuracy: 0.8720 - val_precision: 0.8163 - val_recall: 0.9600 - val_custom_f1: 0.6614 - lr: 2.2528e-05\nEpoch 38/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3299 - accuracy: 0.8614 - precision: 0.8485 - recall: 0.8889 - custom_f1: 0.8663\nEpoch 38: val_loss did not improve from 0.29005\n32/32 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8640 - precision: 0.8434 - recall: 0.8940 - custom_f1: 0.8589 - val_loss: 0.2902 - val_accuracy: 0.8720 - val_precision: 0.8163 - val_recall: 0.9600 - val_custom_f1: 0.6614 - lr: 2.0276e-05\nEpoch 39/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3374 - accuracy: 0.8668 - precision: 0.8434 - recall: 0.9027 - custom_f1: 0.8697\nEpoch 39: val_loss improved from 0.29005 to 0.28937, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.8610 - precision: 0.8361 - recall: 0.8980 - custom_f1: 0.8639 - val_loss: 0.2894 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 1.8248e-05\nEpoch 40/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3152 - accuracy: 0.8709 - precision: 0.8372 - recall: 0.9139 - custom_f1: 0.8681\nEpoch 40: val_loss improved from 0.28937 to 0.28882, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3178 - accuracy: 0.8710 - precision: 0.8442 - recall: 0.9100 - custom_f1: 0.8703 - val_loss: 0.2888 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 1.6423e-05\nEpoch 41/300\n22/32 [===================>..........] - ETA: 0s - loss: 0.3358 - accuracy: 0.8580 - precision: 0.8449 - recall: 0.8827 - custom_f1: 0.8622\nEpoch 41: val_loss improved from 0.28882 to 0.28859, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3385 - accuracy: 0.8560 - precision: 0.8463 - recall: 0.8700 - custom_f1: 0.8533 - val_loss: 0.2886 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 1.4781e-05\nEpoch 42/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3496 - accuracy: 0.8383 - precision: 0.8179 - recall: 0.8692 - custom_f1: 0.8407\nEpoch 42: val_loss did not improve from 0.28859\n32/32 [==============================] - 0s 6ms/step - loss: 0.3485 - accuracy: 0.8400 - precision: 0.8184 - recall: 0.8740 - custom_f1: 0.8394 - val_loss: 0.2900 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 1.3303e-05\nEpoch 43/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3045 - accuracy: 0.8668 - precision: 0.8409 - recall: 0.9049 - custom_f1: 0.8689\nEpoch 43: val_loss did not improve from 0.28859\n32/32 [==============================] - 0s 6ms/step - loss: 0.3162 - accuracy: 0.8610 - precision: 0.8386 - recall: 0.8940 - custom_f1: 0.8637 - val_loss: 0.2893 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 1.1973e-05\nEpoch 44/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3545 - accuracy: 0.8342 - precision: 0.8187 - recall: 0.8587 - custom_f1: 0.8329\nEpoch 44: val_loss did not improve from 0.28859\n32/32 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.8450 - precision: 0.8273 - recall: 0.8720 - custom_f1: 0.8391 - val_loss: 0.2894 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 1.0775e-05\nEpoch 45/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3275 - accuracy: 0.8560 - precision: 0.8137 - recall: 0.9171 - custom_f1: 0.8579\nEpoch 45: val_loss improved from 0.28859 to 0.28753, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3152 - accuracy: 0.8630 - precision: 0.8270 - recall: 0.9180 - custom_f1: 0.8650 - val_loss: 0.2875 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 9.6977e-06\nEpoch 46/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3182 - accuracy: 0.8655 - precision: 0.8270 - recall: 0.9129 - custom_f1: 0.8638\nEpoch 46: val_loss improved from 0.28753 to 0.28686, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3191 - accuracy: 0.8630 - precision: 0.8367 - recall: 0.9020 - custom_f1: 0.8599 - val_loss: 0.2869 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 8.7280e-06\nEpoch 47/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3207 - accuracy: 0.8533 - precision: 0.8342 - recall: 0.8798 - custom_f1: 0.8544\nEpoch 47: val_loss improved from 0.28686 to 0.28675, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3160 - accuracy: 0.8550 - precision: 0.8381 - recall: 0.8800 - custom_f1: 0.8596 - val_loss: 0.2868 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 7.8552e-06\nEpoch 48/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2932 - accuracy: 0.8945 - precision: 0.8738 - recall: 0.9254 - custom_f1: 0.8935\nEpoch 48: val_loss did not improve from 0.28675\n32/32 [==============================] - 0s 6ms/step - loss: 0.2996 - accuracy: 0.8920 - precision: 0.8726 - recall: 0.9180 - custom_f1: 0.8890 - val_loss: 0.2871 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 7.0697e-06\nEpoch 49/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2980 - accuracy: 0.8620 - precision: 0.8314 - recall: 0.9126 - custom_f1: 0.8661\nEpoch 49: val_loss did not improve from 0.28675\n32/32 [==============================] - 0s 6ms/step - loss: 0.3006 - accuracy: 0.8600 - precision: 0.8333 - recall: 0.9000 - custom_f1: 0.8521 - val_loss: 0.2873 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 6.3627e-06\nEpoch 50/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3185 - accuracy: 0.8655 - precision: 0.8549 - recall: 0.8847 - custom_f1: 0.8681\nEpoch 50: val_loss did not improve from 0.28675\n32/32 [==============================] - 0s 6ms/step - loss: 0.3100 - accuracy: 0.8690 - precision: 0.8501 - recall: 0.8960 - custom_f1: 0.8698 - val_loss: 0.2870 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 5.7264e-06\nEpoch 51/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3161 - accuracy: 0.8659 - precision: 0.8564 - recall: 0.8849 - custom_f1: 0.8687\nEpoch 51: val_loss improved from 0.28675 to 0.28644, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3145 - accuracy: 0.8610 - precision: 0.8438 - recall: 0.8860 - custom_f1: 0.8600 - val_loss: 0.2864 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 5.1538e-06\nEpoch 52/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3275 - accuracy: 0.8625 - precision: 0.8432 - recall: 0.8897 - custom_f1: 0.8655\nEpoch 52: val_loss improved from 0.28644 to 0.28622, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3231 - accuracy: 0.8660 - precision: 0.8466 - recall: 0.8940 - custom_f1: 0.8683 - val_loss: 0.2862 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 4.6384e-06\nEpoch 53/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3261 - accuracy: 0.8838 - precision: 0.8585 - recall: 0.9204 - custom_f1: 0.8832\nEpoch 53: val_loss improved from 0.28622 to 0.28592, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3212 - accuracy: 0.8810 - precision: 0.8615 - recall: 0.9080 - custom_f1: 0.8781 - val_loss: 0.2859 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 4.1746e-06\nEpoch 54/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3151 - accuracy: 0.8763 - precision: 0.8526 - recall: 0.9084 - custom_f1: 0.8766\nEpoch 54: val_loss improved from 0.28592 to 0.28582, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3144 - accuracy: 0.8730 - precision: 0.8552 - recall: 0.8980 - custom_f1: 0.8683 - val_loss: 0.2858 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 3.7571e-06\nEpoch 55/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3300 - accuracy: 0.8607 - precision: 0.8524 - recall: 0.8724 - custom_f1: 0.8614\nEpoch 55: val_loss improved from 0.28582 to 0.28554, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3228 - accuracy: 0.8610 - precision: 0.8478 - recall: 0.8800 - custom_f1: 0.8588 - val_loss: 0.2855 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 3.3814e-06\nEpoch 56/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3242 - accuracy: 0.8711 - precision: 0.8438 - recall: 0.9005 - custom_f1: 0.8704\nEpoch 56: val_loss improved from 0.28554 to 0.28549, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3084 - accuracy: 0.8780 - precision: 0.8607 - recall: 0.9020 - custom_f1: 0.8786 - val_loss: 0.2855 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 3.0433e-06\nEpoch 57/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3017 - accuracy: 0.8750 - precision: 0.8516 - recall: 0.9033 - custom_f1: 0.8732\nEpoch 57: val_loss did not improve from 0.28549\n32/32 [==============================] - 0s 6ms/step - loss: 0.3191 - accuracy: 0.8640 - precision: 0.8421 - recall: 0.8960 - custom_f1: 0.8628 - val_loss: 0.2860 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 2.7389e-06\nEpoch 58/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3171 - accuracy: 0.8685 - precision: 0.8452 - recall: 0.9005 - custom_f1: 0.8641\nEpoch 58: val_loss improved from 0.28549 to 0.28546, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3231 - accuracy: 0.8650 - precision: 0.8476 - recall: 0.8900 - custom_f1: 0.8581 - val_loss: 0.2855 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 2.4650e-06\nEpoch 59/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3205 - accuracy: 0.8802 - precision: 0.8517 - recall: 0.9223 - custom_f1: 0.8815\nEpoch 59: val_loss did not improve from 0.28546\n32/32 [==============================] - 0s 6ms/step - loss: 0.3150 - accuracy: 0.8790 - precision: 0.8503 - recall: 0.9200 - custom_f1: 0.8782 - val_loss: 0.2861 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 2.2185e-06\nEpoch 60/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3273 - accuracy: 0.8682 - precision: 0.8410 - recall: 0.9036 - custom_f1: 0.8630\nEpoch 60: val_loss did not improve from 0.28546\n32/32 [==============================] - 0s 6ms/step - loss: 0.3143 - accuracy: 0.8760 - precision: 0.8561 - recall: 0.9040 - custom_f1: 0.8763 - val_loss: 0.2857 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.9967e-06\nEpoch 61/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3265 - accuracy: 0.8723 - precision: 0.8463 - recall: 0.9106 - custom_f1: 0.8727\nEpoch 61: val_loss improved from 0.28546 to 0.28539, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3237 - accuracy: 0.8660 - precision: 0.8389 - recall: 0.9060 - custom_f1: 0.8686 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.7970e-06\nEpoch 62/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2995 - accuracy: 0.8925 - precision: 0.8756 - recall: 0.9187 - custom_f1: 0.8975\nEpoch 62: val_loss improved from 0.28539 to 0.28520, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3069 - accuracy: 0.8820 - precision: 0.8617 - recall: 0.9100 - custom_f1: 0.8796 - val_loss: 0.2852 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.6173e-06\nEpoch 63/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3072 - accuracy: 0.8841 - precision: 0.8595 - recall: 0.9233 - custom_f1: 0.8878\nEpoch 63: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 6ms/step - loss: 0.3058 - accuracy: 0.8770 - precision: 0.8434 - recall: 0.9260 - custom_f1: 0.8842 - val_loss: 0.2853 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.4556e-06\nEpoch 64/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3239 - accuracy: 0.8575 - precision: 0.8410 - recall: 0.8791 - custom_f1: 0.8576\nEpoch 64: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8620 - precision: 0.8494 - recall: 0.8800 - custom_f1: 0.8653 - val_loss: 0.2858 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.3100e-06\nEpoch 65/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2960 - accuracy: 0.8675 - precision: 0.8383 - recall: 0.9132 - custom_f1: 0.8738\nEpoch 65: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 6ms/step - loss: 0.3070 - accuracy: 0.8650 - precision: 0.8361 - recall: 0.9080 - custom_f1: 0.8717 - val_loss: 0.2853 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.1790e-06\nEpoch 66/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3460 - accuracy: 0.8424 - precision: 0.8333 - recall: 0.8651 - custom_f1: 0.8467\nEpoch 66: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 6ms/step - loss: 0.3419 - accuracy: 0.8420 - precision: 0.8239 - recall: 0.8700 - custom_f1: 0.8457 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.0611e-06\nEpoch 67/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3191 - accuracy: 0.8628 - precision: 0.8367 - recall: 0.8986 - custom_f1: 0.8661\nEpoch 67: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 7ms/step - loss: 0.3220 - accuracy: 0.8630 - precision: 0.8380 - recall: 0.9000 - custom_f1: 0.8713 - val_loss: 0.2853 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 9.5500e-07\nEpoch 68/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3388 - accuracy: 0.8505 - precision: 0.8278 - recall: 0.8822 - custom_f1: 0.8488\nEpoch 68: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 7ms/step - loss: 0.3321 - accuracy: 0.8560 - precision: 0.8284 - recall: 0.8980 - custom_f1: 0.8606 - val_loss: 0.2861 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 8.5950e-07\nEpoch 69/300\n22/32 [===================>..........] - ETA: 0s - loss: 0.3077 - accuracy: 0.8778 - precision: 0.8522 - recall: 0.9109 - custom_f1: 0.8786\nEpoch 69: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 7ms/step - loss: 0.3243 - accuracy: 0.8670 - precision: 0.8482 - recall: 0.8940 - custom_f1: 0.8659 - val_loss: 0.2857 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 7.7355e-07\nEpoch 70/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2876 - accuracy: 0.8776 - precision: 0.8564 - recall: 0.9096 - custom_f1: 0.8796\nEpoch 70: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 6ms/step - loss: 0.3009 - accuracy: 0.8740 - precision: 0.8502 - recall: 0.9080 - custom_f1: 0.8792 - val_loss: 0.2860 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 6.9620e-07\nEpoch 71/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3268 - accuracy: 0.8668 - precision: 0.8408 - recall: 0.9086 - custom_f1: 0.8716\nEpoch 71: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 6ms/step - loss: 0.3251 - accuracy: 0.8660 - precision: 0.8414 - recall: 0.9020 - custom_f1: 0.8449 - val_loss: 0.2859 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 6.2658e-07\nEpoch 72/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3518 - accuracy: 0.8383 - precision: 0.8312 - recall: 0.8598 - custom_f1: 0.8423\nEpoch 72: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.8550 - precision: 0.8368 - recall: 0.8820 - custom_f1: 0.8546 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 5.6392e-07\nEpoch 73/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3169 - accuracy: 0.8736 - precision: 0.8479 - recall: 0.9063 - custom_f1: 0.8720\nEpoch 73: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 6ms/step - loss: 0.3199 - accuracy: 0.8700 - precision: 0.8491 - recall: 0.9000 - custom_f1: 0.8702 - val_loss: 0.2855 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 5.0753e-07\nEpoch 74/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3021 - accuracy: 0.8614 - precision: 0.8399 - recall: 0.8864 - custom_f1: 0.8588\nEpoch 74: val_loss did not improve from 0.28520\n32/32 [==============================] - 0s 6ms/step - loss: 0.3032 - accuracy: 0.8640 - precision: 0.8460 - recall: 0.8900 - custom_f1: 0.8617 - val_loss: 0.2853 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 4.5678e-07\nEpoch 75/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3006 - accuracy: 0.8776 - precision: 0.8516 - recall: 0.9138 - custom_f1: 0.8785\nEpoch 75: val_loss improved from 0.28520 to 0.28515, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.2995 - accuracy: 0.8760 - precision: 0.8547 - recall: 0.9060 - custom_f1: 0.8752 - val_loss: 0.2851 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 4.1110e-07\nEpoch 76/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3091 - accuracy: 0.8698 - precision: 0.8450 - recall: 0.9065 - custom_f1: 0.8721\nEpoch 76: val_loss improved from 0.28515 to 0.28471, saving model to best_hybrid_fold1_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3096 - accuracy: 0.8740 - precision: 0.8515 - recall: 0.9060 - custom_f1: 0.8766 - val_loss: 0.2847 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 3.6999e-07\nEpoch 77/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3203 - accuracy: 0.8568 - precision: 0.8535 - recall: 0.8667 - custom_f1: 0.8537\nEpoch 77: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3167 - accuracy: 0.8620 - precision: 0.8508 - recall: 0.8780 - custom_f1: 0.8577 - val_loss: 0.2887 - val_accuracy: 0.8720 - val_precision: 0.8163 - val_recall: 0.9600 - val_custom_f1: 0.6614 - lr: 3.3299e-07\nEpoch 78/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3184 - accuracy: 0.8620 - precision: 0.8538 - recall: 0.8717 - custom_f1: 0.8607\nEpoch 78: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3234 - accuracy: 0.8630 - precision: 0.8497 - recall: 0.8820 - custom_f1: 0.8636 - val_loss: 0.2879 - val_accuracy: 0.8720 - val_precision: 0.8163 - val_recall: 0.9600 - val_custom_f1: 0.6614 - lr: 2.9969e-07\nEpoch 79/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3105 - accuracy: 0.8594 - precision: 0.8521 - recall: 0.8740 - custom_f1: 0.8590\nEpoch 79: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8530 - precision: 0.8375 - recall: 0.8760 - custom_f1: 0.8508 - val_loss: 0.2871 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 2.6972e-07\nEpoch 80/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3136 - accuracy: 0.8724 - precision: 0.8465 - recall: 0.9048 - custom_f1: 0.8739\nEpoch 80: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3226 - accuracy: 0.8640 - precision: 0.8447 - recall: 0.8920 - custom_f1: 0.8644 - val_loss: 0.2862 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 2.4275e-07\nEpoch 81/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3266 - accuracy: 0.8516 - precision: 0.8321 - recall: 0.8837 - custom_f1: 0.8535\nEpoch 81: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3251 - accuracy: 0.8540 - precision: 0.8302 - recall: 0.8900 - custom_f1: 0.8578 - val_loss: 0.2861 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 2.1847e-07\nEpoch 82/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3186 - accuracy: 0.8600 - precision: 0.8406 - recall: 0.8943 - custom_f1: 0.8647\nEpoch 82: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3163 - accuracy: 0.8590 - precision: 0.8355 - recall: 0.8940 - custom_f1: 0.8630 - val_loss: 0.2865 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.9663e-07\nEpoch 83/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2963 - accuracy: 0.8859 - precision: 0.8546 - recall: 0.9254 - custom_f1: 0.8831\nEpoch 83: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3009 - accuracy: 0.8790 - precision: 0.8516 - recall: 0.9180 - custom_f1: 0.8812 - val_loss: 0.2862 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.7696e-07\nEpoch 84/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3204 - accuracy: 0.8668 - precision: 0.8444 - recall: 0.8995 - custom_f1: 0.8696\nEpoch 84: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3197 - accuracy: 0.8660 - precision: 0.8466 - recall: 0.8940 - custom_f1: 0.8581 - val_loss: 0.2892 - val_accuracy: 0.8720 - val_precision: 0.8163 - val_recall: 0.9600 - val_custom_f1: 0.6614 - lr: 1.5927e-07\nEpoch 85/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3217 - accuracy: 0.8614 - precision: 0.8312 - recall: 0.8964 - custom_f1: 0.8584\nEpoch 85: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3234 - accuracy: 0.8660 - precision: 0.8440 - recall: 0.8980 - custom_f1: 0.8692 - val_loss: 0.2882 - val_accuracy: 0.8720 - val_precision: 0.8163 - val_recall: 0.9600 - val_custom_f1: 0.6614 - lr: 1.4334e-07\nEpoch 86/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3037 - accuracy: 0.8709 - precision: 0.8429 - recall: 0.9020 - custom_f1: 0.8681\nEpoch 86: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3026 - accuracy: 0.8730 - precision: 0.8539 - recall: 0.9000 - custom_f1: 0.8713 - val_loss: 0.2903 - val_accuracy: 0.8640 - val_precision: 0.8095 - val_recall: 0.9520 - val_custom_f1: 0.6561 - lr: 1.2901e-07\nEpoch 87/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3103 - accuracy: 0.8777 - precision: 0.8590 - recall: 0.9014 - custom_f1: 0.8789\nEpoch 87: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3109 - accuracy: 0.8800 - precision: 0.8682 - recall: 0.8960 - custom_f1: 0.8798 - val_loss: 0.2888 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.1611e-07\nEpoch 88/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3175 - accuracy: 0.8698 - precision: 0.8411 - recall: 0.9077 - custom_f1: 0.8703\nEpoch 88: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3147 - accuracy: 0.8710 - precision: 0.8467 - recall: 0.9060 - custom_f1: 0.8761 - val_loss: 0.2877 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 1.0450e-07\nEpoch 89/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3154 - accuracy: 0.8788 - precision: 0.8456 - recall: 0.9244 - custom_f1: 0.8776\nEpoch 89: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3222 - accuracy: 0.8730 - precision: 0.8486 - recall: 0.9080 - custom_f1: 0.8737 - val_loss: 0.2871 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 9.4046e-08\nEpoch 90/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3020 - accuracy: 0.8863 - precision: 0.8632 - recall: 0.9173 - custom_f1: 0.8859\nEpoch 90: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3025 - accuracy: 0.8810 - precision: 0.8561 - recall: 0.9160 - custom_f1: 0.8807 - val_loss: 0.2864 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 8.4641e-08\nEpoch 91/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3309 - accuracy: 0.8607 - precision: 0.8244 - recall: 0.9062 - custom_f1: 0.8596\nEpoch 91: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.8680 - precision: 0.8420 - recall: 0.9060 - custom_f1: 0.8677 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 7.6177e-08\nEpoch 92/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3231 - accuracy: 0.8512 - precision: 0.8337 - recall: 0.8775 - custom_f1: 0.8535\nEpoch 92: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3195 - accuracy: 0.8600 - precision: 0.8422 - recall: 0.8860 - custom_f1: 0.8626 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 6.8560e-08\nEpoch 93/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3336 - accuracy: 0.8478 - precision: 0.8235 - recall: 0.8936 - custom_f1: 0.8527\nEpoch 93: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8550 - precision: 0.8257 - recall: 0.9000 - custom_f1: 0.8568 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 6.1704e-08\nEpoch 94/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3127 - accuracy: 0.8600 - precision: 0.8345 - recall: 0.8972 - custom_f1: 0.8649\nEpoch 94: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3228 - accuracy: 0.8580 - precision: 0.8377 - recall: 0.8880 - custom_f1: 0.8504 - val_loss: 0.2855 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 5.5533e-08\nEpoch 95/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3251 - accuracy: 0.8788 - precision: 0.8565 - recall: 0.9100 - custom_f1: 0.8812\nEpoch 95: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3261 - accuracy: 0.8730 - precision: 0.8499 - recall: 0.9060 - custom_f1: 0.8731 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 4.9980e-08\nEpoch 96/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3277 - accuracy: 0.8725 - precision: 0.8595 - recall: 0.8936 - custom_f1: 0.8683\nEpoch 96: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8640 - precision: 0.8500 - recall: 0.8840 - custom_f1: 0.8590 - val_loss: 0.2860 - val_accuracy: 0.8680 - val_precision: 0.8151 - val_recall: 0.9520 - val_custom_f1: 0.6592 - lr: 4.4982e-08\nEpoch 97/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3288 - accuracy: 0.8687 - precision: 0.8440 - recall: 0.9015 - custom_f1: 0.8687\nEpoch 97: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8610 - precision: 0.8425 - recall: 0.8880 - custom_f1: 0.8545 - val_loss: 0.2860 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 4.0484e-08\nEpoch 98/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2985 - accuracy: 0.8872 - precision: 0.8728 - recall: 0.9122 - custom_f1: 0.8899\nEpoch 98: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.8770 - precision: 0.8550 - recall: 0.9080 - custom_f1: 0.8756 - val_loss: 0.2856 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 3.6435e-08\nEpoch 99/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2853 - accuracy: 0.8788 - precision: 0.8592 - recall: 0.9045 - custom_f1: 0.8795\nEpoch 99: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.2886 - accuracy: 0.8800 - precision: 0.8626 - recall: 0.9040 - custom_f1: 0.8824 - val_loss: 0.2853 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 3.2792e-08\nEpoch 100/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3393 - accuracy: 0.8612 - precision: 0.8310 - recall: 0.8972 - custom_f1: 0.8613\nEpoch 100: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8640 - precision: 0.8447 - recall: 0.8920 - custom_f1: 0.8661 - val_loss: 0.2856 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 2.9513e-08\nEpoch 101/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3109 - accuracy: 0.8750 - precision: 0.8505 - recall: 0.9066 - custom_f1: 0.8756Restoring model weights from the end of the best epoch: 76.\n\nEpoch 101: val_loss did not improve from 0.28471\n32/32 [==============================] - 0s 7ms/step - loss: 0.3166 - accuracy: 0.8730 - precision: 0.8580 - recall: 0.8940 - custom_f1: 0.8729 - val_loss: 0.2854 - val_accuracy: 0.8720 - val_precision: 0.8207 - val_recall: 0.9520 - val_custom_f1: 0.6606 - lr: 2.6561e-08\nEpoch 101: early stopping\n\n===== Fold 2 =====\nTraining Hybrid Model...\nEpoch 1/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.7957 - accuracy: 0.5272 - precision_1: 0.5246 - recall_1: 0.4959 - custom_f1: 0.4940 \nEpoch 1: val_loss improved from inf to 0.64398, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 3s 23ms/step - loss: 0.7474 - accuracy: 0.5700 - precision_1: 0.5726 - recall_1: 0.5520 - custom_f1: 0.5491 - val_loss: 0.6440 - val_accuracy: 0.5760 - val_precision_1: 0.7568 - val_recall_1: 0.2240 - val_custom_f1: 0.2703 - lr: 0.0010\nEpoch 2/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.5737 - accuracy: 0.6997 - precision_1: 0.6931 - recall_1: 0.7285 - custom_f1: 0.7082\nEpoch 2: val_loss improved from 0.64398 to 0.63665, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.5744 - accuracy: 0.7080 - precision_1: 0.7023 - recall_1: 0.7220 - custom_f1: 0.7061 - val_loss: 0.6366 - val_accuracy: 0.5600 - val_precision_1: 0.9412 - val_recall_1: 0.1280 - val_custom_f1: 0.2074 - lr: 9.0000e-04\nEpoch 3/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.5337 - accuracy: 0.7459 - precision_1: 0.7307 - recall_1: 0.7876 - custom_f1: 0.7581\nEpoch 3: val_loss improved from 0.63665 to 0.61812, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.5355 - accuracy: 0.7460 - precision_1: 0.7278 - recall_1: 0.7860 - custom_f1: 0.7549 - val_loss: 0.6181 - val_accuracy: 0.6000 - val_precision_1: 0.8571 - val_recall_1: 0.2400 - val_custom_f1: 0.2968 - lr: 8.1000e-04\nEpoch 4/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.4935 - accuracy: 0.7625 - precision_1: 0.7551 - recall_1: 0.7628 - custom_f1: 0.7559\nEpoch 4: val_loss improved from 0.61812 to 0.57496, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.7630 - precision_1: 0.7689 - recall_1: 0.7520 - custom_f1: 0.7581 - val_loss: 0.5750 - val_accuracy: 0.6880 - val_precision_1: 0.8310 - val_recall_1: 0.4720 - val_custom_f1: 0.4588 - lr: 7.2900e-04\nEpoch 5/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.4558 - accuracy: 0.7875 - precision_1: 0.7573 - recall_1: 0.8446 - custom_f1: 0.7930\nEpoch 5: val_loss improved from 0.57496 to 0.57092, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.7840 - precision_1: 0.7572 - recall_1: 0.8360 - custom_f1: 0.7783 - val_loss: 0.5709 - val_accuracy: 0.6800 - val_precision_1: 0.7711 - val_recall_1: 0.5120 - val_custom_f1: 0.4107 - lr: 6.5610e-04\nEpoch 6/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.4498 - accuracy: 0.7786 - precision_1: 0.7870 - recall_1: 0.7749 - custom_f1: 0.7807\nEpoch 6: val_loss improved from 0.57092 to 0.52694, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4404 - accuracy: 0.7830 - precision_1: 0.7780 - recall_1: 0.7920 - custom_f1: 0.7814 - val_loss: 0.5269 - val_accuracy: 0.7840 - val_precision_1: 0.7710 - val_recall_1: 0.8080 - val_custom_f1: 0.6111 - lr: 5.9049e-04\nEpoch 7/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3968 - accuracy: 0.8288 - precision_1: 0.8068 - recall_1: 0.8722 - custom_f1: 0.8365\nEpoch 7: val_loss improved from 0.52694 to 0.50543, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8250 - precision_1: 0.8037 - recall_1: 0.8600 - custom_f1: 0.8205 - val_loss: 0.5054 - val_accuracy: 0.7680 - val_precision_1: 0.7724 - val_recall_1: 0.7600 - val_custom_f1: 0.5751 - lr: 5.3144e-04\nEpoch 8/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3986 - accuracy: 0.8213 - precision_1: 0.8106 - recall_1: 0.8408 - custom_f1: 0.8231\nEpoch 8: val_loss improved from 0.50543 to 0.48383, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8190 - precision_1: 0.8085 - recall_1: 0.8360 - custom_f1: 0.8236 - val_loss: 0.4838 - val_accuracy: 0.8080 - val_precision_1: 0.7770 - val_recall_1: 0.8640 - val_custom_f1: 0.6262 - lr: 4.7830e-04\nEpoch 9/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.4028 - accuracy: 0.8073 - precision_1: 0.7886 - recall_1: 0.8342 - custom_f1: 0.8084\nEpoch 9: val_loss improved from 0.48383 to 0.46009, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3999 - accuracy: 0.8120 - precision_1: 0.7966 - recall_1: 0.8380 - custom_f1: 0.8180 - val_loss: 0.4601 - val_accuracy: 0.8240 - val_precision_1: 0.7793 - val_recall_1: 0.9040 - val_custom_f1: 0.6350 - lr: 4.3047e-04\nEpoch 10/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.4042 - accuracy: 0.8037 - precision_1: 0.7799 - recall_1: 0.8409 - custom_f1: 0.8076\nEpoch 10: val_loss improved from 0.46009 to 0.44538, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8100 - precision_1: 0.7969 - recall_1: 0.8320 - custom_f1: 0.8112 - val_loss: 0.4454 - val_accuracy: 0.8240 - val_precision_1: 0.7832 - val_recall_1: 0.8960 - val_custom_f1: 0.6375 - lr: 3.8742e-04\nEpoch 11/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3784 - accuracy: 0.8313 - precision_1: 0.8190 - recall_1: 0.8610 - custom_f1: 0.8379\nEpoch 11: val_loss improved from 0.44538 to 0.43645, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8300 - precision_1: 0.8125 - recall_1: 0.8580 - custom_f1: 0.8338 - val_loss: 0.4364 - val_accuracy: 0.8120 - val_precision_1: 0.7708 - val_recall_1: 0.8880 - val_custom_f1: 0.6278 - lr: 3.4868e-04\nEpoch 12/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3611 - accuracy: 0.8450 - precision_1: 0.8246 - recall_1: 0.8744 - custom_f1: 0.8451\nEpoch 12: val_loss improved from 0.43645 to 0.42071, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8390 - precision_1: 0.8253 - recall_1: 0.8600 - custom_f1: 0.8418 - val_loss: 0.4207 - val_accuracy: 0.8280 - val_precision_1: 0.7770 - val_recall_1: 0.9200 - val_custom_f1: 0.6385 - lr: 3.1381e-04\nEpoch 13/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3875 - accuracy: 0.8275 - precision_1: 0.8115 - recall_1: 0.8631 - custom_f1: 0.8360\nEpoch 13: val_loss improved from 0.42071 to 0.41250, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.8210 - precision_1: 0.7956 - recall_1: 0.8640 - custom_f1: 0.8224 - val_loss: 0.4125 - val_accuracy: 0.8240 - val_precision_1: 0.7647 - val_recall_1: 0.9360 - val_custom_f1: 0.6332 - lr: 2.8243e-04\nEpoch 14/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3777 - accuracy: 0.8275 - precision_1: 0.8064 - recall_1: 0.8698 - custom_f1: 0.8316\nEpoch 14: val_loss improved from 0.41250 to 0.40724, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3632 - accuracy: 0.8360 - precision_1: 0.8088 - recall_1: 0.8800 - custom_f1: 0.8421 - val_loss: 0.4072 - val_accuracy: 0.8240 - val_precision_1: 0.7647 - val_recall_1: 0.9360 - val_custom_f1: 0.6329 - lr: 2.5419e-04\nEpoch 15/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3490 - accuracy: 0.8581 - precision_1: 0.8440 - recall_1: 0.8730 - custom_f1: 0.8561\nEpoch 15: val_loss improved from 0.40724 to 0.39917, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3448 - accuracy: 0.8550 - precision_1: 0.8433 - recall_1: 0.8720 - custom_f1: 0.8550 - val_loss: 0.3992 - val_accuracy: 0.8280 - val_precision_1: 0.7697 - val_recall_1: 0.9360 - val_custom_f1: 0.6377 - lr: 2.2877e-04\nEpoch 16/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3387 - accuracy: 0.8475 - precision_1: 0.8119 - recall_1: 0.8985 - custom_f1: 0.8432\nEpoch 16: val_loss improved from 0.39917 to 0.39575, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3467 - accuracy: 0.8460 - precision_1: 0.8228 - recall_1: 0.8820 - custom_f1: 0.8371 - val_loss: 0.3957 - val_accuracy: 0.8200 - val_precision_1: 0.7632 - val_recall_1: 0.9280 - val_custom_f1: 0.6336 - lr: 2.0589e-04\nEpoch 17/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3409 - accuracy: 0.8478 - precision_1: 0.8313 - recall_1: 0.8877 - custom_f1: 0.8553\nEpoch 17: val_loss improved from 0.39575 to 0.39526, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3502 - accuracy: 0.8440 - precision_1: 0.8162 - recall_1: 0.8880 - custom_f1: 0.8496 - val_loss: 0.3953 - val_accuracy: 0.8200 - val_precision_1: 0.7532 - val_recall_1: 0.9520 - val_custom_f1: 0.6302 - lr: 1.8530e-04\nEpoch 18/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3251 - accuracy: 0.8662 - precision_1: 0.8424 - recall_1: 0.8995 - custom_f1: 0.8678\nEpoch 18: val_loss improved from 0.39526 to 0.38614, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3377 - accuracy: 0.8580 - precision_1: 0.8365 - recall_1: 0.8900 - custom_f1: 0.8590 - val_loss: 0.3861 - val_accuracy: 0.8240 - val_precision_1: 0.7613 - val_recall_1: 0.9440 - val_custom_f1: 0.6348 - lr: 1.6677e-04\nEpoch 19/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3219 - accuracy: 0.8614 - precision_1: 0.8271 - recall_1: 0.9091 - custom_f1: 0.8604\nEpoch 19: val_loss did not improve from 0.38614\n32/32 [==============================] - 0s 7ms/step - loss: 0.3159 - accuracy: 0.8620 - precision_1: 0.8352 - recall_1: 0.9020 - custom_f1: 0.8649 - val_loss: 0.3873 - val_accuracy: 0.8320 - val_precision_1: 0.7677 - val_recall_1: 0.9520 - val_custom_f1: 0.6380 - lr: 1.5009e-04\nEpoch 20/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3416 - accuracy: 0.8546 - precision_1: 0.8372 - recall_1: 0.8804 - custom_f1: 0.8557\nEpoch 20: val_loss did not improve from 0.38614\n32/32 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8540 - precision_1: 0.8404 - recall_1: 0.8740 - custom_f1: 0.8539 - val_loss: 0.3871 - val_accuracy: 0.8320 - val_precision_1: 0.7677 - val_recall_1: 0.9520 - val_custom_f1: 0.6394 - lr: 1.3509e-04\nEpoch 21/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3409 - accuracy: 0.8490 - precision_1: 0.8313 - recall_1: 0.8747 - custom_f1: 0.8481\nEpoch 21: val_loss did not improve from 0.38614\n32/32 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.8530 - precision_1: 0.8311 - recall_1: 0.8860 - custom_f1: 0.8293 - val_loss: 0.3901 - val_accuracy: 0.8200 - val_precision_1: 0.7532 - val_recall_1: 0.9520 - val_custom_f1: 0.6302 - lr: 1.2158e-04\nEpoch 22/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3329 - accuracy: 0.8519 - precision_1: 0.8184 - recall_1: 0.9014 - custom_f1: 0.8568\nEpoch 22: val_loss improved from 0.38614 to 0.38358, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3202 - accuracy: 0.8600 - precision_1: 0.8309 - recall_1: 0.9040 - custom_f1: 0.8650 - val_loss: 0.3836 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6460 - lr: 1.0942e-04\nEpoch 23/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3172 - accuracy: 0.8841 - precision_1: 0.8844 - recall_1: 0.8911 - custom_f1: 0.8877\nEpoch 23: val_loss improved from 0.38358 to 0.38346, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3172 - accuracy: 0.8840 - precision_1: 0.8735 - recall_1: 0.8980 - custom_f1: 0.8870 - val_loss: 0.3835 - val_accuracy: 0.8400 - val_precision_1: 0.7778 - val_recall_1: 0.9520 - val_custom_f1: 0.6485 - lr: 9.8477e-05\nEpoch 24/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3071 - accuracy: 0.8655 - precision_1: 0.8460 - recall_1: 0.8901 - custom_f1: 0.8658\nEpoch 24: val_loss improved from 0.38346 to 0.38309, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3066 - accuracy: 0.8660 - precision_1: 0.8492 - recall_1: 0.8900 - custom_f1: 0.8654 - val_loss: 0.3831 - val_accuracy: 0.8320 - val_precision_1: 0.7677 - val_recall_1: 0.9520 - val_custom_f1: 0.6394 - lr: 8.8629e-05\nEpoch 25/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3374 - accuracy: 0.8451 - precision_1: 0.8268 - recall_1: 0.8760 - custom_f1: 0.8476\nEpoch 25: val_loss improved from 0.38309 to 0.37962, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3251 - accuracy: 0.8580 - precision_1: 0.8403 - recall_1: 0.8840 - custom_f1: 0.8636 - val_loss: 0.3796 - val_accuracy: 0.8280 - val_precision_1: 0.7662 - val_recall_1: 0.9440 - val_custom_f1: 0.6373 - lr: 7.9766e-05\nEpoch 26/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3439 - accuracy: 0.8383 - precision_1: 0.8044 - recall_1: 0.8940 - custom_f1: 0.8447\nEpoch 26: val_loss improved from 0.37962 to 0.37453, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3178 - accuracy: 0.8590 - precision_1: 0.8270 - recall_1: 0.9080 - custom_f1: 0.8675 - val_loss: 0.3745 - val_accuracy: 0.8440 - val_precision_1: 0.7905 - val_recall_1: 0.9360 - val_custom_f1: 0.6510 - lr: 7.1790e-05\nEpoch 27/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3053 - accuracy: 0.8668 - precision_1: 0.8346 - recall_1: 0.9123 - custom_f1: 0.8687\nEpoch 27: val_loss did not improve from 0.37453\n32/32 [==============================] - 0s 6ms/step - loss: 0.3101 - accuracy: 0.8650 - precision_1: 0.8373 - recall_1: 0.9060 - custom_f1: 0.8624 - val_loss: 0.3753 - val_accuracy: 0.8440 - val_precision_1: 0.7867 - val_recall_1: 0.9440 - val_custom_f1: 0.6484 - lr: 6.4611e-05\nEpoch 28/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3285 - accuracy: 0.8546 - precision_1: 0.8333 - recall_1: 0.8815 - custom_f1: 0.8535\nEpoch 28: val_loss improved from 0.37453 to 0.37386, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.8580 - precision_1: 0.8442 - recall_1: 0.8780 - custom_f1: 0.8544 - val_loss: 0.3739 - val_accuracy: 0.8440 - val_precision_1: 0.7905 - val_recall_1: 0.9360 - val_custom_f1: 0.6487 - lr: 5.8150e-05\nEpoch 29/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3102 - accuracy: 0.8682 - precision_1: 0.8329 - recall_1: 0.9062 - custom_f1: 0.8661\nEpoch 29: val_loss improved from 0.37386 to 0.37231, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3086 - accuracy: 0.8700 - precision_1: 0.8531 - recall_1: 0.8940 - custom_f1: 0.8681 - val_loss: 0.3723 - val_accuracy: 0.8400 - val_precision_1: 0.7852 - val_recall_1: 0.9360 - val_custom_f1: 0.6482 - lr: 5.2335e-05\nEpoch 30/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3256 - accuracy: 0.8682 - precision_1: 0.8469 - recall_1: 0.8997 - custom_f1: 0.8691\nEpoch 30: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 7ms/step - loss: 0.3299 - accuracy: 0.8650 - precision_1: 0.8476 - recall_1: 0.8900 - custom_f1: 0.8623 - val_loss: 0.3749 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 4.7101e-05\nEpoch 31/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2921 - accuracy: 0.8913 - precision_1: 0.8619 - recall_1: 0.9284 - custom_f1: 0.8916\nEpoch 31: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 7ms/step - loss: 0.3062 - accuracy: 0.8810 - precision_1: 0.8561 - recall_1: 0.9160 - custom_f1: 0.8855 - val_loss: 0.3747 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 4.2391e-05\nEpoch 32/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3042 - accuracy: 0.8655 - precision_1: 0.8500 - recall_1: 0.8849 - custom_f1: 0.8675\nEpoch 32: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 7ms/step - loss: 0.3164 - accuracy: 0.8620 - precision_1: 0.8535 - recall_1: 0.8740 - custom_f1: 0.8570 - val_loss: 0.3767 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 3.8152e-05\nEpoch 33/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3010 - accuracy: 0.8791 - precision_1: 0.8668 - recall_1: 0.8973 - custom_f1: 0.8796\nEpoch 33: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8640 - precision_1: 0.8487 - recall_1: 0.8860 - custom_f1: 0.8660 - val_loss: 0.3783 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 3.4337e-05\nEpoch 34/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3171 - accuracy: 0.8672 - precision_1: 0.8407 - recall_1: 0.9026 - custom_f1: 0.8681\nEpoch 34: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3152 - accuracy: 0.8650 - precision_1: 0.8411 - recall_1: 0.9000 - custom_f1: 0.8678 - val_loss: 0.3754 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 3.0903e-05\nEpoch 35/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3132 - accuracy: 0.8696 - precision_1: 0.8462 - recall_1: 0.8936 - custom_f1: 0.8671\nEpoch 35: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 7ms/step - loss: 0.3162 - accuracy: 0.8620 - precision_1: 0.8428 - recall_1: 0.8900 - custom_f1: 0.8583 - val_loss: 0.3745 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 2.7813e-05\nEpoch 36/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3103 - accuracy: 0.8763 - precision_1: 0.8389 - recall_1: 0.9257 - custom_f1: 0.8793\nEpoch 36: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3026 - accuracy: 0.8820 - precision_1: 0.8537 - recall_1: 0.9220 - custom_f1: 0.8855 - val_loss: 0.3724 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 2.5032e-05\nEpoch 37/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2945 - accuracy: 0.8775 - precision_1: 0.8696 - recall_1: 0.8911 - custom_f1: 0.8785\nEpoch 37: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.2906 - accuracy: 0.8780 - precision_1: 0.8677 - recall_1: 0.8920 - custom_f1: 0.8765 - val_loss: 0.3739 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 2.2528e-05\nEpoch 38/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3040 - accuracy: 0.8723 - precision_1: 0.8620 - recall_1: 0.8898 - custom_f1: 0.8734\nEpoch 38: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.2973 - accuracy: 0.8730 - precision_1: 0.8566 - recall_1: 0.8960 - custom_f1: 0.8722 - val_loss: 0.3743 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 2.0276e-05\nEpoch 39/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2942 - accuracy: 0.8845 - precision_1: 0.8603 - recall_1: 0.9225 - custom_f1: 0.8869\nEpoch 39: ReduceLROnPlateau reducing learning rate to 9.12400173547212e-06.\n\nEpoch 39: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3029 - accuracy: 0.8810 - precision_1: 0.8561 - recall_1: 0.9160 - custom_f1: 0.8859 - val_loss: 0.3730 - val_accuracy: 0.8320 - val_precision_1: 0.7748 - val_recall_1: 0.9360 - val_custom_f1: 0.6412 - lr: 9.1240e-06\nEpoch 40/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2913 - accuracy: 0.8804 - precision_1: 0.8505 - recall_1: 0.9167 - custom_f1: 0.8772\nEpoch 40: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 7ms/step - loss: 0.3199 - accuracy: 0.8730 - precision_1: 0.8539 - recall_1: 0.9000 - custom_f1: 0.8720 - val_loss: 0.3735 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.6423e-05\nEpoch 41/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2936 - accuracy: 0.8723 - precision_1: 0.8481 - recall_1: 0.9079 - custom_f1: 0.8730\nEpoch 41: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 7ms/step - loss: 0.3052 - accuracy: 0.8630 - precision_1: 0.8457 - recall_1: 0.8880 - custom_f1: 0.8617 - val_loss: 0.3728 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.4781e-05\nEpoch 42/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2982 - accuracy: 0.8777 - precision_1: 0.8658 - recall_1: 0.8940 - custom_f1: 0.8758\nEpoch 42: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 7ms/step - loss: 0.2891 - accuracy: 0.8800 - precision_1: 0.8640 - recall_1: 0.9020 - custom_f1: 0.8761 - val_loss: 0.3735 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 1.3303e-05\nEpoch 43/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3020 - accuracy: 0.8750 - precision_1: 0.8575 - recall_1: 0.8965 - custom_f1: 0.8742\nEpoch 43: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.2888 - accuracy: 0.8840 - precision_1: 0.8678 - recall_1: 0.9060 - custom_f1: 0.8844 - val_loss: 0.3732 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.1973e-05\nEpoch 44/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3371 - accuracy: 0.8723 - precision_1: 0.8575 - recall_1: 0.8946 - custom_f1: 0.8734\nEpoch 44: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3145 - accuracy: 0.8820 - precision_1: 0.8659 - recall_1: 0.9040 - custom_f1: 0.8849 - val_loss: 0.3732 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.0775e-05\nEpoch 45/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3038 - accuracy: 0.8620 - precision_1: 0.8407 - recall_1: 0.8932 - custom_f1: 0.8658\nEpoch 45: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.2958 - accuracy: 0.8730 - precision_1: 0.8499 - recall_1: 0.9060 - custom_f1: 0.8750 - val_loss: 0.3733 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 9.6977e-06\nEpoch 46/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2837 - accuracy: 0.8791 - precision_1: 0.8321 - recall_1: 0.9379 - custom_f1: 0.8733\nEpoch 46: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.2946 - accuracy: 0.8770 - precision_1: 0.8421 - recall_1: 0.9280 - custom_f1: 0.8790 - val_loss: 0.3733 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 8.7280e-06\nEpoch 47/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3043 - accuracy: 0.8736 - precision_1: 0.8456 - recall_1: 0.9126 - custom_f1: 0.8768\nEpoch 47: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3028 - accuracy: 0.8730 - precision_1: 0.8473 - recall_1: 0.9100 - custom_f1: 0.8759 - val_loss: 0.3726 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 7.8552e-06\nEpoch 48/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2883 - accuracy: 0.8763 - precision_1: 0.8596 - recall_1: 0.8979 - custom_f1: 0.8696\nEpoch 48: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3005 - accuracy: 0.8710 - precision_1: 0.8533 - recall_1: 0.8960 - custom_f1: 0.8701 - val_loss: 0.3735 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 7.0697e-06\nEpoch 49/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3070 - accuracy: 0.8675 - precision_1: 0.8406 - recall_1: 0.9077 - custom_f1: 0.8690\nEpoch 49: ReduceLROnPlateau reducing learning rate to 3.181342663083342e-06.\n\nEpoch 49: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3088 - accuracy: 0.8670 - precision_1: 0.8430 - recall_1: 0.9020 - custom_f1: 0.8560 - val_loss: 0.3738 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 3.1813e-06\nEpoch 50/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3104 - accuracy: 0.8675 - precision_1: 0.8534 - recall_1: 0.8875 - custom_f1: 0.8695\nEpoch 50: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3054 - accuracy: 0.8690 - precision_1: 0.8541 - recall_1: 0.8900 - custom_f1: 0.8667 - val_loss: 0.3735 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 5.7264e-06\nEpoch 51/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2970 - accuracy: 0.8854 - precision_1: 0.8838 - recall_1: 0.8929 - custom_f1: 0.8860\nEpoch 51: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.8770 - precision_1: 0.8646 - recall_1: 0.8940 - custom_f1: 0.8800 - val_loss: 0.3731 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 5.1538e-06\nEpoch 52/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2898 - accuracy: 0.8815 - precision_1: 0.8633 - recall_1: 0.9021 - custom_f1: 0.8812\nEpoch 52: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3003 - accuracy: 0.8800 - precision_1: 0.8654 - recall_1: 0.9000 - custom_f1: 0.8807 - val_loss: 0.3726 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 4.6384e-06\nEpoch 53/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3156 - accuracy: 0.8641 - precision_1: 0.8380 - recall_1: 0.9019 - custom_f1: 0.8631\nEpoch 53: val_loss did not improve from 0.37231\n32/32 [==============================] - 0s 6ms/step - loss: 0.3034 - accuracy: 0.8710 - precision_1: 0.8467 - recall_1: 0.9060 - custom_f1: 0.8701 - val_loss: 0.3728 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 4.1746e-06\nEpoch 54/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2886 - accuracy: 0.8763 - precision_1: 0.8618 - recall_1: 0.8956 - custom_f1: 0.8783\nEpoch 54: val_loss improved from 0.37231 to 0.37230, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.2948 - accuracy: 0.8720 - precision_1: 0.8577 - recall_1: 0.8920 - custom_f1: 0.8721 - val_loss: 0.3723 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 3.7571e-06\nEpoch 55/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2992 - accuracy: 0.8867 - precision_1: 0.8676 - recall_1: 0.9147 - custom_f1: 0.8879\nEpoch 55: val_loss improved from 0.37230 to 0.37220, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.2926 - accuracy: 0.8940 - precision_1: 0.8731 - recall_1: 0.9220 - custom_f1: 0.8960 - val_loss: 0.3722 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 3.3814e-06\nEpoch 56/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3125 - accuracy: 0.8581 - precision_1: 0.8243 - recall_1: 0.8976 - custom_f1: 0.8561\nEpoch 56: val_loss improved from 0.37220 to 0.37162, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3093 - accuracy: 0.8570 - precision_1: 0.8400 - recall_1: 0.8820 - custom_f1: 0.8547 - val_loss: 0.3716 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 3.0433e-06\nEpoch 57/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3268 - accuracy: 0.8668 - precision_1: 0.8425 - recall_1: 0.8942 - custom_f1: 0.8659\nEpoch 57: val_loss improved from 0.37162 to 0.37150, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3146 - accuracy: 0.8700 - precision_1: 0.8491 - recall_1: 0.9000 - custom_f1: 0.8748 - val_loss: 0.3715 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 2.7389e-06\nEpoch 58/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2993 - accuracy: 0.8804 - precision_1: 0.8608 - recall_1: 0.9076 - custom_f1: 0.8789\nEpoch 58: val_loss improved from 0.37150 to 0.37145, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.2991 - accuracy: 0.8770 - precision_1: 0.8577 - recall_1: 0.9040 - custom_f1: 0.8749 - val_loss: 0.3714 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 2.4650e-06\nEpoch 59/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2970 - accuracy: 0.8764 - precision_1: 0.8545 - recall_1: 0.9038 - custom_f1: 0.8757\nEpoch 59: val_loss improved from 0.37145 to 0.37126, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3080 - accuracy: 0.8770 - precision_1: 0.8550 - recall_1: 0.9080 - custom_f1: 0.8750 - val_loss: 0.3713 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 2.2185e-06\nEpoch 60/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3024 - accuracy: 0.8723 - precision_1: 0.8475 - recall_1: 0.9036 - custom_f1: 0.8720\nEpoch 60: val_loss did not improve from 0.37126\n32/32 [==============================] - 0s 6ms/step - loss: 0.3003 - accuracy: 0.8730 - precision_1: 0.8552 - recall_1: 0.8980 - custom_f1: 0.8707 - val_loss: 0.3715 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 1.9967e-06\nEpoch 61/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3007 - accuracy: 0.8750 - precision_1: 0.8602 - recall_1: 0.8985 - custom_f1: 0.8757\nEpoch 61: val_loss did not improve from 0.37126\n32/32 [==============================] - 0s 6ms/step - loss: 0.3034 - accuracy: 0.8730 - precision_1: 0.8607 - recall_1: 0.8900 - custom_f1: 0.8723 - val_loss: 0.3724 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.7970e-06\nEpoch 62/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3002 - accuracy: 0.8723 - precision_1: 0.8489 - recall_1: 0.9084 - custom_f1: 0.8789\nEpoch 62: val_loss did not improve from 0.37126\n32/32 [==============================] - 0s 6ms/step - loss: 0.2978 - accuracy: 0.8800 - precision_1: 0.8598 - recall_1: 0.9080 - custom_f1: 0.8839 - val_loss: 0.3720 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 1.6173e-06\nEpoch 63/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2873 - accuracy: 0.8777 - precision_1: 0.8590 - recall_1: 0.9054 - custom_f1: 0.8784\nEpoch 63: val_loss did not improve from 0.37126\n32/32 [==============================] - 0s 6ms/step - loss: 0.2941 - accuracy: 0.8730 - precision_1: 0.8499 - recall_1: 0.9060 - custom_f1: 0.8693 - val_loss: 0.3721 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.4556e-06\nEpoch 64/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2860 - accuracy: 0.8818 - precision_1: 0.8550 - recall_1: 0.9180 - custom_f1: 0.8824\nEpoch 64: val_loss did not improve from 0.37126\n32/32 [==============================] - 0s 6ms/step - loss: 0.2946 - accuracy: 0.8830 - precision_1: 0.8634 - recall_1: 0.9100 - custom_f1: 0.8816 - val_loss: 0.3721 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.3100e-06\nEpoch 65/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2965 - accuracy: 0.8723 - precision_1: 0.8460 - recall_1: 0.9103 - custom_f1: 0.8741\nEpoch 65: val_loss did not improve from 0.37126\n32/32 [==============================] - 0s 6ms/step - loss: 0.2979 - accuracy: 0.8720 - precision_1: 0.8536 - recall_1: 0.8980 - custom_f1: 0.8643 - val_loss: 0.3720 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 1.1790e-06\nEpoch 66/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3084 - accuracy: 0.8594 - precision_1: 0.8526 - recall_1: 0.8785 - custom_f1: 0.8627\nEpoch 66: val_loss did not improve from 0.37126\n32/32 [==============================] - 0s 6ms/step - loss: 0.2996 - accuracy: 0.8640 - precision_1: 0.8487 - recall_1: 0.8860 - custom_f1: 0.8656 - val_loss: 0.3713 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.0611e-06\nEpoch 67/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3029 - accuracy: 0.8750 - precision_1: 0.8575 - recall_1: 0.9018 - custom_f1: 0.8777\nEpoch 67: val_loss improved from 0.37126 to 0.37115, saving model to best_hybrid_fold2_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3030 - accuracy: 0.8790 - precision_1: 0.8610 - recall_1: 0.9040 - custom_f1: 0.8772 - val_loss: 0.3711 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 9.5500e-07\nEpoch 68/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2990 - accuracy: 0.8845 - precision_1: 0.8773 - recall_1: 0.8940 - custom_f1: 0.8842\nEpoch 68: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 7ms/step - loss: 0.3008 - accuracy: 0.8780 - precision_1: 0.8677 - recall_1: 0.8920 - custom_f1: 0.8710 - val_loss: 0.3712 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 8.5950e-07\nEpoch 69/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3181 - accuracy: 0.8628 - precision_1: 0.8376 - recall_1: 0.8953 - custom_f1: 0.8622\nEpoch 69: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 7ms/step - loss: 0.3101 - accuracy: 0.8650 - precision_1: 0.8450 - recall_1: 0.8940 - custom_f1: 0.8633 - val_loss: 0.3712 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 7.7355e-07\nEpoch 70/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3042 - accuracy: 0.8655 - precision_1: 0.8321 - recall_1: 0.9121 - custom_f1: 0.8655\nEpoch 70: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3019 - accuracy: 0.8700 - precision_1: 0.8451 - recall_1: 0.9060 - custom_f1: 0.8655 - val_loss: 0.3713 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 6.9620e-07\nEpoch 71/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2923 - accuracy: 0.8777 - precision_1: 0.8663 - recall_1: 0.8987 - custom_f1: 0.8803\nEpoch 71: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.2958 - accuracy: 0.8750 - precision_1: 0.8613 - recall_1: 0.8940 - custom_f1: 0.8776 - val_loss: 0.3718 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 6.2658e-07\nEpoch 72/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2968 - accuracy: 0.8655 - precision_1: 0.8546 - recall_1: 0.8886 - custom_f1: 0.8682\nEpoch 72: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3099 - accuracy: 0.8620 - precision_1: 0.8415 - recall_1: 0.8920 - custom_f1: 0.8597 - val_loss: 0.3718 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 5.6392e-07\nEpoch 73/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3082 - accuracy: 0.8537 - precision_1: 0.8268 - recall_1: 0.8950 - custom_f1: 0.8578\nEpoch 73: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3098 - accuracy: 0.8590 - precision_1: 0.8330 - recall_1: 0.8980 - custom_f1: 0.8664 - val_loss: 0.3715 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 5.0753e-07\nEpoch 74/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3195 - accuracy: 0.8662 - precision_1: 0.8429 - recall_1: 0.8962 - custom_f1: 0.8649\nEpoch 74: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3151 - accuracy: 0.8650 - precision_1: 0.8463 - recall_1: 0.8920 - custom_f1: 0.8598 - val_loss: 0.3714 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 4.5678e-07\nEpoch 75/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3210 - accuracy: 0.8725 - precision_1: 0.8531 - recall_1: 0.9000 - custom_f1: 0.8709\nEpoch 75: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3085 - accuracy: 0.8770 - precision_1: 0.8618 - recall_1: 0.8980 - custom_f1: 0.8748 - val_loss: 0.3717 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 4.1110e-07\nEpoch 76/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3024 - accuracy: 0.8791 - precision_1: 0.8601 - recall_1: 0.9086 - custom_f1: 0.8800\nEpoch 76: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.2946 - accuracy: 0.8810 - precision_1: 0.8588 - recall_1: 0.9120 - custom_f1: 0.8838 - val_loss: 0.3715 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 3.6999e-07\nEpoch 77/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2758 - accuracy: 0.8893 - precision_1: 0.8812 - recall_1: 0.9059 - custom_f1: 0.8881\nEpoch 77: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.2918 - accuracy: 0.8750 - precision_1: 0.8599 - recall_1: 0.8960 - custom_f1: 0.8677 - val_loss: 0.3717 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 3.3299e-07\nEpoch 78/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2817 - accuracy: 0.8880 - precision_1: 0.8652 - recall_1: 0.9193 - custom_f1: 0.8897\nEpoch 78: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.2875 - accuracy: 0.8810 - precision_1: 0.8601 - recall_1: 0.9100 - custom_f1: 0.8830 - val_loss: 0.3718 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 2.9969e-07\nEpoch 79/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3020 - accuracy: 0.8723 - precision_1: 0.8491 - recall_1: 0.9046 - custom_f1: 0.8718\nEpoch 79: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3071 - accuracy: 0.8670 - precision_1: 0.8482 - recall_1: 0.8940 - custom_f1: 0.8666 - val_loss: 0.3714 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 2.6972e-07\nEpoch 80/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3039 - accuracy: 0.8841 - precision_1: 0.8632 - recall_1: 0.9108 - custom_f1: 0.8824\nEpoch 80: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.2982 - accuracy: 0.8800 - precision_1: 0.8612 - recall_1: 0.9060 - custom_f1: 0.8764 - val_loss: 0.3712 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 2.4275e-07\nEpoch 81/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2979 - accuracy: 0.8696 - precision_1: 0.8468 - recall_1: 0.8981 - custom_f1: 0.8690\nEpoch 81: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 7ms/step - loss: 0.2953 - accuracy: 0.8720 - precision_1: 0.8509 - recall_1: 0.9020 - custom_f1: 0.8724 - val_loss: 0.3713 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 2.1847e-07\nEpoch 82/300\n21/32 [==================>...........] - ETA: 0s - loss: 0.3047 - accuracy: 0.8661 - precision_1: 0.8600 - recall_1: 0.8801 - custom_f1: 0.8684\nEpoch 82: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 7ms/step - loss: 0.3067 - accuracy: 0.8630 - precision_1: 0.8431 - recall_1: 0.8920 - custom_f1: 0.8593 - val_loss: 0.3721 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.9663e-07\nEpoch 83/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3073 - accuracy: 0.8587 - precision_1: 0.8456 - recall_1: 0.8734 - custom_f1: 0.8542\nEpoch 83: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3041 - accuracy: 0.8630 - precision_1: 0.8511 - recall_1: 0.8800 - custom_f1: 0.8625 - val_loss: 0.3714 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.7696e-07\nEpoch 84/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3081 - accuracy: 0.8620 - precision_1: 0.8317 - recall_1: 0.9058 - custom_f1: 0.8648\nEpoch 84: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3062 - accuracy: 0.8640 - precision_1: 0.8396 - recall_1: 0.9000 - custom_f1: 0.8610 - val_loss: 0.3725 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 1.5927e-07\nEpoch 85/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3154 - accuracy: 0.8568 - precision_1: 0.8280 - recall_1: 0.8939 - custom_f1: 0.8552\nEpoch 85: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3135 - accuracy: 0.8520 - precision_1: 0.8321 - recall_1: 0.8820 - custom_f1: 0.8444 - val_loss: 0.3726 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.4334e-07\nEpoch 86/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2887 - accuracy: 0.8788 - precision_1: 0.8667 - recall_1: 0.8909 - custom_f1: 0.8764\nEpoch 86: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.2882 - accuracy: 0.8830 - precision_1: 0.8690 - recall_1: 0.9020 - custom_f1: 0.8819 - val_loss: 0.3724 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.2901e-07\nEpoch 87/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2954 - accuracy: 0.8750 - precision_1: 0.8615 - recall_1: 0.8889 - custom_f1: 0.8734\nEpoch 87: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.8740 - precision_1: 0.8638 - recall_1: 0.8880 - custom_f1: 0.8764 - val_loss: 0.3721 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 1.1611e-07\nEpoch 88/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3038 - accuracy: 0.8646 - precision_1: 0.8345 - recall_1: 0.9050 - custom_f1: 0.8662\nEpoch 88: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3113 - accuracy: 0.8610 - precision_1: 0.8386 - recall_1: 0.8940 - custom_f1: 0.8586 - val_loss: 0.3725 - val_accuracy: 0.8320 - val_precision_1: 0.7712 - val_recall_1: 0.9440 - val_custom_f1: 0.6418 - lr: 1.0450e-07\nEpoch 89/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3217 - accuracy: 0.8612 - precision_1: 0.8454 - recall_1: 0.8816 - custom_f1: 0.8624\nEpoch 89: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.8630 - precision_1: 0.8444 - recall_1: 0.8900 - custom_f1: 0.8648 - val_loss: 0.3720 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 9.4046e-08\nEpoch 90/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3176 - accuracy: 0.8789 - precision_1: 0.8627 - recall_1: 0.9049 - custom_f1: 0.8791\nEpoch 90: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.3142 - accuracy: 0.8750 - precision_1: 0.8518 - recall_1: 0.9080 - custom_f1: 0.8742 - val_loss: 0.3719 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 8.4641e-08\nEpoch 91/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2943 - accuracy: 0.8737 - precision_1: 0.8519 - recall_1: 0.8977 - custom_f1: 0.8708\nEpoch 91: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 6ms/step - loss: 0.2863 - accuracy: 0.8770 - precision_1: 0.8550 - recall_1: 0.9080 - custom_f1: 0.8791 - val_loss: 0.3713 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 7.6177e-08\nEpoch 92/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2916 - accuracy: 0.8723 - precision_1: 0.8485 - recall_1: 0.9081 - custom_f1: 0.8744Restoring model weights from the end of the best epoch: 67.\n\nEpoch 92: val_loss did not improve from 0.37115\n32/32 [==============================] - 0s 7ms/step - loss: 0.2876 - accuracy: 0.8730 - precision_1: 0.8512 - recall_1: 0.9040 - custom_f1: 0.8784 - val_loss: 0.3714 - val_accuracy: 0.8360 - val_precision_1: 0.7763 - val_recall_1: 0.9440 - val_custom_f1: 0.6437 - lr: 6.8560e-08\nEpoch 92: early stopping\n\n===== Fold 3 =====\nTraining Hybrid Model...\nEpoch 1/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.8157 - accuracy: 0.5417 - precision_2: 0.5353 - recall_2: 0.5212 - custom_f1: 0.5146 \nEpoch 1: val_loss improved from inf to 0.62893, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 4s 22ms/step - loss: 0.7847 - accuracy: 0.5570 - precision_2: 0.5578 - recall_2: 0.5500 - custom_f1: 0.5471 - val_loss: 0.6289 - val_accuracy: 0.6960 - val_precision_2: 0.7025 - val_recall_2: 0.6800 - val_custom_f1: 0.5108 - lr: 0.0010\nEpoch 2/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.6042 - accuracy: 0.6758 - precision_2: 0.6667 - recall_2: 0.7031 - custom_f1: 0.6817\nEpoch 2: val_loss improved from 0.62893 to 0.59913, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.6028 - accuracy: 0.6800 - precision_2: 0.6711 - recall_2: 0.7060 - custom_f1: 0.6738 - val_loss: 0.5991 - val_accuracy: 0.7400 - val_precision_2: 0.8125 - val_recall_2: 0.6240 - val_custom_f1: 0.5624 - lr: 9.0000e-04\nEpoch 3/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.5448 - accuracy: 0.7279 - precision_2: 0.7146 - recall_2: 0.7610 - custom_f1: 0.7336\nEpoch 3: val_loss improved from 0.59913 to 0.57224, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.5458 - accuracy: 0.7230 - precision_2: 0.7116 - recall_2: 0.7500 - custom_f1: 0.7300 - val_loss: 0.5722 - val_accuracy: 0.7680 - val_precision_2: 0.8454 - val_recall_2: 0.6560 - val_custom_f1: 0.6002 - lr: 8.1000e-04\nEpoch 4/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.5163 - accuracy: 0.7250 - precision_2: 0.7143 - recall_2: 0.7216 - custom_f1: 0.7153\nEpoch 4: val_loss improved from 0.57224 to 0.55145, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.7380 - precision_2: 0.7380 - recall_2: 0.7380 - custom_f1: 0.7358 - val_loss: 0.5515 - val_accuracy: 0.8160 - val_precision_2: 0.7842 - val_recall_2: 0.8720 - val_custom_f1: 0.5813 - lr: 7.2900e-04\nEpoch 5/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.4788 - accuracy: 0.7695 - precision_2: 0.7329 - recall_2: 0.8425 - custom_f1: 0.7798\nEpoch 5: val_loss improved from 0.55145 to 0.52612, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.7720 - precision_2: 0.7420 - recall_2: 0.8340 - custom_f1: 0.7761 - val_loss: 0.5261 - val_accuracy: 0.8560 - val_precision_2: 0.8296 - val_recall_2: 0.8960 - val_custom_f1: 0.6219 - lr: 6.5610e-04\nEpoch 6/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.4459 - accuracy: 0.7912 - precision_2: 0.7881 - recall_2: 0.8093 - custom_f1: 0.7969\nEpoch 6: val_loss improved from 0.52612 to 0.50596, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.7880 - precision_2: 0.7727 - recall_2: 0.8160 - custom_f1: 0.7974 - val_loss: 0.5060 - val_accuracy: 0.8360 - val_precision_2: 0.7763 - val_recall_2: 0.9440 - val_custom_f1: 0.6117 - lr: 5.9049e-04\nEpoch 7/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.4456 - accuracy: 0.7894 - precision_2: 0.7814 - recall_2: 0.8206 - custom_f1: 0.7974\nEpoch 7: val_loss improved from 0.50596 to 0.47628, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.7880 - precision_2: 0.7717 - recall_2: 0.8180 - custom_f1: 0.7898 - val_loss: 0.4763 - val_accuracy: 0.8120 - val_precision_2: 0.7532 - val_recall_2: 0.9280 - val_custom_f1: 0.5764 - lr: 5.3144e-04\nEpoch 8/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.4407 - accuracy: 0.7837 - precision_2: 0.7664 - recall_2: 0.8180 - custom_f1: 0.7865\nEpoch 8: val_loss improved from 0.47628 to 0.45429, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.7970 - precision_2: 0.7797 - recall_2: 0.8280 - custom_f1: 0.7991 - val_loss: 0.4543 - val_accuracy: 0.8440 - val_precision_2: 0.7829 - val_recall_2: 0.9520 - val_custom_f1: 0.6080 - lr: 4.7830e-04\nEpoch 9/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3933 - accuracy: 0.8413 - precision_2: 0.8134 - recall_2: 0.8847 - custom_f1: 0.8448\nEpoch 9: val_loss improved from 0.45429 to 0.43342, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8360 - precision_2: 0.8100 - recall_2: 0.8780 - custom_f1: 0.8373 - val_loss: 0.4334 - val_accuracy: 0.8280 - val_precision_2: 0.7628 - val_recall_2: 0.9520 - val_custom_f1: 0.5839 - lr: 4.3047e-04\nEpoch 10/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.4074 - accuracy: 0.8261 - precision_2: 0.8010 - recall_2: 0.8703 - custom_f1: 0.8296\nEpoch 10: val_loss improved from 0.43342 to 0.42744, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.8140 - precision_2: 0.7875 - recall_2: 0.8600 - custom_f1: 0.8154 - val_loss: 0.4274 - val_accuracy: 0.8360 - val_precision_2: 0.7727 - val_recall_2: 0.9520 - val_custom_f1: 0.6123 - lr: 3.8742e-04\nEpoch 11/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.4061 - accuracy: 0.8125 - precision_2: 0.8009 - recall_2: 0.8403 - custom_f1: 0.8164\nEpoch 11: val_loss improved from 0.42744 to 0.40295, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8160 - precision_2: 0.7981 - recall_2: 0.8460 - custom_f1: 0.8222 - val_loss: 0.4029 - val_accuracy: 0.8440 - val_precision_2: 0.7792 - val_recall_2: 0.9600 - val_custom_f1: 0.5926 - lr: 3.4868e-04\nEpoch 12/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3534 - accuracy: 0.8438 - precision_2: 0.8289 - recall_2: 0.8643 - custom_f1: 0.8441\nEpoch 12: val_loss improved from 0.40295 to 0.39667, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3593 - accuracy: 0.8390 - precision_2: 0.8229 - recall_2: 0.8640 - custom_f1: 0.8352 - val_loss: 0.3967 - val_accuracy: 0.8360 - val_precision_2: 0.7727 - val_recall_2: 0.9520 - val_custom_f1: 0.6029 - lr: 3.1381e-04\nEpoch 13/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3638 - accuracy: 0.8359 - precision_2: 0.8231 - recall_2: 0.8612 - custom_f1: 0.8395\nEpoch 13: val_loss improved from 0.39667 to 0.39084, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3570 - accuracy: 0.8380 - precision_2: 0.8201 - recall_2: 0.8660 - custom_f1: 0.8388 - val_loss: 0.3908 - val_accuracy: 0.8320 - val_precision_2: 0.7643 - val_recall_2: 0.9600 - val_custom_f1: 0.5972 - lr: 2.8243e-04\nEpoch 14/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3425 - accuracy: 0.8478 - precision_2: 0.8346 - recall_2: 0.8786 - custom_f1: 0.8521\nEpoch 14: val_loss improved from 0.39084 to 0.37608, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8410 - precision_2: 0.8175 - recall_2: 0.8780 - custom_f1: 0.8424 - val_loss: 0.3761 - val_accuracy: 0.8400 - val_precision_2: 0.7742 - val_recall_2: 0.9600 - val_custom_f1: 0.6033 - lr: 2.5419e-04\nEpoch 15/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3673 - accuracy: 0.8370 - precision_2: 0.8261 - recall_2: 0.8444 - custom_f1: 0.8286\nEpoch 15: val_loss improved from 0.37608 to 0.36178, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3640 - accuracy: 0.8380 - precision_2: 0.8340 - recall_2: 0.8440 - custom_f1: 0.8259 - val_loss: 0.3618 - val_accuracy: 0.8400 - val_precision_2: 0.7778 - val_recall_2: 0.9520 - val_custom_f1: 0.6030 - lr: 2.2877e-04\nEpoch 16/300\n29/32 [==========================>...] - ETA: 0s - loss: 0.3498 - accuracy: 0.8416 - precision_2: 0.8047 - recall_2: 0.8976 - custom_f1: 0.8456\nEpoch 16: val_loss improved from 0.36178 to 0.36164, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 9ms/step - loss: 0.3486 - accuracy: 0.8430 - precision_2: 0.8068 - recall_2: 0.9020 - custom_f1: 0.8499 - val_loss: 0.3616 - val_accuracy: 0.8480 - val_precision_2: 0.7843 - val_recall_2: 0.9600 - val_custom_f1: 0.6086 - lr: 2.0589e-04\nEpoch 17/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3124 - accuracy: 0.8763 - precision_2: 0.8554 - recall_2: 0.9065 - custom_f1: 0.8784\nEpoch 17: val_loss improved from 0.36164 to 0.35728, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3265 - accuracy: 0.8680 - precision_2: 0.8459 - recall_2: 0.9000 - custom_f1: 0.8673 - val_loss: 0.3573 - val_accuracy: 0.8440 - val_precision_2: 0.7829 - val_recall_2: 0.9520 - val_custom_f1: 0.6065 - lr: 1.8530e-04\nEpoch 18/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3414 - accuracy: 0.8490 - precision_2: 0.8370 - recall_2: 0.8715 - custom_f1: 0.8503\nEpoch 18: val_loss improved from 0.35728 to 0.35049, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3523 - accuracy: 0.8530 - precision_2: 0.8324 - recall_2: 0.8840 - custom_f1: 0.8510 - val_loss: 0.3505 - val_accuracy: 0.8480 - val_precision_2: 0.7843 - val_recall_2: 0.9600 - val_custom_f1: 0.6086 - lr: 1.6677e-04\nEpoch 19/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3459 - accuracy: 0.8397 - precision_2: 0.8073 - recall_2: 0.8757 - custom_f1: 0.8368\nEpoch 19: val_loss improved from 0.35049 to 0.34704, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3454 - accuracy: 0.8360 - precision_2: 0.8146 - recall_2: 0.8700 - custom_f1: 0.8367 - val_loss: 0.3470 - val_accuracy: 0.8520 - val_precision_2: 0.7895 - val_recall_2: 0.9600 - val_custom_f1: 0.6109 - lr: 1.5009e-04\nEpoch 20/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3328 - accuracy: 0.8600 - precision_2: 0.8411 - recall_2: 0.8911 - custom_f1: 0.8634\nEpoch 20: val_loss did not improve from 0.34704\n32/32 [==============================] - 0s 6ms/step - loss: 0.3376 - accuracy: 0.8570 - precision_2: 0.8349 - recall_2: 0.8900 - custom_f1: 0.8588 - val_loss: 0.3587 - val_accuracy: 0.8480 - val_precision_2: 0.7881 - val_recall_2: 0.9520 - val_custom_f1: 0.6058 - lr: 1.3509e-04\nEpoch 21/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3262 - accuracy: 0.8568 - precision_2: 0.8293 - recall_2: 0.8984 - custom_f1: 0.8589\nEpoch 21: val_loss did not improve from 0.34704\n32/32 [==============================] - 0s 6ms/step - loss: 0.3268 - accuracy: 0.8560 - precision_2: 0.8333 - recall_2: 0.8900 - custom_f1: 0.8522 - val_loss: 0.3572 - val_accuracy: 0.8520 - val_precision_2: 0.7895 - val_recall_2: 0.9600 - val_custom_f1: 0.6109 - lr: 1.2158e-04\nEpoch 22/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3303 - accuracy: 0.8568 - precision_2: 0.8337 - recall_2: 0.8865 - custom_f1: 0.8574\nEpoch 22: val_loss did not improve from 0.34704\n32/32 [==============================] - 0s 6ms/step - loss: 0.3227 - accuracy: 0.8600 - precision_2: 0.8435 - recall_2: 0.8840 - custom_f1: 0.8587 - val_loss: 0.3472 - val_accuracy: 0.8560 - val_precision_2: 0.7908 - val_recall_2: 0.9680 - val_custom_f1: 0.6126 - lr: 1.0942e-04\nEpoch 23/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3374 - accuracy: 0.8438 - precision_2: 0.8188 - recall_2: 0.8927 - custom_f1: 0.8506\nEpoch 23: val_loss improved from 0.34704 to 0.34597, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3414 - accuracy: 0.8450 - precision_2: 0.8142 - recall_2: 0.8940 - custom_f1: 0.8456 - val_loss: 0.3460 - val_accuracy: 0.8560 - val_precision_2: 0.7908 - val_recall_2: 0.9680 - val_custom_f1: 0.6130 - lr: 9.8477e-05\nEpoch 24/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3164 - accuracy: 0.8612 - precision_2: 0.8231 - recall_2: 0.9167 - custom_f1: 0.8644\nEpoch 24: val_loss improved from 0.34597 to 0.33928, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3274 - accuracy: 0.8620 - precision_2: 0.8315 - recall_2: 0.9080 - custom_f1: 0.8615 - val_loss: 0.3393 - val_accuracy: 0.8600 - val_precision_2: 0.8000 - val_recall_2: 0.9600 - val_custom_f1: 0.6187 - lr: 8.8629e-05\nEpoch 25/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3103 - accuracy: 0.8672 - precision_2: 0.8670 - recall_2: 0.8715 - custom_f1: 0.8659\nEpoch 25: val_loss did not improve from 0.33928\n32/32 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8620 - precision_2: 0.8508 - recall_2: 0.8780 - custom_f1: 0.8653 - val_loss: 0.3419 - val_accuracy: 0.8560 - val_precision_2: 0.7947 - val_recall_2: 0.9600 - val_custom_f1: 0.6128 - lr: 7.9766e-05\nEpoch 26/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3053 - accuracy: 0.8832 - precision_2: 0.8634 - recall_2: 0.9103 - custom_f1: 0.8843\nEpoch 26: val_loss improved from 0.33928 to 0.33913, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3060 - accuracy: 0.8790 - precision_2: 0.8569 - recall_2: 0.9100 - custom_f1: 0.8746 - val_loss: 0.3391 - val_accuracy: 0.8560 - val_precision_2: 0.7947 - val_recall_2: 0.9600 - val_custom_f1: 0.6128 - lr: 7.1790e-05\nEpoch 27/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3210 - accuracy: 0.8711 - precision_2: 0.8259 - recall_2: 0.9335 - custom_f1: 0.8753\nEpoch 27: val_loss improved from 0.33913 to 0.33704, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.8640 - precision_2: 0.8273 - recall_2: 0.9200 - custom_f1: 0.8676 - val_loss: 0.3370 - val_accuracy: 0.8640 - val_precision_2: 0.8054 - val_recall_2: 0.9600 - val_custom_f1: 0.6232 - lr: 6.4611e-05\nEpoch 28/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3260 - accuracy: 0.8659 - precision_2: 0.8433 - recall_2: 0.8945 - custom_f1: 0.8649\nEpoch 28: val_loss improved from 0.33704 to 0.33645, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3257 - accuracy: 0.8580 - precision_2: 0.8416 - recall_2: 0.8820 - custom_f1: 0.8592 - val_loss: 0.3364 - val_accuracy: 0.8680 - val_precision_2: 0.8108 - val_recall_2: 0.9600 - val_custom_f1: 0.6315 - lr: 5.8150e-05\nEpoch 29/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3139 - accuracy: 0.8736 - precision_2: 0.8427 - recall_2: 0.9029 - custom_f1: 0.8699\nEpoch 29: val_loss improved from 0.33645 to 0.33545, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3206 - accuracy: 0.8720 - precision_2: 0.8577 - recall_2: 0.8920 - custom_f1: 0.8728 - val_loss: 0.3355 - val_accuracy: 0.8640 - val_precision_2: 0.8054 - val_recall_2: 0.9600 - val_custom_f1: 0.6232 - lr: 5.2335e-05\nEpoch 30/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3277 - accuracy: 0.8672 - precision_2: 0.8532 - recall_2: 0.8886 - custom_f1: 0.8663\nEpoch 30: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8630 - precision_2: 0.8405 - recall_2: 0.8960 - custom_f1: 0.8662 - val_loss: 0.3361 - val_accuracy: 0.8600 - val_precision_2: 0.8000 - val_recall_2: 0.9600 - val_custom_f1: 0.6172 - lr: 4.7101e-05\nEpoch 31/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3145 - accuracy: 0.8776 - precision_2: 0.8418 - recall_2: 0.9227 - custom_f1: 0.8748\nEpoch 31: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3098 - accuracy: 0.8830 - precision_2: 0.8566 - recall_2: 0.9200 - custom_f1: 0.8851 - val_loss: 0.3374 - val_accuracy: 0.8600 - val_precision_2: 0.8000 - val_recall_2: 0.9600 - val_custom_f1: 0.6172 - lr: 4.2391e-05\nEpoch 32/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3239 - accuracy: 0.8672 - precision_2: 0.8439 - recall_2: 0.9010 - custom_f1: 0.8695\nEpoch 32: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3143 - accuracy: 0.8720 - precision_2: 0.8432 - recall_2: 0.9140 - custom_f1: 0.8658 - val_loss: 0.3366 - val_accuracy: 0.8600 - val_precision_2: 0.8000 - val_recall_2: 0.9600 - val_custom_f1: 0.6172 - lr: 3.8152e-05\nEpoch 33/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3192 - accuracy: 0.8685 - precision_2: 0.8463 - recall_2: 0.9013 - custom_f1: 0.8686\nEpoch 33: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3156 - accuracy: 0.8730 - precision_2: 0.8552 - recall_2: 0.8980 - custom_f1: 0.8729 - val_loss: 0.3370 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 3.4337e-05\nEpoch 34/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3100 - accuracy: 0.8788 - precision_2: 0.8657 - recall_2: 0.8980 - custom_f1: 0.8770\nEpoch 34: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3128 - accuracy: 0.8770 - precision_2: 0.8618 - recall_2: 0.8980 - custom_f1: 0.8729 - val_loss: 0.3379 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 3.0903e-05\nEpoch 35/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3232 - accuracy: 0.8587 - precision_2: 0.8439 - recall_2: 0.8764 - custom_f1: 0.8591\nEpoch 35: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3357 - accuracy: 0.8480 - precision_2: 0.8295 - recall_2: 0.8760 - custom_f1: 0.8516 - val_loss: 0.3371 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 2.7813e-05\nEpoch 36/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3177 - accuracy: 0.8737 - precision_2: 0.8564 - recall_2: 0.8947 - custom_f1: 0.8726\nEpoch 36: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3156 - accuracy: 0.8740 - precision_2: 0.8596 - recall_2: 0.8940 - custom_f1: 0.8722 - val_loss: 0.3387 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 2.5032e-05\nEpoch 37/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3142 - accuracy: 0.8763 - precision_2: 0.8688 - recall_2: 0.8931 - custom_f1: 0.8792\nEpoch 37: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3165 - accuracy: 0.8730 - precision_2: 0.8539 - recall_2: 0.9000 - custom_f1: 0.8684 - val_loss: 0.3382 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 2.2528e-05\nEpoch 38/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2980 - accuracy: 0.8628 - precision_2: 0.8495 - recall_2: 0.8880 - custom_f1: 0.8676\nEpoch 38: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 7ms/step - loss: 0.3099 - accuracy: 0.8590 - precision_2: 0.8380 - recall_2: 0.8900 - custom_f1: 0.8581 - val_loss: 0.3375 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6208 - lr: 2.0276e-05\nEpoch 39/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3269 - accuracy: 0.8562 - precision_2: 0.8277 - recall_2: 0.9069 - custom_f1: 0.8623\nEpoch 39: ReduceLROnPlateau reducing learning rate to 9.12400173547212e-06.\n\nEpoch 39: val_loss did not improve from 0.33545\n32/32 [==============================] - 0s 6ms/step - loss: 0.3256 - accuracy: 0.8550 - precision_2: 0.8269 - recall_2: 0.8980 - custom_f1: 0.8549 - val_loss: 0.3370 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 9.1240e-06\nEpoch 40/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3065 - accuracy: 0.8724 - precision_2: 0.8366 - recall_2: 0.9171 - custom_f1: 0.8695\nEpoch 40: val_loss improved from 0.33545 to 0.33405, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3081 - accuracy: 0.8690 - precision_2: 0.8423 - recall_2: 0.9080 - custom_f1: 0.8703 - val_loss: 0.3340 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 1.6423e-05\nEpoch 41/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3155 - accuracy: 0.8750 - precision_2: 0.8453 - recall_2: 0.9173 - custom_f1: 0.8791\nEpoch 41: val_loss improved from 0.33405 to 0.33373, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3079 - accuracy: 0.8820 - precision_2: 0.8550 - recall_2: 0.9200 - custom_f1: 0.8761 - val_loss: 0.3337 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 1.4781e-05\nEpoch 42/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3045 - accuracy: 0.8650 - precision_2: 0.8424 - recall_2: 0.8972 - custom_f1: 0.8673\nEpoch 42: val_loss improved from 0.33373 to 0.33355, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3061 - accuracy: 0.8670 - precision_2: 0.8430 - recall_2: 0.9020 - custom_f1: 0.8695 - val_loss: 0.3335 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 1.3303e-05\nEpoch 43/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3204 - accuracy: 0.8607 - precision_2: 0.8309 - recall_2: 0.9029 - custom_f1: 0.8645\nEpoch 43: val_loss improved from 0.33355 to 0.33233, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3148 - accuracy: 0.8650 - precision_2: 0.8373 - recall_2: 0.9060 - custom_f1: 0.8723 - val_loss: 0.3323 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 1.1973e-05\nEpoch 44/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3370 - accuracy: 0.8533 - precision_2: 0.8287 - recall_2: 0.8916 - custom_f1: 0.8565\nEpoch 44: val_loss did not improve from 0.33233\n32/32 [==============================] - 0s 6ms/step - loss: 0.3158 - accuracy: 0.8700 - precision_2: 0.8464 - recall_2: 0.9040 - custom_f1: 0.8678 - val_loss: 0.3333 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 1.0775e-05\nEpoch 45/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3287 - accuracy: 0.8675 - precision_2: 0.8326 - recall_2: 0.9167 - custom_f1: 0.8708\nEpoch 45: val_loss improved from 0.33233 to 0.33196, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3137 - accuracy: 0.8740 - precision_2: 0.8463 - recall_2: 0.9140 - custom_f1: 0.8807 - val_loss: 0.3320 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 9.6977e-06\nEpoch 46/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3115 - accuracy: 0.8725 - precision_2: 0.8409 - recall_2: 0.9100 - custom_f1: 0.8715\nEpoch 46: val_loss improved from 0.33196 to 0.33182, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3227 - accuracy: 0.8620 - precision_2: 0.8377 - recall_2: 0.8980 - custom_f1: 0.8609 - val_loss: 0.3318 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 8.7280e-06\nEpoch 47/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2863 - accuracy: 0.8938 - precision_2: 0.8726 - recall_2: 0.9190 - custom_f1: 0.8959\nEpoch 47: val_loss improved from 0.33182 to 0.33165, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.2947 - accuracy: 0.8890 - precision_2: 0.8677 - recall_2: 0.9180 - custom_f1: 0.8924 - val_loss: 0.3317 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 7.8552e-06\nEpoch 48/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3002 - accuracy: 0.8737 - precision_2: 0.8540 - recall_2: 0.9046 - custom_f1: 0.8736\nEpoch 48: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.2942 - accuracy: 0.8820 - precision_2: 0.8631 - recall_2: 0.9080 - custom_f1: 0.8851 - val_loss: 0.3330 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 7.0697e-06\nEpoch 49/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3036 - accuracy: 0.8880 - precision_2: 0.8716 - recall_2: 0.9121 - custom_f1: 0.8884\nEpoch 49: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.3012 - accuracy: 0.8880 - precision_2: 0.8633 - recall_2: 0.9220 - custom_f1: 0.8824 - val_loss: 0.3330 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 6.3627e-06\nEpoch 50/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3021 - accuracy: 0.8764 - precision_2: 0.8424 - recall_2: 0.9268 - custom_f1: 0.8789\nEpoch 50: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.3027 - accuracy: 0.8740 - precision_2: 0.8412 - recall_2: 0.9220 - custom_f1: 0.8737 - val_loss: 0.3331 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 5.7264e-06\nEpoch 51/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3188 - accuracy: 0.8838 - precision_2: 0.8687 - recall_2: 0.9055 - custom_f1: 0.8817\nEpoch 51: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.3239 - accuracy: 0.8730 - precision_2: 0.8512 - recall_2: 0.9040 - custom_f1: 0.8667 - val_loss: 0.3327 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 5.1538e-06\nEpoch 52/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3138 - accuracy: 0.8825 - precision_2: 0.8545 - recall_2: 0.9192 - custom_f1: 0.8822\nEpoch 52: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.3172 - accuracy: 0.8820 - precision_2: 0.8577 - recall_2: 0.9160 - custom_f1: 0.8792 - val_loss: 0.3319 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 4.6384e-06\nEpoch 53/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3072 - accuracy: 0.8662 - precision_2: 0.8482 - recall_2: 0.8889 - custom_f1: 0.8631\nEpoch 53: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.3091 - accuracy: 0.8690 - precision_2: 0.8569 - recall_2: 0.8860 - custom_f1: 0.8651 - val_loss: 0.3327 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 4.1746e-06\nEpoch 54/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3126 - accuracy: 0.8737 - precision_2: 0.8445 - recall_2: 0.9146 - custom_f1: 0.8763\nEpoch 54: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.3147 - accuracy: 0.8710 - precision_2: 0.8480 - recall_2: 0.9040 - custom_f1: 0.8731 - val_loss: 0.3324 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 3.7571e-06\nEpoch 55/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3206 - accuracy: 0.8620 - precision_2: 0.8365 - recall_2: 0.9016 - custom_f1: 0.8619\nEpoch 55: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.3154 - accuracy: 0.8690 - precision_2: 0.8410 - recall_2: 0.9100 - custom_f1: 0.8726 - val_loss: 0.3324 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 3.3814e-06\nEpoch 56/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3011 - accuracy: 0.8863 - precision_2: 0.8454 - recall_2: 0.9352 - custom_f1: 0.8883\nEpoch 56: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.2989 - accuracy: 0.8890 - precision_2: 0.8595 - recall_2: 0.9300 - custom_f1: 0.8894 - val_loss: 0.3319 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 3.0433e-06\nEpoch 57/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3022 - accuracy: 0.8724 - precision_2: 0.8462 - recall_2: 0.9045 - custom_f1: 0.8694\nEpoch 57: ReduceLROnPlateau reducing learning rate to 1.3694636891159462e-06.\n\nEpoch 57: val_loss did not improve from 0.33165\n32/32 [==============================] - 0s 6ms/step - loss: 0.3023 - accuracy: 0.8760 - precision_2: 0.8494 - recall_2: 0.9140 - custom_f1: 0.8756 - val_loss: 0.3322 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 1.3695e-06\nEpoch 58/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2933 - accuracy: 0.8850 - precision_2: 0.8561 - recall_2: 0.9177 - custom_f1: 0.8832\nEpoch 58: val_loss improved from 0.33165 to 0.33133, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3056 - accuracy: 0.8820 - precision_2: 0.8604 - recall_2: 0.9120 - custom_f1: 0.8789 - val_loss: 0.3313 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 2.4650e-06\nEpoch 59/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3252 - accuracy: 0.8650 - precision_2: 0.8387 - recall_2: 0.9055 - custom_f1: 0.8687\nEpoch 59: val_loss improved from 0.33133 to 0.33125, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.8630 - precision_2: 0.8367 - recall_2: 0.9020 - custom_f1: 0.8667 - val_loss: 0.3313 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 2.2185e-06\nEpoch 60/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2854 - accuracy: 0.8945 - precision_2: 0.8643 - recall_2: 0.9272 - custom_f1: 0.8943\nEpoch 60: val_loss did not improve from 0.33125\n32/32 [==============================] - 0s 7ms/step - loss: 0.2809 - accuracy: 0.8970 - precision_2: 0.8738 - recall_2: 0.9280 - custom_f1: 0.8956 - val_loss: 0.3324 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 1.9967e-06\nEpoch 61/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3355 - accuracy: 0.8462 - precision_2: 0.8258 - recall_2: 0.8737 - custom_f1: 0.8452\nEpoch 61: val_loss did not improve from 0.33125\n32/32 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.8570 - precision_2: 0.8400 - recall_2: 0.8820 - custom_f1: 0.8556 - val_loss: 0.3320 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 1.7970e-06\nEpoch 62/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3008 - accuracy: 0.8675 - precision_2: 0.8426 - recall_2: 0.9055 - custom_f1: 0.8692\nEpoch 62: val_loss did not improve from 0.33125\n32/32 [==============================] - 0s 6ms/step - loss: 0.2944 - accuracy: 0.8750 - precision_2: 0.8479 - recall_2: 0.9140 - custom_f1: 0.8799 - val_loss: 0.3314 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 1.6173e-06\nEpoch 63/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2857 - accuracy: 0.8815 - precision_2: 0.8667 - recall_2: 0.9046 - custom_f1: 0.8843\nEpoch 63: val_loss did not improve from 0.33125\n32/32 [==============================] - 0s 6ms/step - loss: 0.3024 - accuracy: 0.8700 - precision_2: 0.8491 - recall_2: 0.9000 - custom_f1: 0.8724 - val_loss: 0.3318 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6292 - lr: 1.4556e-06\nEpoch 64/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2910 - accuracy: 0.8788 - precision_2: 0.8582 - recall_2: 0.9075 - custom_f1: 0.8803\nEpoch 64: val_loss did not improve from 0.33125\n32/32 [==============================] - 0s 6ms/step - loss: 0.2875 - accuracy: 0.8810 - precision_2: 0.8574 - recall_2: 0.9140 - custom_f1: 0.8857 - val_loss: 0.3325 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6208 - lr: 1.3100e-06\nEpoch 65/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3117 - accuracy: 0.8838 - precision_2: 0.8504 - recall_2: 0.9361 - custom_f1: 0.8908\nEpoch 65: val_loss did not improve from 0.33125\n32/32 [==============================] - 0s 6ms/step - loss: 0.3070 - accuracy: 0.8840 - precision_2: 0.8516 - recall_2: 0.9300 - custom_f1: 0.8902 - val_loss: 0.3324 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6292 - lr: 1.1790e-06\nEpoch 66/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3105 - accuracy: 0.8725 - precision_2: 0.8382 - recall_2: 0.9256 - custom_f1: 0.8762\nEpoch 66: val_loss did not improve from 0.33125\n32/32 [==============================] - 0s 6ms/step - loss: 0.3135 - accuracy: 0.8720 - precision_2: 0.8382 - recall_2: 0.9220 - custom_f1: 0.8749 - val_loss: 0.3320 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6292 - lr: 1.0611e-06\nEpoch 67/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3225 - accuracy: 0.8555 - precision_2: 0.8286 - recall_2: 0.8992 - custom_f1: 0.8598\nEpoch 67: val_loss improved from 0.33125 to 0.33124, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3208 - accuracy: 0.8550 - precision_2: 0.8257 - recall_2: 0.9000 - custom_f1: 0.8540 - val_loss: 0.3312 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 9.5500e-07\nEpoch 68/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3231 - accuracy: 0.8587 - precision_2: 0.8254 - recall_2: 0.9100 - custom_f1: 0.8628\nEpoch 68: val_loss improved from 0.33124 to 0.33091, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3197 - accuracy: 0.8580 - precision_2: 0.8303 - recall_2: 0.9000 - custom_f1: 0.8634 - val_loss: 0.3309 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6292 - lr: 8.5950e-07\nEpoch 69/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2990 - accuracy: 0.8845 - precision_2: 0.8639 - recall_2: 0.9091 - custom_f1: 0.8825\nEpoch 69: val_loss improved from 0.33091 to 0.33074, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3096 - accuracy: 0.8790 - precision_2: 0.8623 - recall_2: 0.9020 - custom_f1: 0.8827 - val_loss: 0.3307 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6292 - lr: 7.7355e-07\nEpoch 70/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3041 - accuracy: 0.8764 - precision_2: 0.8467 - recall_2: 0.9183 - custom_f1: 0.8816\nEpoch 70: val_loss did not improve from 0.33074\n32/32 [==============================] - 0s 6ms/step - loss: 0.3048 - accuracy: 0.8750 - precision_2: 0.8466 - recall_2: 0.9160 - custom_f1: 0.8719 - val_loss: 0.3308 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6292 - lr: 6.9620e-07\nEpoch 71/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3002 - accuracy: 0.8854 - precision_2: 0.8605 - recall_2: 0.9262 - custom_f1: 0.8907\nEpoch 71: val_loss did not improve from 0.33074\n32/32 [==============================] - 0s 6ms/step - loss: 0.3038 - accuracy: 0.8790 - precision_2: 0.8503 - recall_2: 0.9200 - custom_f1: 0.8808 - val_loss: 0.3318 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 6.2658e-07\nEpoch 72/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3309 - accuracy: 0.8637 - precision_2: 0.8421 - recall_2: 0.9020 - custom_f1: 0.8688\nEpoch 72: val_loss did not improve from 0.33074\n32/32 [==============================] - 0s 6ms/step - loss: 0.3205 - accuracy: 0.8660 - precision_2: 0.8440 - recall_2: 0.8980 - custom_f1: 0.8683 - val_loss: 0.3314 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 5.6392e-07\nEpoch 73/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2951 - accuracy: 0.8750 - precision_2: 0.8571 - recall_2: 0.8950 - custom_f1: 0.8757\nEpoch 73: val_loss did not improve from 0.33074\n32/32 [==============================] - 0s 6ms/step - loss: 0.3030 - accuracy: 0.8740 - precision_2: 0.8555 - recall_2: 0.9000 - custom_f1: 0.8740 - val_loss: 0.3324 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 5.0753e-07\nEpoch 74/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3265 - accuracy: 0.8612 - precision_2: 0.8353 - recall_2: 0.8929 - custom_f1: 0.8584\nEpoch 74: val_loss did not improve from 0.33074\n32/32 [==============================] - 0s 6ms/step - loss: 0.3256 - accuracy: 0.8600 - precision_2: 0.8422 - recall_2: 0.8860 - custom_f1: 0.8539 - val_loss: 0.3314 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 4.5678e-07\nEpoch 75/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2909 - accuracy: 0.8775 - precision_2: 0.8456 - recall_2: 0.9221 - custom_f1: 0.8818\nEpoch 75: val_loss did not improve from 0.33074\n32/32 [==============================] - 0s 6ms/step - loss: 0.3018 - accuracy: 0.8750 - precision_2: 0.8428 - recall_2: 0.9220 - custom_f1: 0.8813 - val_loss: 0.3310 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 4.1110e-07\nEpoch 76/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3052 - accuracy: 0.8687 - precision_2: 0.8667 - recall_2: 0.8731 - custom_f1: 0.8661\nEpoch 76: val_loss improved from 0.33074 to 0.33051, saving model to best_hybrid_fold3_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3078 - accuracy: 0.8660 - precision_2: 0.8533 - recall_2: 0.8840 - custom_f1: 0.8674 - val_loss: 0.3305 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 3.6999e-07\nEpoch 77/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3047 - accuracy: 0.8800 - precision_2: 0.8649 - recall_2: 0.9035 - custom_f1: 0.8809\nEpoch 77: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3049 - accuracy: 0.8790 - precision_2: 0.8529 - recall_2: 0.9160 - custom_f1: 0.8749 - val_loss: 0.3325 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6208 - lr: 3.3299e-07\nEpoch 78/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2856 - accuracy: 0.8893 - precision_2: 0.8627 - recall_2: 0.9275 - custom_f1: 0.8915\nEpoch 78: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.2888 - accuracy: 0.8900 - precision_2: 0.8638 - recall_2: 0.9260 - custom_f1: 0.8950 - val_loss: 0.3321 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6208 - lr: 2.9969e-07\nEpoch 79/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3164 - accuracy: 0.8650 - precision_2: 0.8295 - recall_2: 0.9171 - custom_f1: 0.8689\nEpoch 79: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3242 - accuracy: 0.8620 - precision_2: 0.8315 - recall_2: 0.9080 - custom_f1: 0.8651 - val_loss: 0.3311 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6208 - lr: 2.6972e-07\nEpoch 80/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3101 - accuracy: 0.8802 - precision_2: 0.8454 - recall_2: 0.9259 - custom_f1: 0.8850\nEpoch 80: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3026 - accuracy: 0.8850 - precision_2: 0.8558 - recall_2: 0.9260 - custom_f1: 0.8908 - val_loss: 0.3308 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 2.4275e-07\nEpoch 81/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3100 - accuracy: 0.8633 - precision_2: 0.8571 - recall_2: 0.8769 - custom_f1: 0.8607\nEpoch 81: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3166 - accuracy: 0.8560 - precision_2: 0.8397 - recall_2: 0.8800 - custom_f1: 0.8515 - val_loss: 0.3310 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 2.1847e-07\nEpoch 82/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2982 - accuracy: 0.8813 - precision_2: 0.8588 - recall_2: 0.9125 - custom_f1: 0.8832\nEpoch 82: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.2948 - accuracy: 0.8830 - precision_2: 0.8553 - recall_2: 0.9220 - custom_f1: 0.8872 - val_loss: 0.3313 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6193 - lr: 1.9663e-07\nEpoch 83/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2964 - accuracy: 0.8825 - precision_2: 0.8616 - recall_2: 0.9093 - custom_f1: 0.8826\nEpoch 83: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3017 - accuracy: 0.8750 - precision_2: 0.8531 - recall_2: 0.9060 - custom_f1: 0.8742 - val_loss: 0.3309 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 1.7696e-07\nEpoch 84/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2671 - accuracy: 0.9141 - precision_2: 0.9013 - recall_2: 0.9295 - custom_f1: 0.9141\nEpoch 84: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.2779 - accuracy: 0.9030 - precision_2: 0.8868 - recall_2: 0.9240 - custom_f1: 0.8937 - val_loss: 0.3327 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 1.5927e-07\nEpoch 85/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2976 - accuracy: 0.8886 - precision_2: 0.8560 - recall_2: 0.9276 - custom_f1: 0.8870\nEpoch 85: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3007 - accuracy: 0.8810 - precision_2: 0.8521 - recall_2: 0.9220 - custom_f1: 0.8814 - val_loss: 0.3322 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 1.4334e-07\nEpoch 86/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2781 - accuracy: 0.8880 - precision_2: 0.8550 - recall_2: 0.9243 - custom_f1: 0.8882\nEpoch 86: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.2910 - accuracy: 0.8800 - precision_2: 0.8612 - recall_2: 0.9060 - custom_f1: 0.8846 - val_loss: 0.3317 - val_accuracy: 0.8600 - val_precision_2: 0.7961 - val_recall_2: 0.9680 - val_custom_f1: 0.6149 - lr: 1.2901e-07\nEpoch 87/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3191 - accuracy: 0.8800 - precision_2: 0.8505 - recall_2: 0.9192 - custom_f1: 0.8800\nEpoch 87: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3162 - accuracy: 0.8760 - precision_2: 0.8561 - recall_2: 0.9040 - custom_f1: 0.8739 - val_loss: 0.3308 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 1.1611e-07\nEpoch 88/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3381 - accuracy: 0.8581 - precision_2: 0.8337 - recall_2: 0.8927 - custom_f1: 0.8556\nEpoch 88: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3167 - accuracy: 0.8690 - precision_2: 0.8462 - recall_2: 0.9020 - custom_f1: 0.8572 - val_loss: 0.3309 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6208 - lr: 1.0450e-07\nEpoch 89/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3017 - accuracy: 0.8775 - precision_2: 0.8558 - recall_2: 0.9073 - custom_f1: 0.8780\nEpoch 89: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3046 - accuracy: 0.8770 - precision_2: 0.8537 - recall_2: 0.9100 - custom_f1: 0.8813 - val_loss: 0.3315 - val_accuracy: 0.8640 - val_precision_2: 0.8013 - val_recall_2: 0.9680 - val_custom_f1: 0.6208 - lr: 9.4046e-08\nEpoch 90/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3088 - accuracy: 0.8675 - precision_2: 0.8447 - recall_2: 0.8997 - custom_f1: 0.8665\nEpoch 90: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.2993 - accuracy: 0.8710 - precision_2: 0.8442 - recall_2: 0.9100 - custom_f1: 0.8714 - val_loss: 0.3313 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6292 - lr: 8.4641e-08\nEpoch 91/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3149 - accuracy: 0.8687 - precision_2: 0.8337 - recall_2: 0.9128 - custom_f1: 0.8648\nEpoch 91: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3148 - accuracy: 0.8670 - precision_2: 0.8379 - recall_2: 0.9100 - custom_f1: 0.8680 - val_loss: 0.3306 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 7.6177e-08\nEpoch 92/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2826 - accuracy: 0.8888 - precision_2: 0.8621 - recall_2: 0.9248 - custom_f1: 0.8914\nEpoch 92: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.2748 - accuracy: 0.8930 - precision_2: 0.8701 - recall_2: 0.9240 - custom_f1: 0.8925 - val_loss: 0.3308 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 6.8560e-08\nEpoch 93/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3079 - accuracy: 0.8650 - precision_2: 0.8411 - recall_2: 0.9000 - custom_f1: 0.8670\nEpoch 93: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3112 - accuracy: 0.8630 - precision_2: 0.8393 - recall_2: 0.8980 - custom_f1: 0.8648 - val_loss: 0.3312 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 6.1704e-08\nEpoch 94/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3145 - accuracy: 0.8711 - precision_2: 0.8575 - recall_2: 0.8909 - custom_f1: 0.8719\nEpoch 94: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3188 - accuracy: 0.8690 - precision_2: 0.8528 - recall_2: 0.8920 - custom_f1: 0.8740 - val_loss: 0.3313 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 5.5533e-08\nEpoch 95/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3036 - accuracy: 0.8815 - precision_2: 0.8558 - recall_2: 0.9235 - custom_f1: 0.8846\nEpoch 95: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 7ms/step - loss: 0.2993 - accuracy: 0.8840 - precision_2: 0.8516 - recall_2: 0.9300 - custom_f1: 0.8822 - val_loss: 0.3330 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 4.9980e-08\nEpoch 96/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3217 - accuracy: 0.8737 - precision_2: 0.8465 - recall_2: 0.9191 - custom_f1: 0.8755\nEpoch 96: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.8740 - precision_2: 0.8400 - recall_2: 0.9240 - custom_f1: 0.8747 - val_loss: 0.3326 - val_accuracy: 0.8680 - val_precision_2: 0.8067 - val_recall_2: 0.9680 - val_custom_f1: 0.6253 - lr: 4.4982e-08\nEpoch 97/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2917 - accuracy: 0.8906 - precision_2: 0.8568 - recall_2: 0.9339 - custom_f1: 0.8926\nEpoch 97: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.2998 - accuracy: 0.8830 - precision_2: 0.8463 - recall_2: 0.9360 - custom_f1: 0.8913 - val_loss: 0.3320 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 4.0484e-08\nEpoch 98/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3413 - accuracy: 0.8512 - precision_2: 0.8314 - recall_2: 0.8902 - custom_f1: 0.8590\nEpoch 98: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8560 - precision_2: 0.8333 - recall_2: 0.8900 - custom_f1: 0.8598 - val_loss: 0.3319 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 3.6435e-08\nEpoch 99/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2944 - accuracy: 0.8938 - precision_2: 0.8614 - recall_2: 0.9372 - custom_f1: 0.8968\nEpoch 99: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3048 - accuracy: 0.8810 - precision_2: 0.8483 - recall_2: 0.9280 - custom_f1: 0.8818 - val_loss: 0.3318 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 3.2792e-08\nEpoch 100/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2857 - accuracy: 0.8971 - precision_2: 0.8690 - recall_2: 0.9274 - custom_f1: 0.8964\nEpoch 100: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 6ms/step - loss: 0.3043 - accuracy: 0.8860 - precision_2: 0.8669 - recall_2: 0.9120 - custom_f1: 0.8876 - val_loss: 0.3316 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 2.9513e-08\nEpoch 101/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3267 - accuracy: 0.8682 - precision_2: 0.8410 - recall_2: 0.9036 - custom_f1: 0.8699Restoring model weights from the end of the best epoch: 76.\n\nEpoch 101: val_loss did not improve from 0.33051\n32/32 [==============================] - 0s 7ms/step - loss: 0.3161 - accuracy: 0.8780 - precision_2: 0.8593 - recall_2: 0.9040 - custom_f1: 0.8779 - val_loss: 0.3306 - val_accuracy: 0.8720 - val_precision_2: 0.8121 - val_recall_2: 0.9680 - val_custom_f1: 0.6336 - lr: 2.6561e-08\nEpoch 101: early stopping\n\n===== Fold 4 =====\nTraining Hybrid Model...\nEpoch 1/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.8181 - accuracy: 0.5408 - precision_3: 0.5357 - recall_3: 0.4972 - custom_f1: 0.5012 \nEpoch 1: val_loss improved from inf to 0.64196, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 3s 22ms/step - loss: 0.7807 - accuracy: 0.5670 - precision_3: 0.5699 - recall_3: 0.5460 - custom_f1: 0.5491 - val_loss: 0.6420 - val_accuracy: 0.5760 - val_precision_3: 0.7317 - val_recall_3: 0.2400 - val_custom_f1: 0.3320 - lr: 0.0010\nEpoch 2/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.6129 - accuracy: 0.6780 - precision_3: 0.6684 - recall_3: 0.7030 - custom_f1: 0.6799\nEpoch 2: val_loss improved from 0.64196 to 0.62506, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.6770 - precision_3: 0.6712 - recall_3: 0.6940 - custom_f1: 0.6736 - val_loss: 0.6251 - val_accuracy: 0.5800 - val_precision_3: 0.8846 - val_recall_3: 0.1840 - val_custom_f1: 0.2325 - lr: 9.0000e-04\nEpoch 3/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.5316 - accuracy: 0.7188 - precision_3: 0.7182 - recall_3: 0.7201 - custom_f1: 0.7124\nEpoch 3: val_loss improved from 0.62506 to 0.59103, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.5606 - accuracy: 0.7150 - precision_3: 0.7112 - recall_3: 0.7240 - custom_f1: 0.7127 - val_loss: 0.5910 - val_accuracy: 0.7040 - val_precision_3: 0.8923 - val_recall_3: 0.4640 - val_custom_f1: 0.5131 - lr: 8.1000e-04\nEpoch 4/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.5136 - accuracy: 0.7526 - precision_3: 0.7421 - recall_3: 0.7540 - custom_f1: 0.7414\nEpoch 4: val_loss improved from 0.59103 to 0.55862, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.5220 - accuracy: 0.7510 - precision_3: 0.7556 - recall_3: 0.7420 - custom_f1: 0.7424 - val_loss: 0.5586 - val_accuracy: 0.7720 - val_precision_3: 0.8091 - val_recall_3: 0.7120 - val_custom_f1: 0.4715 - lr: 7.2900e-04\nEpoch 5/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.4760 - accuracy: 0.7812 - precision_3: 0.7417 - recall_3: 0.8575 - custom_f1: 0.7941\nEpoch 5: val_loss improved from 0.55862 to 0.54114, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4659 - accuracy: 0.7840 - precision_3: 0.7527 - recall_3: 0.8460 - custom_f1: 0.7855 - val_loss: 0.5411 - val_accuracy: 0.7880 - val_precision_3: 0.8333 - val_recall_3: 0.7200 - val_custom_f1: 0.5285 - lr: 6.5610e-04\nEpoch 6/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.4655 - accuracy: 0.7738 - precision_3: 0.7674 - recall_3: 0.7921 - custom_f1: 0.7760\nEpoch 6: val_loss improved from 0.54114 to 0.50925, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.7820 - precision_3: 0.7701 - recall_3: 0.8040 - custom_f1: 0.7813 - val_loss: 0.5092 - val_accuracy: 0.7960 - val_precision_3: 0.8190 - val_recall_3: 0.7600 - val_custom_f1: 0.5612 - lr: 5.9049e-04\nEpoch 7/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.4665 - accuracy: 0.7682 - precision_3: 0.7665 - recall_3: 0.7784 - custom_f1: 0.7718\nEpoch 7: val_loss improved from 0.50925 to 0.48349, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.7840 - precision_3: 0.7784 - recall_3: 0.7940 - custom_f1: 0.7877 - val_loss: 0.4835 - val_accuracy: 0.7960 - val_precision_3: 0.7803 - val_recall_3: 0.8240 - val_custom_f1: 0.5708 - lr: 5.3144e-04\nEpoch 8/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.4079 - accuracy: 0.8164 - precision_3: 0.8101 - recall_3: 0.8290 - custom_f1: 0.8171\nEpoch 8: val_loss improved from 0.48349 to 0.45446, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.8100 - precision_3: 0.8027 - recall_3: 0.8220 - custom_f1: 0.8057 - val_loss: 0.4545 - val_accuracy: 0.8120 - val_precision_3: 0.7708 - val_recall_3: 0.8880 - val_custom_f1: 0.6014 - lr: 4.7830e-04\nEpoch 9/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.4454 - accuracy: 0.7812 - precision_3: 0.7576 - recall_3: 0.8219 - custom_f1: 0.7845\nEpoch 9: val_loss improved from 0.45446 to 0.43011, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.7920 - precision_3: 0.7704 - recall_3: 0.8320 - custom_f1: 0.8015 - val_loss: 0.4301 - val_accuracy: 0.8360 - val_precision_3: 0.8043 - val_recall_3: 0.8880 - val_custom_f1: 0.6078 - lr: 4.3047e-04\nEpoch 10/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3810 - accuracy: 0.8320 - precision_3: 0.8250 - recall_3: 0.8483 - custom_f1: 0.8343\nEpoch 10: val_loss improved from 0.43011 to 0.41948, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3866 - accuracy: 0.8270 - precision_3: 0.8102 - recall_3: 0.8540 - custom_f1: 0.8153 - val_loss: 0.4195 - val_accuracy: 0.8320 - val_precision_3: 0.7902 - val_recall_3: 0.9040 - val_custom_f1: 0.6172 - lr: 3.8742e-04\nEpoch 11/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.4004 - accuracy: 0.8216 - precision_3: 0.8153 - recall_3: 0.8422 - custom_f1: 0.8295\nEpoch 11: val_loss improved from 0.41948 to 0.40170, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8230 - precision_3: 0.8148 - recall_3: 0.8360 - custom_f1: 0.8237 - val_loss: 0.4017 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6205 - lr: 3.4868e-04\nEpoch 12/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3949 - accuracy: 0.8075 - precision_3: 0.8055 - recall_3: 0.8095 - custom_f1: 0.8029\nEpoch 12: val_loss improved from 0.40170 to 0.39132, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8060 - precision_3: 0.8036 - recall_3: 0.8100 - custom_f1: 0.7797 - val_loss: 0.3913 - val_accuracy: 0.8240 - val_precision_3: 0.7755 - val_recall_3: 0.9120 - val_custom_f1: 0.6095 - lr: 3.1381e-04\nEpoch 13/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3821 - accuracy: 0.8288 - precision_3: 0.8157 - recall_3: 0.8613 - custom_f1: 0.8340\nEpoch 13: val_loss improved from 0.39132 to 0.37581, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8280 - precision_3: 0.8060 - recall_3: 0.8640 - custom_f1: 0.8305 - val_loss: 0.3758 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6187 - lr: 2.8243e-04\nEpoch 14/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3870 - accuracy: 0.8229 - precision_3: 0.8237 - recall_3: 0.8321 - custom_f1: 0.8257\nEpoch 14: val_loss improved from 0.37581 to 0.37034, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8280 - precision_3: 0.8216 - recall_3: 0.8380 - custom_f1: 0.8268 - val_loss: 0.3703 - val_accuracy: 0.8480 - val_precision_3: 0.7919 - val_recall_3: 0.9440 - val_custom_f1: 0.6367 - lr: 2.5419e-04\nEpoch 15/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3509 - accuracy: 0.8413 - precision_3: 0.8260 - recall_3: 0.8575 - custom_f1: 0.8402\nEpoch 15: val_loss improved from 0.37034 to 0.36080, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3411 - accuracy: 0.8460 - precision_3: 0.8302 - recall_3: 0.8700 - custom_f1: 0.8476 - val_loss: 0.3608 - val_accuracy: 0.8320 - val_precision_3: 0.7862 - val_recall_3: 0.9120 - val_custom_f1: 0.6161 - lr: 2.2877e-04\nEpoch 16/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3526 - accuracy: 0.8512 - precision_3: 0.8350 - recall_3: 0.8709 - custom_f1: 0.8470\nEpoch 16: val_loss did not improve from 0.36080\n32/32 [==============================] - 0s 6ms/step - loss: 0.3475 - accuracy: 0.8590 - precision_3: 0.8485 - recall_3: 0.8740 - custom_f1: 0.8567 - val_loss: 0.3633 - val_accuracy: 0.8320 - val_precision_3: 0.7785 - val_recall_3: 0.9280 - val_custom_f1: 0.6121 - lr: 2.0589e-04\nEpoch 17/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3416 - accuracy: 0.8363 - precision_3: 0.8223 - recall_3: 0.8610 - custom_f1: 0.8369\nEpoch 17: val_loss improved from 0.36080 to 0.35669, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3487 - accuracy: 0.8370 - precision_3: 0.8210 - recall_3: 0.8620 - custom_f1: 0.8360 - val_loss: 0.3567 - val_accuracy: 0.8320 - val_precision_3: 0.7785 - val_recall_3: 0.9280 - val_custom_f1: 0.6140 - lr: 1.8530e-04\nEpoch 18/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3827 - accuracy: 0.8313 - precision_3: 0.8200 - recall_3: 0.8467 - custom_f1: 0.8300\nEpoch 18: val_loss improved from 0.35669 to 0.35114, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8250 - precision_3: 0.8168 - recall_3: 0.8380 - custom_f1: 0.8182 - val_loss: 0.3511 - val_accuracy: 0.8400 - val_precision_3: 0.7852 - val_recall_3: 0.9360 - val_custom_f1: 0.6325 - lr: 1.6677e-04\nEpoch 19/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3348 - accuracy: 0.8575 - precision_3: 0.8293 - recall_3: 0.8892 - custom_f1: 0.8575\nEpoch 19: val_loss did not improve from 0.35114\n32/32 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.8600 - precision_3: 0.8371 - recall_3: 0.8940 - custom_f1: 0.8666 - val_loss: 0.3537 - val_accuracy: 0.8360 - val_precision_3: 0.7877 - val_recall_3: 0.9200 - val_custom_f1: 0.6198 - lr: 1.5009e-04\nEpoch 20/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3441 - accuracy: 0.8525 - precision_3: 0.8345 - recall_3: 0.8840 - custom_f1: 0.8567\nEpoch 20: val_loss improved from 0.35114 to 0.34693, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8470 - precision_3: 0.8255 - recall_3: 0.8800 - custom_f1: 0.8512 - val_loss: 0.3469 - val_accuracy: 0.8360 - val_precision_3: 0.7800 - val_recall_3: 0.9360 - val_custom_f1: 0.6161 - lr: 1.3509e-04\nEpoch 21/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3205 - accuracy: 0.8650 - precision_3: 0.8621 - recall_3: 0.8706 - custom_f1: 0.8649\nEpoch 21: val_loss did not improve from 0.34693\n32/32 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8590 - precision_3: 0.8472 - recall_3: 0.8760 - custom_f1: 0.8498 - val_loss: 0.3480 - val_accuracy: 0.8440 - val_precision_3: 0.7867 - val_recall_3: 0.9440 - val_custom_f1: 0.6374 - lr: 1.2158e-04\nEpoch 22/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3364 - accuracy: 0.8537 - precision_3: 0.8345 - recall_3: 0.8788 - custom_f1: 0.8577\nEpoch 22: val_loss improved from 0.34693 to 0.34637, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3246 - accuracy: 0.8640 - precision_3: 0.8514 - recall_3: 0.8820 - custom_f1: 0.8702 - val_loss: 0.3464 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6206 - lr: 1.0942e-04\nEpoch 23/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3165 - accuracy: 0.8650 - precision_3: 0.8641 - recall_3: 0.8725 - custom_f1: 0.8650\nEpoch 23: val_loss improved from 0.34637 to 0.34633, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3295 - accuracy: 0.8610 - precision_3: 0.8574 - recall_3: 0.8660 - custom_f1: 0.8563 - val_loss: 0.3463 - val_accuracy: 0.8360 - val_precision_3: 0.7800 - val_recall_3: 0.9360 - val_custom_f1: 0.6161 - lr: 9.8477e-05\nEpoch 24/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3123 - accuracy: 0.8725 - precision_3: 0.8575 - recall_3: 0.8920 - custom_f1: 0.8726\nEpoch 24: val_loss improved from 0.34633 to 0.34247, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3342 - accuracy: 0.8620 - precision_3: 0.8508 - recall_3: 0.8780 - custom_f1: 0.8631 - val_loss: 0.3425 - val_accuracy: 0.8320 - val_precision_3: 0.7748 - val_recall_3: 0.9360 - val_custom_f1: 0.6138 - lr: 8.8629e-05\nEpoch 25/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3244 - accuracy: 0.8633 - precision_3: 0.8454 - recall_3: 0.8951 - custom_f1: 0.8699\nEpoch 25: val_loss improved from 0.34247 to 0.33980, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3305 - accuracy: 0.8580 - precision_3: 0.8377 - recall_3: 0.8880 - custom_f1: 0.8558 - val_loss: 0.3398 - val_accuracy: 0.8360 - val_precision_3: 0.7800 - val_recall_3: 0.9360 - val_custom_f1: 0.6165 - lr: 7.9766e-05\nEpoch 26/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3111 - accuracy: 0.8800 - precision_3: 0.8537 - recall_3: 0.9105 - custom_f1: 0.8810\nEpoch 26: val_loss improved from 0.33980 to 0.33525, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3246 - accuracy: 0.8610 - precision_3: 0.8399 - recall_3: 0.8920 - custom_f1: 0.8629 - val_loss: 0.3353 - val_accuracy: 0.8440 - val_precision_3: 0.7867 - val_recall_3: 0.9440 - val_custom_f1: 0.6214 - lr: 7.1790e-05\nEpoch 27/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3074 - accuracy: 0.8650 - precision_3: 0.8376 - recall_3: 0.9048 - custom_f1: 0.8656\nEpoch 27: val_loss did not improve from 0.33525\n32/32 [==============================] - 0s 6ms/step - loss: 0.3080 - accuracy: 0.8660 - precision_3: 0.8427 - recall_3: 0.9000 - custom_f1: 0.8605 - val_loss: 0.3355 - val_accuracy: 0.8440 - val_precision_3: 0.7867 - val_recall_3: 0.9440 - val_custom_f1: 0.6214 - lr: 6.4611e-05\nEpoch 28/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3221 - accuracy: 0.8763 - precision_3: 0.8711 - recall_3: 0.8825 - custom_f1: 0.8742\nEpoch 28: val_loss improved from 0.33525 to 0.33469, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3213 - accuracy: 0.8730 - precision_3: 0.8693 - recall_3: 0.8780 - custom_f1: 0.8737 - val_loss: 0.3347 - val_accuracy: 0.8440 - val_precision_3: 0.7867 - val_recall_3: 0.9440 - val_custom_f1: 0.6214 - lr: 5.8150e-05\nEpoch 29/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3428 - accuracy: 0.8646 - precision_3: 0.8425 - recall_3: 0.8795 - custom_f1: 0.8598\nEpoch 29: val_loss did not improve from 0.33469\n32/32 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8690 - precision_3: 0.8639 - recall_3: 0.8760 - custom_f1: 0.8709 - val_loss: 0.3356 - val_accuracy: 0.8360 - val_precision_3: 0.7800 - val_recall_3: 0.9360 - val_custom_f1: 0.6161 - lr: 5.2335e-05\nEpoch 30/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3318 - accuracy: 0.8587 - precision_3: 0.8421 - recall_3: 0.8822 - custom_f1: 0.8568\nEpoch 30: val_loss did not improve from 0.33469\n32/32 [==============================] - 0s 6ms/step - loss: 0.3245 - accuracy: 0.8650 - precision_3: 0.8530 - recall_3: 0.8820 - custom_f1: 0.8610 - val_loss: 0.3360 - val_accuracy: 0.8400 - val_precision_3: 0.7815 - val_recall_3: 0.9440 - val_custom_f1: 0.6187 - lr: 4.7101e-05\nEpoch 31/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3237 - accuracy: 0.8587 - precision_3: 0.8314 - recall_3: 0.8965 - custom_f1: 0.8573\nEpoch 31: val_loss did not improve from 0.33469\n32/32 [==============================] - 0s 6ms/step - loss: 0.3211 - accuracy: 0.8610 - precision_3: 0.8336 - recall_3: 0.9020 - custom_f1: 0.8599 - val_loss: 0.3352 - val_accuracy: 0.8320 - val_precision_3: 0.7748 - val_recall_3: 0.9360 - val_custom_f1: 0.6138 - lr: 4.2391e-05\nEpoch 32/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2860 - accuracy: 0.8880 - precision_3: 0.8700 - recall_3: 0.9110 - custom_f1: 0.8805\nEpoch 32: val_loss improved from 0.33469 to 0.33341, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.2965 - accuracy: 0.8780 - precision_3: 0.8593 - recall_3: 0.9040 - custom_f1: 0.8732 - val_loss: 0.3334 - val_accuracy: 0.8400 - val_precision_3: 0.7852 - val_recall_3: 0.9360 - val_custom_f1: 0.6183 - lr: 3.8152e-05\nEpoch 33/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3261 - accuracy: 0.8550 - precision_3: 0.8432 - recall_3: 0.8765 - custom_f1: 0.8552\nEpoch 33: val_loss improved from 0.33341 to 0.33237, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3157 - accuracy: 0.8670 - precision_3: 0.8509 - recall_3: 0.8900 - custom_f1: 0.8689 - val_loss: 0.3324 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6162 - lr: 3.4337e-05\nEpoch 34/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3121 - accuracy: 0.8682 - precision_3: 0.8575 - recall_3: 0.8832 - custom_f1: 0.8663\nEpoch 34: val_loss did not improve from 0.33237\n32/32 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.8650 - precision_3: 0.8614 - recall_3: 0.8700 - custom_f1: 0.8560 - val_loss: 0.3328 - val_accuracy: 0.8360 - val_precision_3: 0.7800 - val_recall_3: 0.9360 - val_custom_f1: 0.6161 - lr: 3.0903e-05\nEpoch 35/300\n30/32 [===========================>..] - ETA: 0s - loss: 0.3259 - accuracy: 0.8708 - precision_3: 0.8445 - recall_3: 0.9051 - custom_f1: 0.8710\nEpoch 35: val_loss did not improve from 0.33237\n32/32 [==============================] - 0s 7ms/step - loss: 0.3230 - accuracy: 0.8710 - precision_3: 0.8493 - recall_3: 0.9020 - custom_f1: 0.8716 - val_loss: 0.3336 - val_accuracy: 0.8360 - val_precision_3: 0.7800 - val_recall_3: 0.9360 - val_custom_f1: 0.6161 - lr: 2.7813e-05\nEpoch 36/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3125 - accuracy: 0.8659 - precision_3: 0.8417 - recall_3: 0.8933 - custom_f1: 0.8641\nEpoch 36: val_loss did not improve from 0.33237\n32/32 [==============================] - 0s 6ms/step - loss: 0.3138 - accuracy: 0.8710 - precision_3: 0.8507 - recall_3: 0.9000 - custom_f1: 0.8680 - val_loss: 0.3329 - val_accuracy: 0.8320 - val_precision_3: 0.7785 - val_recall_3: 0.9280 - val_custom_f1: 0.6140 - lr: 2.5032e-05\nEpoch 37/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3104 - accuracy: 0.8612 - precision_3: 0.8527 - recall_3: 0.8799 - custom_f1: 0.8624\nEpoch 37: val_loss did not improve from 0.33237\n32/32 [==============================] - 0s 6ms/step - loss: 0.3036 - accuracy: 0.8670 - precision_3: 0.8495 - recall_3: 0.8920 - custom_f1: 0.8617 - val_loss: 0.3335 - val_accuracy: 0.8360 - val_precision_3: 0.7800 - val_recall_3: 0.9360 - val_custom_f1: 0.6161 - lr: 2.2528e-05\nEpoch 38/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3060 - accuracy: 0.8750 - precision_3: 0.8630 - recall_3: 0.8957 - custom_f1: 0.8779\nEpoch 38: val_loss did not improve from 0.33237\n32/32 [==============================] - 0s 6ms/step - loss: 0.3128 - accuracy: 0.8700 - precision_3: 0.8517 - recall_3: 0.8960 - custom_f1: 0.8700 - val_loss: 0.3334 - val_accuracy: 0.8320 - val_precision_3: 0.7785 - val_recall_3: 0.9280 - val_custom_f1: 0.6140 - lr: 2.0276e-05\nEpoch 39/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3159 - accuracy: 0.8725 - precision_3: 0.8551 - recall_3: 0.9015 - custom_f1: 0.8749\nEpoch 39: val_loss improved from 0.33237 to 0.33128, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3254 - accuracy: 0.8670 - precision_3: 0.8509 - recall_3: 0.8900 - custom_f1: 0.8607 - val_loss: 0.3313 - val_accuracy: 0.8480 - val_precision_3: 0.8000 - val_recall_3: 0.9280 - val_custom_f1: 0.6284 - lr: 1.8248e-05\nEpoch 40/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3012 - accuracy: 0.8788 - precision_3: 0.8725 - recall_3: 0.8835 - custom_f1: 0.8740\nEpoch 40: val_loss did not improve from 0.33128\n32/32 [==============================] - 0s 6ms/step - loss: 0.3031 - accuracy: 0.8780 - precision_3: 0.8691 - recall_3: 0.8900 - custom_f1: 0.8785 - val_loss: 0.3324 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 1.6423e-05\nEpoch 41/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3116 - accuracy: 0.8650 - precision_3: 0.8520 - recall_3: 0.8859 - custom_f1: 0.8651\nEpoch 41: val_loss did not improve from 0.33128\n32/32 [==============================] - 0s 6ms/step - loss: 0.3236 - accuracy: 0.8560 - precision_3: 0.8371 - recall_3: 0.8840 - custom_f1: 0.8542 - val_loss: 0.3328 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.4781e-05\nEpoch 42/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3027 - accuracy: 0.8841 - precision_3: 0.8649 - recall_3: 0.9119 - custom_f1: 0.8870\nEpoch 42: val_loss did not improve from 0.33128\n32/32 [==============================] - 0s 6ms/step - loss: 0.3029 - accuracy: 0.8840 - precision_3: 0.8664 - recall_3: 0.9080 - custom_f1: 0.8841 - val_loss: 0.3325 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.3303e-05\nEpoch 43/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3118 - accuracy: 0.8813 - precision_3: 0.8592 - recall_3: 0.9091 - custom_f1: 0.8796\nEpoch 43: val_loss did not improve from 0.33128\n32/32 [==============================] - 0s 6ms/step - loss: 0.3078 - accuracy: 0.8760 - precision_3: 0.8629 - recall_3: 0.8940 - custom_f1: 0.8658 - val_loss: 0.3322 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.1973e-05\nEpoch 44/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3100 - accuracy: 0.8791 - precision_3: 0.8613 - recall_3: 0.9014 - custom_f1: 0.8779\nEpoch 44: val_loss did not improve from 0.33128\n32/32 [==============================] - 0s 6ms/step - loss: 0.3184 - accuracy: 0.8710 - precision_3: 0.8547 - recall_3: 0.8940 - custom_f1: 0.8713 - val_loss: 0.3315 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.0775e-05\nEpoch 45/300\n32/32 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.8660 - precision_3: 0.8401 - recall_3: 0.9040 - custom_f1: 0.8730\nEpoch 45: val_loss improved from 0.33128 to 0.33090, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3095 - accuracy: 0.8660 - precision_3: 0.8401 - recall_3: 0.9040 - custom_f1: 0.8730 - val_loss: 0.3309 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 9.6977e-06\nEpoch 46/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3104 - accuracy: 0.8777 - precision_3: 0.8591 - recall_3: 0.8930 - custom_f1: 0.8720\nEpoch 46: val_loss did not improve from 0.33090\n32/32 [==============================] - 0s 7ms/step - loss: 0.3159 - accuracy: 0.8720 - precision_3: 0.8633 - recall_3: 0.8840 - custom_f1: 0.8726 - val_loss: 0.3311 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 8.7280e-06\nEpoch 47/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3034 - accuracy: 0.8841 - precision_3: 0.8840 - recall_3: 0.8863 - custom_f1: 0.8837\nEpoch 47: val_loss did not improve from 0.33090\n32/32 [==============================] - 0s 6ms/step - loss: 0.3069 - accuracy: 0.8810 - precision_3: 0.8699 - recall_3: 0.8960 - custom_f1: 0.8782 - val_loss: 0.3315 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 7.8552e-06\nEpoch 48/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3153 - accuracy: 0.8620 - precision_3: 0.8365 - recall_3: 0.9016 - custom_f1: 0.8608\nEpoch 48: val_loss improved from 0.33090 to 0.33080, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3187 - accuracy: 0.8590 - precision_3: 0.8355 - recall_3: 0.8940 - custom_f1: 0.8571 - val_loss: 0.3308 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 7.0697e-06\nEpoch 49/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3083 - accuracy: 0.8620 - precision_3: 0.8386 - recall_3: 0.8992 - custom_f1: 0.8636\nEpoch 49: val_loss did not improve from 0.33080\n32/32 [==============================] - 0s 6ms/step - loss: 0.3025 - accuracy: 0.8630 - precision_3: 0.8418 - recall_3: 0.8940 - custom_f1: 0.8677 - val_loss: 0.3309 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 6.3627e-06\nEpoch 50/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2825 - accuracy: 0.8938 - precision_3: 0.8821 - recall_3: 0.9066 - custom_f1: 0.8932\nEpoch 50: val_loss did not improve from 0.33080\n32/32 [==============================] - 0s 6ms/step - loss: 0.2943 - accuracy: 0.8860 - precision_3: 0.8726 - recall_3: 0.9040 - custom_f1: 0.8858 - val_loss: 0.3311 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 5.7264e-06\nEpoch 51/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.2991 - accuracy: 0.8854 - precision_3: 0.8716 - recall_3: 0.9075 - custom_f1: 0.8868\nEpoch 51: val_loss improved from 0.33080 to 0.33071, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.2996 - accuracy: 0.8880 - precision_3: 0.8702 - recall_3: 0.9120 - custom_f1: 0.8861 - val_loss: 0.3307 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 5.1538e-06\nEpoch 52/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3066 - accuracy: 0.8560 - precision_3: 0.8453 - recall_3: 0.8685 - custom_f1: 0.8547\nEpoch 52: val_loss improved from 0.33071 to 0.33028, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3057 - accuracy: 0.8600 - precision_3: 0.8475 - recall_3: 0.8780 - custom_f1: 0.8611 - val_loss: 0.3303 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 4.6384e-06\nEpoch 53/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3693 - accuracy: 0.8329 - precision_3: 0.8056 - recall_3: 0.8740 - custom_f1: 0.8333\nEpoch 53: val_loss did not improve from 0.33028\n32/32 [==============================] - 0s 7ms/step - loss: 0.3415 - accuracy: 0.8490 - precision_3: 0.8299 - recall_3: 0.8780 - custom_f1: 0.8492 - val_loss: 0.3303 - val_accuracy: 0.8440 - val_precision_3: 0.7905 - val_recall_3: 0.9360 - val_custom_f1: 0.6224 - lr: 4.1746e-06\nEpoch 54/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2989 - accuracy: 0.8845 - precision_3: 0.8724 - recall_3: 0.9030 - custom_f1: 0.8850\nEpoch 54: val_loss improved from 0.33028 to 0.32998, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3072 - accuracy: 0.8770 - precision_3: 0.8632 - recall_3: 0.8960 - custom_f1: 0.8742 - val_loss: 0.3300 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 3.7571e-06\nEpoch 55/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3006 - accuracy: 0.8764 - precision_3: 0.8698 - recall_3: 0.8907 - custom_f1: 0.8770\nEpoch 55: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3107 - accuracy: 0.8630 - precision_3: 0.8431 - recall_3: 0.8920 - custom_f1: 0.8603 - val_loss: 0.3302 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 3.3814e-06\nEpoch 56/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3206 - accuracy: 0.8662 - precision_3: 0.8361 - recall_3: 0.8990 - custom_f1: 0.8625\nEpoch 56: val_loss improved from 0.32998 to 0.32998, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3120 - accuracy: 0.8700 - precision_3: 0.8517 - recall_3: 0.8960 - custom_f1: 0.8693 - val_loss: 0.3300 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 3.0433e-06\nEpoch 57/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3203 - accuracy: 0.8709 - precision_3: 0.8440 - recall_3: 0.9066 - custom_f1: 0.8686\nEpoch 57: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3056 - accuracy: 0.8790 - precision_3: 0.8542 - recall_3: 0.9140 - custom_f1: 0.8675 - val_loss: 0.3300 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 2.7389e-06\nEpoch 58/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3127 - accuracy: 0.8776 - precision_3: 0.8680 - recall_3: 0.8906 - custom_f1: 0.8755\nEpoch 58: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3186 - accuracy: 0.8740 - precision_3: 0.8638 - recall_3: 0.8880 - custom_f1: 0.8686 - val_loss: 0.3306 - val_accuracy: 0.8440 - val_precision_3: 0.7905 - val_recall_3: 0.9360 - val_custom_f1: 0.6224 - lr: 2.4650e-06\nEpoch 59/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3273 - accuracy: 0.8620 - precision_3: 0.8382 - recall_3: 0.8990 - custom_f1: 0.8647\nEpoch 59: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3073 - accuracy: 0.8710 - precision_3: 0.8442 - recall_3: 0.9100 - custom_f1: 0.8722 - val_loss: 0.3302 - val_accuracy: 0.8440 - val_precision_3: 0.7905 - val_recall_3: 0.9360 - val_custom_f1: 0.6224 - lr: 2.2185e-06\nEpoch 60/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3086 - accuracy: 0.8668 - precision_3: 0.8425 - recall_3: 0.8942 - custom_f1: 0.8641\nEpoch 60: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3120 - accuracy: 0.8660 - precision_3: 0.8506 - recall_3: 0.8880 - custom_f1: 0.8634 - val_loss: 0.3302 - val_accuracy: 0.8440 - val_precision_3: 0.7905 - val_recall_3: 0.9360 - val_custom_f1: 0.6224 - lr: 1.9967e-06\nEpoch 61/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3065 - accuracy: 0.8620 - precision_3: 0.8442 - recall_3: 0.8842 - custom_f1: 0.8601\nEpoch 61: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3033 - accuracy: 0.8640 - precision_3: 0.8487 - recall_3: 0.8860 - custom_f1: 0.8628 - val_loss: 0.3304 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.7970e-06\nEpoch 62/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3169 - accuracy: 0.8568 - precision_3: 0.8349 - recall_3: 0.8949 - custom_f1: 0.8607\nEpoch 62: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3169 - accuracy: 0.8580 - precision_3: 0.8365 - recall_3: 0.8900 - custom_f1: 0.8634 - val_loss: 0.3304 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.6173e-06\nEpoch 63/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2979 - accuracy: 0.8813 - precision_3: 0.8612 - recall_3: 0.9104 - custom_f1: 0.8854\nEpoch 63: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3063 - accuracy: 0.8800 - precision_3: 0.8612 - recall_3: 0.9060 - custom_f1: 0.8856 - val_loss: 0.3310 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.4556e-06\nEpoch 64/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3122 - accuracy: 0.8637 - precision_3: 0.8454 - recall_3: 0.8936 - custom_f1: 0.8649\nEpoch 64: ReduceLROnPlateau reducing learning rate to 1e-06.\n\nEpoch 64: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3149 - accuracy: 0.8600 - precision_3: 0.8358 - recall_3: 0.8960 - custom_f1: 0.8544 - val_loss: 0.3310 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 1.0000e-06\nEpoch 65/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3019 - accuracy: 0.8685 - precision_3: 0.8430 - recall_3: 0.9065 - custom_f1: 0.8688\nEpoch 65: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3037 - accuracy: 0.8680 - precision_3: 0.8459 - recall_3: 0.9000 - custom_f1: 0.8661 - val_loss: 0.3305 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.1790e-06\nEpoch 66/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3272 - accuracy: 0.8662 - precision_3: 0.8609 - recall_3: 0.8799 - custom_f1: 0.8700\nEpoch 66: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3240 - accuracy: 0.8630 - precision_3: 0.8552 - recall_3: 0.8740 - custom_f1: 0.8608 - val_loss: 0.3302 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.0611e-06\nEpoch 67/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3019 - accuracy: 0.8859 - precision_3: 0.8766 - recall_3: 0.9045 - custom_f1: 0.8881\nEpoch 67: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.2996 - accuracy: 0.8830 - precision_3: 0.8704 - recall_3: 0.9000 - custom_f1: 0.8820 - val_loss: 0.3306 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 9.5500e-07\nEpoch 68/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3041 - accuracy: 0.8700 - precision_3: 0.8637 - recall_3: 0.8809 - custom_f1: 0.8668\nEpoch 68: val_loss did not improve from 0.32998\n32/32 [==============================] - 0s 6ms/step - loss: 0.3113 - accuracy: 0.8610 - precision_3: 0.8519 - recall_3: 0.8740 - custom_f1: 0.8569 - val_loss: 0.3302 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 8.5950e-07\nEpoch 69/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3171 - accuracy: 0.8587 - precision_3: 0.8425 - recall_3: 0.8708 - custom_f1: 0.8530\nEpoch 69: val_loss improved from 0.32998 to 0.32992, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3166 - accuracy: 0.8650 - precision_3: 0.8600 - recall_3: 0.8720 - custom_f1: 0.8650 - val_loss: 0.3299 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 7.7355e-07\nEpoch 70/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3121 - accuracy: 0.8607 - precision_3: 0.8441 - recall_3: 0.8857 - custom_f1: 0.8617\nEpoch 70: val_loss did not improve from 0.32992\n32/32 [==============================] - 0s 6ms/step - loss: 0.3014 - accuracy: 0.8740 - precision_3: 0.8624 - recall_3: 0.8900 - custom_f1: 0.8747 - val_loss: 0.3299 - val_accuracy: 0.8440 - val_precision_3: 0.7945 - val_recall_3: 0.9280 - val_custom_f1: 0.6262 - lr: 6.9620e-07\nEpoch 71/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3257 - accuracy: 0.8737 - precision_3: 0.8619 - recall_3: 0.8938 - custom_f1: 0.8745\nEpoch 71: val_loss improved from 0.32992 to 0.32974, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8750 - precision_3: 0.8585 - recall_3: 0.8980 - custom_f1: 0.8778 - val_loss: 0.3297 - val_accuracy: 0.8440 - val_precision_3: 0.7945 - val_recall_3: 0.9280 - val_custom_f1: 0.6262 - lr: 6.2658e-07\nEpoch 72/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3176 - accuracy: 0.8575 - precision_3: 0.8550 - recall_3: 0.8635 - custom_f1: 0.8599\nEpoch 72: val_loss improved from 0.32974 to 0.32972, saving model to best_hybrid_fold4_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3150 - accuracy: 0.8650 - precision_3: 0.8571 - recall_3: 0.8760 - custom_f1: 0.8650 - val_loss: 0.3297 - val_accuracy: 0.8480 - val_precision_3: 0.8000 - val_recall_3: 0.9280 - val_custom_f1: 0.6284 - lr: 5.6392e-07\nEpoch 73/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3206 - accuracy: 0.8650 - precision_3: 0.8416 - recall_3: 0.8967 - custom_f1: 0.8685\nEpoch 73: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3115 - accuracy: 0.8740 - precision_3: 0.8555 - recall_3: 0.9000 - custom_f1: 0.8752 - val_loss: 0.3301 - val_accuracy: 0.8440 - val_precision_3: 0.7945 - val_recall_3: 0.9280 - val_custom_f1: 0.6262 - lr: 5.0753e-07\nEpoch 74/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3213 - accuracy: 0.8562 - precision_3: 0.8418 - recall_3: 0.8737 - custom_f1: 0.8531\nEpoch 74: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3154 - accuracy: 0.8630 - precision_3: 0.8524 - recall_3: 0.8780 - custom_f1: 0.8644 - val_loss: 0.3305 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 4.5678e-07\nEpoch 75/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.2933 - accuracy: 0.8810 - precision_3: 0.8692 - recall_3: 0.8964 - custom_f1: 0.8840\nEpoch 75: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.2862 - accuracy: 0.8830 - precision_3: 0.8733 - recall_3: 0.8960 - custom_f1: 0.8848 - val_loss: 0.3302 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 4.1110e-07\nEpoch 76/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2952 - accuracy: 0.8913 - precision_3: 0.8878 - recall_3: 0.8988 - custom_f1: 0.8925\nEpoch 76: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3040 - accuracy: 0.8840 - precision_3: 0.8765 - recall_3: 0.8940 - custom_f1: 0.8840 - val_loss: 0.3301 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 3.6999e-07\nEpoch 77/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2945 - accuracy: 0.8900 - precision_3: 0.8690 - recall_3: 0.9242 - custom_f1: 0.8923\nEpoch 77: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.2913 - accuracy: 0.8910 - precision_3: 0.8668 - recall_3: 0.9240 - custom_f1: 0.8940 - val_loss: 0.3307 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 3.3299e-07\nEpoch 78/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3173 - accuracy: 0.8650 - precision_3: 0.8460 - recall_3: 0.8925 - custom_f1: 0.8692\nEpoch 78: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3124 - accuracy: 0.8630 - precision_3: 0.8380 - recall_3: 0.9000 - custom_f1: 0.8683 - val_loss: 0.3311 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 2.9969e-07\nEpoch 79/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.2834 - accuracy: 0.8886 - precision_3: 0.8859 - recall_3: 0.8954 - custom_f1: 0.8864\nEpoch 79: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.2976 - accuracy: 0.8740 - precision_3: 0.8652 - recall_3: 0.8860 - custom_f1: 0.8711 - val_loss: 0.3308 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 2.6972e-07\nEpoch 80/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3045 - accuracy: 0.8700 - precision_3: 0.8467 - recall_3: 0.9020 - custom_f1: 0.8688\nEpoch 80: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.2990 - accuracy: 0.8780 - precision_3: 0.8580 - recall_3: 0.9060 - custom_f1: 0.8786 - val_loss: 0.3301 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 2.4275e-07\nEpoch 81/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3055 - accuracy: 0.8700 - precision_3: 0.8544 - recall_3: 0.8928 - custom_f1: 0.8659\nEpoch 81: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3083 - accuracy: 0.8690 - precision_3: 0.8528 - recall_3: 0.8920 - custom_f1: 0.8661 - val_loss: 0.3299 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 2.1847e-07\nEpoch 82/300\n30/32 [===========================>..] - ETA: 0s - loss: 0.2981 - accuracy: 0.8729 - precision_3: 0.8714 - recall_3: 0.8786 - custom_f1: 0.8739\nEpoch 82: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 7ms/step - loss: 0.3012 - accuracy: 0.8700 - precision_3: 0.8642 - recall_3: 0.8780 - custom_f1: 0.8722 - val_loss: 0.3304 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.9663e-07\nEpoch 83/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3295 - accuracy: 0.8702 - precision_3: 0.8616 - recall_3: 0.8783 - custom_f1: 0.8679\nEpoch 83: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3210 - accuracy: 0.8700 - precision_3: 0.8613 - recall_3: 0.8820 - custom_f1: 0.8684 - val_loss: 0.3304 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.7696e-07\nEpoch 84/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3145 - accuracy: 0.8813 - precision_3: 0.8654 - recall_3: 0.9023 - custom_f1: 0.8812\nEpoch 84: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8730 - precision_3: 0.8552 - recall_3: 0.8980 - custom_f1: 0.8619 - val_loss: 0.3310 - val_accuracy: 0.8400 - val_precision_3: 0.7852 - val_recall_3: 0.9360 - val_custom_f1: 0.6189 - lr: 1.5927e-07\nEpoch 85/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3023 - accuracy: 0.8858 - precision_3: 0.8897 - recall_3: 0.8833 - custom_f1: 0.8835\nEpoch 85: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.8870 - precision_3: 0.8817 - recall_3: 0.8940 - custom_f1: 0.8847 - val_loss: 0.3308 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 1.4334e-07\nEpoch 86/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2891 - accuracy: 0.8788 - precision_3: 0.8485 - recall_3: 0.9192 - custom_f1: 0.8804\nEpoch 86: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.2908 - accuracy: 0.8780 - precision_3: 0.8526 - recall_3: 0.9140 - custom_f1: 0.8720 - val_loss: 0.3312 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 1.2901e-07\nEpoch 87/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.2908 - accuracy: 0.8850 - precision_3: 0.8598 - recall_3: 0.9200 - custom_f1: 0.8876\nEpoch 87: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.2971 - accuracy: 0.8810 - precision_3: 0.8615 - recall_3: 0.9080 - custom_f1: 0.8739 - val_loss: 0.3306 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 1.1611e-07\nEpoch 88/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3313 - accuracy: 0.8562 - precision_3: 0.8353 - recall_3: 0.8838 - custom_f1: 0.8546\nEpoch 88: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3243 - accuracy: 0.8620 - precision_3: 0.8467 - recall_3: 0.8840 - custom_f1: 0.8557 - val_loss: 0.3306 - val_accuracy: 0.8360 - val_precision_3: 0.7838 - val_recall_3: 0.9280 - val_custom_f1: 0.6168 - lr: 1.0450e-07\nEpoch 89/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3294 - accuracy: 0.8490 - precision_3: 0.8293 - recall_3: 0.8808 - custom_f1: 0.8493\nEpoch 89: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.8550 - precision_3: 0.8368 - recall_3: 0.8820 - custom_f1: 0.8555 - val_loss: 0.3303 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 9.4046e-08\nEpoch 90/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3250 - accuracy: 0.8537 - precision_3: 0.8337 - recall_3: 0.8856 - custom_f1: 0.8532\nEpoch 90: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3188 - accuracy: 0.8610 - precision_3: 0.8399 - recall_3: 0.8920 - custom_f1: 0.8614 - val_loss: 0.3305 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 8.4641e-08\nEpoch 91/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3096 - accuracy: 0.8600 - precision_3: 0.8424 - recall_3: 0.8769 - custom_f1: 0.8573\nEpoch 91: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3180 - accuracy: 0.8590 - precision_3: 0.8485 - recall_3: 0.8740 - custom_f1: 0.8608 - val_loss: 0.3300 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 7.6177e-08\nEpoch 92/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3082 - accuracy: 0.8725 - precision_3: 0.8430 - recall_3: 0.9148 - custom_f1: 0.8752\nEpoch 92: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3095 - accuracy: 0.8730 - precision_3: 0.8473 - recall_3: 0.9100 - custom_f1: 0.8760 - val_loss: 0.3298 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 6.8560e-08\nEpoch 93/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3269 - accuracy: 0.8487 - precision_3: 0.8266 - recall_3: 0.8788 - custom_f1: 0.8499\nEpoch 93: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3364 - accuracy: 0.8500 - precision_3: 0.8289 - recall_3: 0.8820 - custom_f1: 0.8516 - val_loss: 0.3302 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 6.1704e-08\nEpoch 94/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3238 - accuracy: 0.8587 - precision_3: 0.8462 - recall_3: 0.8778 - custom_f1: 0.8588\nEpoch 94: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3240 - accuracy: 0.8540 - precision_3: 0.8365 - recall_3: 0.8800 - custom_f1: 0.8475 - val_loss: 0.3300 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 5.5533e-08\nEpoch 95/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3443 - accuracy: 0.8562 - precision_3: 0.8291 - recall_3: 0.8975 - custom_f1: 0.8593\nEpoch 95: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3371 - accuracy: 0.8590 - precision_3: 0.8318 - recall_3: 0.9000 - custom_f1: 0.8621 - val_loss: 0.3301 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 4.9980e-08\nEpoch 96/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3064 - accuracy: 0.8725 - precision_3: 0.8657 - recall_3: 0.8870 - custom_f1: 0.8718\nEpoch 96: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3155 - accuracy: 0.8690 - precision_3: 0.8555 - recall_3: 0.8880 - custom_f1: 0.8679 - val_loss: 0.3302 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 4.4982e-08\nEpoch 97/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3303 - accuracy: 0.8637 - precision_3: 0.8452 - recall_3: 0.8897 - custom_f1: 0.8653Restoring model weights from the end of the best epoch: 72.\n\nEpoch 97: val_loss did not improve from 0.32972\n32/32 [==============================] - 0s 6ms/step - loss: 0.3228 - accuracy: 0.8700 - precision_3: 0.8531 - recall_3: 0.8940 - custom_f1: 0.8660 - val_loss: 0.3299 - val_accuracy: 0.8400 - val_precision_3: 0.7891 - val_recall_3: 0.9280 - val_custom_f1: 0.6202 - lr: 4.0484e-08\nEpoch 97: early stopping\n\n===== Fold 5 =====\nTraining Hybrid Model...\nEpoch 1/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.7949 - accuracy: 0.5793 - precision_4: 0.5812 - recall_4: 0.5388 - custom_f1: 0.5446 \nEpoch 1: val_loss improved from inf to 0.63238, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 3s 22ms/step - loss: 0.7753 - accuracy: 0.5840 - precision_4: 0.5886 - recall_4: 0.5580 - custom_f1: 0.5634 - val_loss: 0.6324 - val_accuracy: 0.7320 - val_precision_4: 0.7377 - val_recall_4: 0.7200 - val_custom_f1: 0.5747 - lr: 0.0010\nEpoch 2/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.5979 - accuracy: 0.6817 - precision_4: 0.6734 - recall_4: 0.6970 - custom_f1: 0.6782\nEpoch 2: val_loss improved from 0.63238 to 0.58433, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.6780 - precision_4: 0.6732 - recall_4: 0.6920 - custom_f1: 0.6738 - val_loss: 0.5843 - val_accuracy: 0.8040 - val_precision_4: 0.8585 - val_recall_4: 0.7280 - val_custom_f1: 0.6389 - lr: 9.0000e-04\nEpoch 3/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.5813 - accuracy: 0.6956 - precision_4: 0.6902 - recall_4: 0.7047 - custom_f1: 0.6919\nEpoch 3: val_loss improved from 0.58433 to 0.56363, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.5719 - accuracy: 0.7020 - precision_4: 0.6988 - recall_4: 0.7100 - custom_f1: 0.6920 - val_loss: 0.5636 - val_accuracy: 0.8360 - val_precision_4: 0.8962 - val_recall_4: 0.7600 - val_custom_f1: 0.6868 - lr: 8.1000e-04\nEpoch 4/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.5080 - accuracy: 0.7487 - precision_4: 0.7359 - recall_4: 0.7640 - custom_f1: 0.7452\nEpoch 4: val_loss improved from 0.56363 to 0.53412, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.5105 - accuracy: 0.7550 - precision_4: 0.7505 - recall_4: 0.7640 - custom_f1: 0.7549 - val_loss: 0.5341 - val_accuracy: 0.8280 - val_precision_4: 0.8203 - val_recall_4: 0.8400 - val_custom_f1: 0.6390 - lr: 7.2900e-04\nEpoch 5/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.4975 - accuracy: 0.7588 - precision_4: 0.7442 - recall_4: 0.7940 - custom_f1: 0.7641\nEpoch 5: val_loss improved from 0.53412 to 0.50216, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.5041 - accuracy: 0.7600 - precision_4: 0.7425 - recall_4: 0.7960 - custom_f1: 0.7522 - val_loss: 0.5022 - val_accuracy: 0.8760 - val_precision_4: 0.8672 - val_recall_4: 0.8880 - val_custom_f1: 0.7059 - lr: 6.5610e-04\nEpoch 6/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.4533 - accuracy: 0.7986 - precision_4: 0.8125 - recall_4: 0.7905 - custom_f1: 0.7972\nEpoch 6: val_loss improved from 0.50216 to 0.47948, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.7940 - precision_4: 0.7952 - recall_4: 0.7920 - custom_f1: 0.7894 - val_loss: 0.4795 - val_accuracy: 0.8680 - val_precision_4: 0.8898 - val_recall_4: 0.8400 - val_custom_f1: 0.7255 - lr: 5.9049e-04\nEpoch 7/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.4414 - accuracy: 0.7824 - precision_4: 0.7768 - recall_4: 0.8050 - custom_f1: 0.7873\nEpoch 7: val_loss improved from 0.47948 to 0.44597, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7820 - precision_4: 0.7701 - recall_4: 0.8040 - custom_f1: 0.7817 - val_loss: 0.4460 - val_accuracy: 0.8920 - val_precision_4: 0.8828 - val_recall_4: 0.9040 - val_custom_f1: 0.7655 - lr: 5.3144e-04\nEpoch 8/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.4305 - accuracy: 0.7998 - precision_4: 0.7857 - recall_4: 0.8205 - custom_f1: 0.7974\nEpoch 8: val_loss improved from 0.44597 to 0.41885, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.7990 - precision_4: 0.7903 - recall_4: 0.8140 - custom_f1: 0.7865 - val_loss: 0.4188 - val_accuracy: 0.8920 - val_precision_4: 0.8828 - val_recall_4: 0.9040 - val_custom_f1: 0.7583 - lr: 4.7830e-04\nEpoch 9/300\n28/32 [=========================>....] - ETA: 0s - loss: 0.4295 - accuracy: 0.8002 - precision_4: 0.7885 - recall_4: 0.8218 - custom_f1: 0.8030\nEpoch 9: val_loss improved from 0.41885 to 0.38760, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.8030 - precision_4: 0.7919 - recall_4: 0.8220 - custom_f1: 0.8073 - val_loss: 0.3876 - val_accuracy: 0.9000 - val_precision_4: 0.8472 - val_recall_4: 0.9760 - val_custom_f1: 0.7376 - lr: 4.3047e-04\nEpoch 10/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.4098 - accuracy: 0.8125 - precision_4: 0.8005 - recall_4: 0.8313 - custom_f1: 0.8133\nEpoch 10: val_loss improved from 0.38760 to 0.36136, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8020 - precision_4: 0.7893 - recall_4: 0.8240 - custom_f1: 0.7992 - val_loss: 0.3614 - val_accuracy: 0.9200 - val_precision_4: 0.8889 - val_recall_4: 0.9600 - val_custom_f1: 0.7749 - lr: 3.8742e-04\nEpoch 11/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.4099 - accuracy: 0.8229 - precision_4: 0.8341 - recall_4: 0.8172 - custom_f1: 0.8229\nEpoch 11: val_loss improved from 0.36136 to 0.34714, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8240 - precision_4: 0.8214 - recall_4: 0.8280 - custom_f1: 0.8273 - val_loss: 0.3471 - val_accuracy: 0.9160 - val_precision_4: 0.8768 - val_recall_4: 0.9680 - val_custom_f1: 0.7613 - lr: 3.4868e-04\nEpoch 12/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.4231 - accuracy: 0.8032 - precision_4: 0.7895 - recall_4: 0.8295 - custom_f1: 0.8006\nEpoch 12: val_loss improved from 0.34714 to 0.32718, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8050 - precision_4: 0.7894 - recall_4: 0.8320 - custom_f1: 0.8043 - val_loss: 0.3272 - val_accuracy: 0.9160 - val_precision_4: 0.8768 - val_recall_4: 0.9680 - val_custom_f1: 0.7669 - lr: 3.1381e-04\nEpoch 13/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.3680 - accuracy: 0.8160 - precision_4: 0.8044 - recall_4: 0.8394 - custom_f1: 0.8164\nEpoch 13: val_loss improved from 0.32718 to 0.30662, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3701 - accuracy: 0.8170 - precision_4: 0.8019 - recall_4: 0.8420 - custom_f1: 0.8173 - val_loss: 0.3066 - val_accuracy: 0.9200 - val_precision_4: 0.8723 - val_recall_4: 0.9840 - val_custom_f1: 0.7609 - lr: 2.8243e-04\nEpoch 14/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3814 - accuracy: 0.8225 - precision_4: 0.8247 - recall_4: 0.8247 - custom_f1: 0.8213\nEpoch 14: val_loss improved from 0.30662 to 0.29916, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8320 - precision_4: 0.8281 - recall_4: 0.8380 - custom_f1: 0.8284 - val_loss: 0.2992 - val_accuracy: 0.9120 - val_precision_4: 0.8705 - val_recall_4: 0.9680 - val_custom_f1: 0.7549 - lr: 2.5419e-04\nEpoch 15/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3878 - accuracy: 0.8313 - precision_4: 0.8153 - recall_4: 0.8465 - custom_f1: 0.8259\nEpoch 15: val_loss improved from 0.29916 to 0.28954, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8350 - precision_4: 0.8252 - recall_4: 0.8500 - custom_f1: 0.8266 - val_loss: 0.2895 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7620 - lr: 2.2877e-04\nEpoch 16/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3747 - accuracy: 0.8363 - precision_4: 0.8093 - recall_4: 0.8766 - custom_f1: 0.8318\nEpoch 16: val_loss improved from 0.28954 to 0.27734, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.8320 - precision_4: 0.8097 - recall_4: 0.8680 - custom_f1: 0.8295 - val_loss: 0.2773 - val_accuracy: 0.9280 - val_precision_4: 0.8849 - val_recall_4: 0.9840 - val_custom_f1: 0.7758 - lr: 2.0589e-04\nEpoch 17/300\n20/32 [=================>............] - ETA: 0s - loss: 0.3537 - accuracy: 0.8422 - precision_4: 0.8262 - recall_4: 0.8788 - custom_f1: 0.8495\nEpoch 17: val_loss improved from 0.27734 to 0.27244, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3701 - accuracy: 0.8220 - precision_4: 0.8038 - recall_4: 0.8520 - custom_f1: 0.8185 - val_loss: 0.2724 - val_accuracy: 0.9240 - val_precision_4: 0.8786 - val_recall_4: 0.9840 - val_custom_f1: 0.7639 - lr: 1.8530e-04\nEpoch 18/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3548 - accuracy: 0.8413 - precision_4: 0.8193 - recall_4: 0.8673 - custom_f1: 0.8348\nEpoch 18: val_loss improved from 0.27244 to 0.26233, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3673 - accuracy: 0.8310 - precision_4: 0.8177 - recall_4: 0.8520 - custom_f1: 0.8262 - val_loss: 0.2623 - val_accuracy: 0.9280 - val_precision_4: 0.8905 - val_recall_4: 0.9760 - val_custom_f1: 0.7794 - lr: 1.6677e-04\nEpoch 19/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3598 - accuracy: 0.8498 - precision_4: 0.8401 - recall_4: 0.8585 - custom_f1: 0.8451\nEpoch 19: val_loss improved from 0.26233 to 0.25948, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3553 - accuracy: 0.8520 - precision_4: 0.8424 - recall_4: 0.8660 - custom_f1: 0.8493 - val_loss: 0.2595 - val_accuracy: 0.9200 - val_precision_4: 0.8832 - val_recall_4: 0.9680 - val_custom_f1: 0.7713 - lr: 1.5009e-04\nEpoch 20/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3657 - accuracy: 0.8475 - precision_4: 0.8373 - recall_4: 0.8663 - custom_f1: 0.8490\nEpoch 20: val_loss improved from 0.25948 to 0.25550, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3520 - accuracy: 0.8560 - precision_4: 0.8436 - recall_4: 0.8740 - custom_f1: 0.8595 - val_loss: 0.2555 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.3509e-04\nEpoch 21/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3636 - accuracy: 0.8389 - precision_4: 0.8280 - recall_4: 0.8595 - custom_f1: 0.8410\nEpoch 21: val_loss improved from 0.25550 to 0.25354, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3668 - accuracy: 0.8320 - precision_4: 0.8205 - recall_4: 0.8500 - custom_f1: 0.8101 - val_loss: 0.2535 - val_accuracy: 0.9240 - val_precision_4: 0.8786 - val_recall_4: 0.9840 - val_custom_f1: 0.7713 - lr: 1.2158e-04\nEpoch 22/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.3663 - accuracy: 0.8414 - precision_4: 0.8248 - recall_4: 0.8651 - custom_f1: 0.8432\nEpoch 22: val_loss improved from 0.25354 to 0.25096, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8400 - precision_4: 0.8232 - recall_4: 0.8660 - custom_f1: 0.8439 - val_loss: 0.2510 - val_accuracy: 0.9240 - val_precision_4: 0.8786 - val_recall_4: 0.9840 - val_custom_f1: 0.7713 - lr: 1.0942e-04\nEpoch 23/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3387 - accuracy: 0.8546 - precision_4: 0.8389 - recall_4: 0.8844 - custom_f1: 0.8611\nEpoch 23: val_loss improved from 0.25096 to 0.24962, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3353 - accuracy: 0.8610 - precision_4: 0.8412 - recall_4: 0.8900 - custom_f1: 0.8681 - val_loss: 0.2496 - val_accuracy: 0.9280 - val_precision_4: 0.8794 - val_recall_4: 0.9920 - val_custom_f1: 0.7738 - lr: 9.8477e-05\nEpoch 24/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3599 - accuracy: 0.8425 - precision_4: 0.8333 - recall_4: 0.8629 - custom_f1: 0.8450\nEpoch 24: val_loss improved from 0.24962 to 0.24806, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8410 - precision_4: 0.8235 - recall_4: 0.8680 - custom_f1: 0.8445 - val_loss: 0.2481 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 8.8629e-05\nEpoch 25/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.3494 - accuracy: 0.8414 - precision_4: 0.8345 - recall_4: 0.8519 - custom_f1: 0.8403\nEpoch 25: val_loss improved from 0.24806 to 0.24656, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3578 - accuracy: 0.8360 - precision_4: 0.8218 - recall_4: 0.8580 - custom_f1: 0.8360 - val_loss: 0.2466 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 7.9766e-05\nEpoch 26/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3514 - accuracy: 0.8365 - precision_4: 0.8271 - recall_4: 0.8510 - custom_f1: 0.8398\nEpoch 26: val_loss improved from 0.24656 to 0.24438, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8330 - precision_4: 0.8221 - recall_4: 0.8500 - custom_f1: 0.8351 - val_loss: 0.2444 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 7.1790e-05\nEpoch 27/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3258 - accuracy: 0.8650 - precision_4: 0.8449 - recall_4: 0.8917 - custom_f1: 0.8652\nEpoch 27: val_loss improved from 0.24438 to 0.24223, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3424 - accuracy: 0.8550 - precision_4: 0.8460 - recall_4: 0.8680 - custom_f1: 0.8547 - val_loss: 0.2422 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 6.4611e-05\nEpoch 28/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.3461 - accuracy: 0.8484 - precision_4: 0.8300 - recall_4: 0.8744 - custom_f1: 0.8497\nEpoch 28: val_loss improved from 0.24223 to 0.24080, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3519 - accuracy: 0.8490 - precision_4: 0.8349 - recall_4: 0.8700 - custom_f1: 0.8474 - val_loss: 0.2408 - val_accuracy: 0.9280 - val_precision_4: 0.8905 - val_recall_4: 0.9760 - val_custom_f1: 0.7794 - lr: 5.8150e-05\nEpoch 29/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3494 - accuracy: 0.8510 - precision_4: 0.8188 - recall_4: 0.8881 - custom_f1: 0.8512\nEpoch 29: val_loss improved from 0.24080 to 0.24020, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3453 - accuracy: 0.8510 - precision_4: 0.8330 - recall_4: 0.8780 - custom_f1: 0.8572 - val_loss: 0.2402 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 5.2335e-05\nEpoch 30/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.3564 - accuracy: 0.8403 - precision_4: 0.8166 - recall_4: 0.8805 - custom_f1: 0.8444\nEpoch 30: val_loss improved from 0.24020 to 0.23873, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3639 - accuracy: 0.8360 - precision_4: 0.8100 - recall_4: 0.8780 - custom_f1: 0.8337 - val_loss: 0.2387 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 4.7101e-05\nEpoch 31/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3482 - accuracy: 0.8546 - precision_4: 0.8292 - recall_4: 0.8913 - custom_f1: 0.8548\nEpoch 31: val_loss improved from 0.23873 to 0.23720, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 0.8550 - precision_4: 0.8318 - recall_4: 0.8900 - custom_f1: 0.8588 - val_loss: 0.2372 - val_accuracy: 0.9280 - val_precision_4: 0.8849 - val_recall_4: 0.9840 - val_custom_f1: 0.7758 - lr: 4.2391e-05\nEpoch 32/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3383 - accuracy: 0.8525 - precision_4: 0.8393 - recall_4: 0.8728 - custom_f1: 0.8518\nEpoch 32: val_loss improved from 0.23720 to 0.23680, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3394 - accuracy: 0.8500 - precision_4: 0.8327 - recall_4: 0.8760 - custom_f1: 0.8510 - val_loss: 0.2368 - val_accuracy: 0.9280 - val_precision_4: 0.8905 - val_recall_4: 0.9760 - val_custom_f1: 0.7794 - lr: 3.8152e-05\nEpoch 33/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3474 - accuracy: 0.8568 - precision_4: 0.8420 - recall_4: 0.8811 - custom_f1: 0.8584\nEpoch 33: val_loss improved from 0.23680 to 0.23483, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3555 - accuracy: 0.8560 - precision_4: 0.8410 - recall_4: 0.8780 - custom_f1: 0.8577 - val_loss: 0.2348 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 3.4337e-05\nEpoch 34/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3570 - accuracy: 0.8450 - precision_4: 0.8374 - recall_4: 0.8543 - custom_f1: 0.8438\nEpoch 34: val_loss improved from 0.23483 to 0.23428, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8430 - precision_4: 0.8343 - recall_4: 0.8560 - custom_f1: 0.8446 - val_loss: 0.2343 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 3.0903e-05\nEpoch 35/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3514 - accuracy: 0.8475 - precision_4: 0.8259 - recall_4: 0.8797 - custom_f1: 0.8506\nEpoch 35: val_loss improved from 0.23428 to 0.23373, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8490 - precision_4: 0.8324 - recall_4: 0.8740 - custom_f1: 0.8548 - val_loss: 0.2337 - val_accuracy: 0.9280 - val_precision_4: 0.8905 - val_recall_4: 0.9760 - val_custom_f1: 0.7794 - lr: 2.7813e-05\nEpoch 36/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3272 - accuracy: 0.8600 - precision_4: 0.8353 - recall_4: 0.8906 - custom_f1: 0.8612\nEpoch 36: val_loss did not improve from 0.23373\n32/32 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8550 - precision_4: 0.8368 - recall_4: 0.8820 - custom_f1: 0.8613 - val_loss: 0.2340 - val_accuracy: 0.9280 - val_precision_4: 0.8905 - val_recall_4: 0.9760 - val_custom_f1: 0.7873 - lr: 2.5032e-05\nEpoch 37/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3420 - accuracy: 0.8438 - precision_4: 0.8349 - recall_4: 0.8617 - custom_f1: 0.8482\nEpoch 37: val_loss did not improve from 0.23373\n32/32 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.8580 - precision_4: 0.8482 - recall_4: 0.8720 - custom_f1: 0.8555 - val_loss: 0.2348 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.2528e-05\nEpoch 38/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3395 - accuracy: 0.8537 - precision_4: 0.8389 - recall_4: 0.8784 - custom_f1: 0.8555\nEpoch 38: val_loss did not improve from 0.23373\n32/32 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8550 - precision_4: 0.8355 - recall_4: 0.8840 - custom_f1: 0.8601 - val_loss: 0.2344 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.0276e-05\nEpoch 39/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3548 - accuracy: 0.8474 - precision_4: 0.8326 - recall_4: 0.8741 - custom_f1: 0.8492\nEpoch 39: val_loss did not improve from 0.23373\n32/32 [==============================] - 0s 6ms/step - loss: 0.3479 - accuracy: 0.8520 - precision_4: 0.8333 - recall_4: 0.8800 - custom_f1: 0.8566 - val_loss: 0.2341 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 1.8248e-05\nEpoch 40/300\n27/32 [========================>.....] - ETA: 0s - loss: 0.3502 - accuracy: 0.8519 - precision_4: 0.8209 - recall_4: 0.8974 - custom_f1: 0.8518\nEpoch 40: val_loss did not improve from 0.23373\n32/32 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8450 - precision_4: 0.8224 - recall_4: 0.8800 - custom_f1: 0.8427 - val_loss: 0.2343 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.6423e-05\nEpoch 41/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3350 - accuracy: 0.8486 - precision_4: 0.8427 - recall_4: 0.8589 - custom_f1: 0.8488\nEpoch 41: val_loss did not improve from 0.23373\n32/32 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8520 - precision_4: 0.8478 - recall_4: 0.8580 - custom_f1: 0.8502 - val_loss: 0.2338 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.4781e-05\nEpoch 42/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3238 - accuracy: 0.8642 - precision_4: 0.8460 - recall_4: 0.8960 - custom_f1: 0.8669\nEpoch 42: val_loss improved from 0.23373 to 0.23334, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.8640 - precision_4: 0.8396 - recall_4: 0.9000 - custom_f1: 0.8606 - val_loss: 0.2333 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 1.3303e-05\nEpoch 43/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3485 - accuracy: 0.8462 - precision_4: 0.8243 - recall_4: 0.8798 - custom_f1: 0.8477\nEpoch 43: val_loss did not improve from 0.23334\n32/32 [==============================] - 0s 6ms/step - loss: 0.3428 - accuracy: 0.8500 - precision_4: 0.8289 - recall_4: 0.8820 - custom_f1: 0.8548 - val_loss: 0.2345 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.1973e-05\nEpoch 44/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3286 - accuracy: 0.8522 - precision_4: 0.8357 - recall_4: 0.8704 - custom_f1: 0.8502\nEpoch 44: val_loss did not improve from 0.23334\n32/32 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8540 - precision_4: 0.8404 - recall_4: 0.8740 - custom_f1: 0.8584 - val_loss: 0.2341 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 1.0775e-05\nEpoch 45/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3564 - accuracy: 0.8400 - precision_4: 0.8126 - recall_4: 0.8785 - custom_f1: 0.8451\nEpoch 45: val_loss did not improve from 0.23334\n32/32 [==============================] - 0s 6ms/step - loss: 0.3420 - accuracy: 0.8510 - precision_4: 0.8330 - recall_4: 0.8780 - custom_f1: 0.8432 - val_loss: 0.2334 - val_accuracy: 0.9280 - val_precision_4: 0.8905 - val_recall_4: 0.9760 - val_custom_f1: 0.7873 - lr: 9.6977e-06\nEpoch 46/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3090 - accuracy: 0.8800 - precision_4: 0.8578 - recall_4: 0.9021 - custom_f1: 0.8774\nEpoch 46: val_loss improved from 0.23334 to 0.23254, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3216 - accuracy: 0.8720 - precision_4: 0.8591 - recall_4: 0.8900 - custom_f1: 0.8669 - val_loss: 0.2325 - val_accuracy: 0.9280 - val_precision_4: 0.8905 - val_recall_4: 0.9760 - val_custom_f1: 0.7873 - lr: 8.7280e-06\nEpoch 47/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3440 - accuracy: 0.8486 - precision_4: 0.8376 - recall_4: 0.8657 - custom_f1: 0.8486\nEpoch 47: val_loss improved from 0.23254 to 0.23201, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8400 - precision_4: 0.8208 - recall_4: 0.8700 - custom_f1: 0.8427 - val_loss: 0.2320 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7827 - lr: 7.8552e-06\nEpoch 48/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3448 - accuracy: 0.8462 - precision_4: 0.8303 - recall_4: 0.8702 - custom_f1: 0.8448\nEpoch 48: val_loss improved from 0.23201 to 0.23200, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.8490 - precision_4: 0.8311 - recall_4: 0.8760 - custom_f1: 0.8494 - val_loss: 0.2320 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 7.0697e-06\nEpoch 49/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3222 - accuracy: 0.8570 - precision_4: 0.8515 - recall_4: 0.8697 - custom_f1: 0.8589\nEpoch 49: val_loss improved from 0.23200 to 0.23188, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.8550 - precision_4: 0.8368 - recall_4: 0.8820 - custom_f1: 0.8518 - val_loss: 0.2319 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 6.3627e-06\nEpoch 50/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3238 - accuracy: 0.8562 - precision_4: 0.8449 - recall_4: 0.8762 - custom_f1: 0.8578\nEpoch 50: val_loss improved from 0.23188 to 0.23173, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3358 - accuracy: 0.8520 - precision_4: 0.8385 - recall_4: 0.8720 - custom_f1: 0.8444 - val_loss: 0.2317 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 5.7264e-06\nEpoch 51/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3442 - accuracy: 0.8642 - precision_4: 0.8475 - recall_4: 0.8936 - custom_f1: 0.8665\nEpoch 51: val_loss did not improve from 0.23173\n32/32 [==============================] - 0s 6ms/step - loss: 0.3399 - accuracy: 0.8660 - precision_4: 0.8440 - recall_4: 0.8980 - custom_f1: 0.8644 - val_loss: 0.2319 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 5.1538e-06\nEpoch 52/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3486 - accuracy: 0.8438 - precision_4: 0.8500 - recall_4: 0.8420 - custom_f1: 0.8447\nEpoch 52: val_loss improved from 0.23173 to 0.23154, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3639 - accuracy: 0.8340 - precision_4: 0.8313 - recall_4: 0.8380 - custom_f1: 0.8352 - val_loss: 0.2315 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 4.6384e-06\nEpoch 53/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3177 - accuracy: 0.8737 - precision_4: 0.8645 - recall_4: 0.8841 - custom_f1: 0.8700\nEpoch 53: val_loss did not improve from 0.23154\n32/32 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8630 - precision_4: 0.8552 - recall_4: 0.8740 - custom_f1: 0.8607 - val_loss: 0.2319 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 4.1746e-06\nEpoch 54/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3528 - accuracy: 0.8462 - precision_4: 0.8420 - recall_4: 0.8525 - custom_f1: 0.8459\nEpoch 54: val_loss did not improve from 0.23154\n32/32 [==============================] - 0s 6ms/step - loss: 0.3437 - accuracy: 0.8490 - precision_4: 0.8442 - recall_4: 0.8560 - custom_f1: 0.8518 - val_loss: 0.2319 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 3.7571e-06\nEpoch 55/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3492 - accuracy: 0.8512 - precision_4: 0.8413 - recall_4: 0.8685 - custom_f1: 0.8478\nEpoch 55: val_loss did not improve from 0.23154\n32/32 [==============================] - 0s 6ms/step - loss: 0.3419 - accuracy: 0.8540 - precision_4: 0.8471 - recall_4: 0.8640 - custom_f1: 0.8505 - val_loss: 0.2318 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 3.3814e-06\nEpoch 56/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3363 - accuracy: 0.8594 - precision_4: 0.8243 - recall_4: 0.9037 - custom_f1: 0.8571\nEpoch 56: val_loss improved from 0.23154 to 0.23146, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3426 - accuracy: 0.8590 - precision_4: 0.8380 - recall_4: 0.8900 - custom_f1: 0.8517 - val_loss: 0.2315 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 3.0433e-06\nEpoch 57/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3380 - accuracy: 0.8562 - precision_4: 0.8239 - recall_4: 0.8977 - custom_f1: 0.8562\nEpoch 57: val_loss did not improve from 0.23146\n32/32 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.8580 - precision_4: 0.8365 - recall_4: 0.8900 - custom_f1: 0.8596 - val_loss: 0.2325 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 2.7389e-06\nEpoch 58/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3421 - accuracy: 0.8550 - precision_4: 0.8294 - recall_4: 0.8883 - custom_f1: 0.8550\nEpoch 58: val_loss did not improve from 0.23146\n32/32 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8500 - precision_4: 0.8302 - recall_4: 0.8800 - custom_f1: 0.8501 - val_loss: 0.2321 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 2.4650e-06\nEpoch 59/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3441 - accuracy: 0.8413 - precision_4: 0.8278 - recall_4: 0.8628 - custom_f1: 0.8428\nEpoch 59: val_loss did not improve from 0.23146\n32/32 [==============================] - 0s 6ms/step - loss: 0.3382 - accuracy: 0.8460 - precision_4: 0.8353 - recall_4: 0.8620 - custom_f1: 0.8473 - val_loss: 0.2316 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.2185e-06\nEpoch 60/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3187 - accuracy: 0.8725 - precision_4: 0.8547 - recall_4: 0.8897 - custom_f1: 0.8639\nEpoch 60: val_loss improved from 0.23146 to 0.23140, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3226 - accuracy: 0.8680 - precision_4: 0.8580 - recall_4: 0.8820 - custom_f1: 0.8617 - val_loss: 0.2314 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.9967e-06\nEpoch 61/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3373 - accuracy: 0.8370 - precision_4: 0.8122 - recall_4: 0.8743 - custom_f1: 0.8373\nEpoch 61: val_loss improved from 0.23140 to 0.23120, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.8440 - precision_4: 0.8197 - recall_4: 0.8820 - custom_f1: 0.8433 - val_loss: 0.2312 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 1.7970e-06\nEpoch 62/300\n29/32 [==========================>...] - ETA: 0s - loss: 0.3313 - accuracy: 0.8556 - precision_4: 0.8398 - recall_4: 0.8827 - custom_f1: 0.8578\nEpoch 62: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 7ms/step - loss: 0.3395 - accuracy: 0.8520 - precision_4: 0.8372 - recall_4: 0.8740 - custom_f1: 0.8399 - val_loss: 0.2314 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.6173e-06\nEpoch 63/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3494 - accuracy: 0.8500 - precision_4: 0.8337 - recall_4: 0.8790 - custom_f1: 0.8484\nEpoch 63: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8480 - precision_4: 0.8283 - recall_4: 0.8780 - custom_f1: 0.8470 - val_loss: 0.2313 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.4556e-06\nEpoch 64/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3230 - accuracy: 0.8562 - precision_4: 0.8372 - recall_4: 0.8889 - custom_f1: 0.8616\nEpoch 64: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3234 - accuracy: 0.8580 - precision_4: 0.8352 - recall_4: 0.8920 - custom_f1: 0.8558 - val_loss: 0.2317 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.3100e-06\nEpoch 65/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3493 - accuracy: 0.8500 - precision_4: 0.8369 - recall_4: 0.8741 - custom_f1: 0.8516\nEpoch 65: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3348 - accuracy: 0.8610 - precision_4: 0.8451 - recall_4: 0.8840 - custom_f1: 0.8565 - val_loss: 0.2315 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.1790e-06\nEpoch 66/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3214 - accuracy: 0.8815 - precision_4: 0.8678 - recall_4: 0.9016 - custom_f1: 0.8825\nEpoch 66: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3362 - accuracy: 0.8700 - precision_4: 0.8477 - recall_4: 0.9020 - custom_f1: 0.8749 - val_loss: 0.2314 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 1.0611e-06\nEpoch 67/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3764 - accuracy: 0.8356 - precision_4: 0.8210 - recall_4: 0.8629 - custom_f1: 0.8367\nEpoch 67: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8480 - precision_4: 0.8321 - recall_4: 0.8720 - custom_f1: 0.8482 - val_loss: 0.2314 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 9.5500e-07\nEpoch 68/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3413 - accuracy: 0.8600 - precision_4: 0.8368 - recall_4: 0.8953 - custom_f1: 0.8611\nEpoch 68: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8650 - precision_4: 0.8463 - recall_4: 0.8920 - custom_f1: 0.8685 - val_loss: 0.2314 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 8.5950e-07\nEpoch 69/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3615 - accuracy: 0.8359 - precision_4: 0.8161 - recall_4: 0.8594 - custom_f1: 0.8331\nEpoch 69: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8390 - precision_4: 0.8216 - recall_4: 0.8660 - custom_f1: 0.8389 - val_loss: 0.2316 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 7.7355e-07\nEpoch 70/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3311 - accuracy: 0.8737 - precision_4: 0.8544 - recall_4: 0.8995 - custom_f1: 0.8766\nEpoch 70: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3395 - accuracy: 0.8660 - precision_4: 0.8519 - recall_4: 0.8860 - custom_f1: 0.8606 - val_loss: 0.2326 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 6.9620e-07\nEpoch 71/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3162 - accuracy: 0.8723 - precision_4: 0.8611 - recall_4: 0.8974 - custom_f1: 0.8773\nEpoch 71: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8650 - precision_4: 0.8463 - recall_4: 0.8920 - custom_f1: 0.8702 - val_loss: 0.2329 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 6.2658e-07\nEpoch 72/300\n22/32 [===================>..........] - ETA: 0s - loss: 0.3400 - accuracy: 0.8665 - precision_4: 0.8680 - recall_4: 0.8680 - custom_f1: 0.8678\nEpoch 72: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 7ms/step - loss: 0.3411 - accuracy: 0.8640 - precision_4: 0.8640 - recall_4: 0.8640 - custom_f1: 0.8644 - val_loss: 0.2325 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 5.6392e-07\nEpoch 73/300\n22/32 [===================>..........] - ETA: 0s - loss: 0.3193 - accuracy: 0.8707 - precision_4: 0.8544 - recall_4: 0.8911 - custom_f1: 0.8699\nEpoch 73: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 7ms/step - loss: 0.3206 - accuracy: 0.8700 - precision_4: 0.8517 - recall_4: 0.8960 - custom_f1: 0.8713 - val_loss: 0.2324 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 5.0753e-07\nEpoch 74/300\n22/32 [===================>..........] - ETA: 0s - loss: 0.3320 - accuracy: 0.8693 - precision_4: 0.8497 - recall_4: 0.8937 - custom_f1: 0.8690\nEpoch 74: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 7ms/step - loss: 0.3342 - accuracy: 0.8670 - precision_4: 0.8469 - recall_4: 0.8960 - custom_f1: 0.8688 - val_loss: 0.2328 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 4.5678e-07\nEpoch 75/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3161 - accuracy: 0.8573 - precision_4: 0.8495 - recall_4: 0.8658 - custom_f1: 0.8539\nEpoch 75: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3084 - accuracy: 0.8630 - precision_4: 0.8580 - recall_4: 0.8700 - custom_f1: 0.8619 - val_loss: 0.2323 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 4.1110e-07\nEpoch 76/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3403 - accuracy: 0.8600 - precision_4: 0.8416 - recall_4: 0.8878 - custom_f1: 0.8600\nEpoch 76: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8570 - precision_4: 0.8400 - recall_4: 0.8820 - custom_f1: 0.8561 - val_loss: 0.2316 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 3.6999e-07\nEpoch 77/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3319 - accuracy: 0.8537 - precision_4: 0.8405 - recall_4: 0.8759 - custom_f1: 0.8541\nEpoch 77: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3416 - accuracy: 0.8500 - precision_4: 0.8378 - recall_4: 0.8680 - custom_f1: 0.8379 - val_loss: 0.2321 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 3.3299e-07\nEpoch 78/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3365 - accuracy: 0.8600 - precision_4: 0.8500 - recall_4: 0.8793 - custom_f1: 0.8622\nEpoch 78: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3256 - accuracy: 0.8640 - precision_4: 0.8460 - recall_4: 0.8900 - custom_f1: 0.8630 - val_loss: 0.2322 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.9969e-07\nEpoch 79/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3426 - accuracy: 0.8537 - precision_4: 0.8491 - recall_4: 0.8639 - custom_f1: 0.8545\nEpoch 79: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3367 - accuracy: 0.8540 - precision_4: 0.8444 - recall_4: 0.8680 - custom_f1: 0.8544 - val_loss: 0.2318 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.6972e-07\nEpoch 80/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3194 - accuracy: 0.8724 - precision_4: 0.8483 - recall_4: 0.9021 - custom_f1: 0.8729\nEpoch 80: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3205 - accuracy: 0.8690 - precision_4: 0.8488 - recall_4: 0.8980 - custom_f1: 0.8737 - val_loss: 0.2315 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.4275e-07\nEpoch 81/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3234 - accuracy: 0.8700 - precision_4: 0.8534 - recall_4: 0.8958 - custom_f1: 0.8705\nEpoch 81: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.8660 - precision_4: 0.8479 - recall_4: 0.8920 - custom_f1: 0.8633 - val_loss: 0.2315 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.1847e-07\nEpoch 82/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3292 - accuracy: 0.8575 - precision_4: 0.8404 - recall_4: 0.8861 - custom_f1: 0.8607\nEpoch 82: val_loss did not improve from 0.23120\n32/32 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8510 - precision_4: 0.8343 - recall_4: 0.8760 - custom_f1: 0.8523 - val_loss: 0.2314 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.9663e-07\nEpoch 83/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3109 - accuracy: 0.8650 - precision_4: 0.8417 - recall_4: 0.8931 - custom_f1: 0.8637\nEpoch 83: val_loss improved from 0.23120 to 0.23101, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 0.8650 - precision_4: 0.8489 - recall_4: 0.8880 - custom_f1: 0.8621 - val_loss: 0.2310 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.7696e-07\nEpoch 84/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3502 - accuracy: 0.8462 - precision_4: 0.8259 - recall_4: 0.8775 - custom_f1: 0.8484\nEpoch 84: val_loss did not improve from 0.23101\n32/32 [==============================] - 0s 6ms/step - loss: 0.3520 - accuracy: 0.8410 - precision_4: 0.8235 - recall_4: 0.8680 - custom_f1: 0.8345 - val_loss: 0.2314 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 1.5927e-07\nEpoch 85/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3346 - accuracy: 0.8573 - precision_4: 0.8489 - recall_4: 0.8607 - custom_f1: 0.8550\nEpoch 85: val_loss improved from 0.23101 to 0.23098, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 8ms/step - loss: 0.3407 - accuracy: 0.8560 - precision_4: 0.8490 - recall_4: 0.8660 - custom_f1: 0.8570 - val_loss: 0.2310 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.4334e-07\nEpoch 86/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3276 - accuracy: 0.8737 - precision_4: 0.8485 - recall_4: 0.9008 - custom_f1: 0.8704\nEpoch 86: val_loss did not improve from 0.23098\n32/32 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8690 - precision_4: 0.8541 - recall_4: 0.8900 - custom_f1: 0.8639 - val_loss: 0.2311 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.2901e-07\nEpoch 87/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3786 - accuracy: 0.8464 - precision_4: 0.8266 - recall_4: 0.8704 - custom_f1: 0.8443\nEpoch 87: val_loss improved from 0.23098 to 0.23077, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3656 - accuracy: 0.8550 - precision_4: 0.8447 - recall_4: 0.8700 - custom_f1: 0.8553 - val_loss: 0.2308 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.1611e-07\nEpoch 88/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3258 - accuracy: 0.8625 - precision_4: 0.8389 - recall_4: 0.8903 - custom_f1: 0.8608\nEpoch 88: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8580 - precision_4: 0.8403 - recall_4: 0.8840 - custom_f1: 0.8579 - val_loss: 0.2309 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.0450e-07\nEpoch 89/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3380 - accuracy: 0.8512 - precision_4: 0.8275 - recall_4: 0.8875 - custom_f1: 0.8506\nEpoch 89: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3379 - accuracy: 0.8570 - precision_4: 0.8374 - recall_4: 0.8860 - custom_f1: 0.8589 - val_loss: 0.2311 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 9.4046e-08\nEpoch 90/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3373 - accuracy: 0.8542 - precision_4: 0.8301 - recall_4: 0.8906 - custom_f1: 0.8522\nEpoch 90: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.8500 - precision_4: 0.8289 - recall_4: 0.8820 - custom_f1: 0.8456 - val_loss: 0.2309 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 8.4641e-08\nEpoch 91/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3279 - accuracy: 0.8655 - precision_4: 0.8422 - recall_4: 0.8873 - custom_f1: 0.8588\nEpoch 91: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.8660 - precision_4: 0.8492 - recall_4: 0.8900 - custom_f1: 0.8674 - val_loss: 0.2310 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 7.6177e-08\nEpoch 92/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3437 - accuracy: 0.8477 - precision_4: 0.8231 - recall_4: 0.8816 - custom_f1: 0.8457\nEpoch 92: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8550 - precision_4: 0.8355 - recall_4: 0.8840 - custom_f1: 0.8547 - val_loss: 0.2309 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 6.8560e-08\nEpoch 93/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3311 - accuracy: 0.8620 - precision_4: 0.8456 - recall_4: 0.8892 - custom_f1: 0.8623\nEpoch 93: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3303 - accuracy: 0.8630 - precision_4: 0.8418 - recall_4: 0.8940 - custom_f1: 0.8625 - val_loss: 0.2309 - val_accuracy: 0.9280 - val_precision_4: 0.8905 - val_recall_4: 0.9760 - val_custom_f1: 0.7873 - lr: 6.1704e-08\nEpoch 94/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3183 - accuracy: 0.8810 - precision_4: 0.8681 - recall_4: 0.8993 - custom_f1: 0.8825\nEpoch 94: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3153 - accuracy: 0.8820 - precision_4: 0.8659 - recall_4: 0.9040 - custom_f1: 0.8865 - val_loss: 0.2311 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 5.5533e-08\nEpoch 95/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3444 - accuracy: 0.8375 - precision_4: 0.8111 - recall_4: 0.8800 - custom_f1: 0.8390\nEpoch 95: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.8460 - precision_4: 0.8252 - recall_4: 0.8780 - custom_f1: 0.8450 - val_loss: 0.2320 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 4.9980e-08\nEpoch 96/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3096 - accuracy: 0.8750 - precision_4: 0.8675 - recall_4: 0.8889 - custom_f1: 0.8738\nEpoch 96: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3127 - accuracy: 0.8710 - precision_4: 0.8602 - recall_4: 0.8860 - custom_f1: 0.8675 - val_loss: 0.2322 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 4.4982e-08\nEpoch 97/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3512 - accuracy: 0.8388 - precision_4: 0.8280 - recall_4: 0.8510 - custom_f1: 0.8391\nEpoch 97: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.8470 - precision_4: 0.8343 - recall_4: 0.8660 - custom_f1: 0.8497 - val_loss: 0.2317 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 4.0484e-08\nEpoch 98/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3214 - accuracy: 0.8625 - precision_4: 0.8511 - recall_4: 0.8845 - custom_f1: 0.8638\nEpoch 98: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8510 - precision_4: 0.8343 - recall_4: 0.8760 - custom_f1: 0.8541 - val_loss: 0.2315 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 3.6435e-08\nEpoch 99/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3328 - accuracy: 0.8612 - precision_4: 0.8440 - recall_4: 0.8881 - custom_f1: 0.8631\nEpoch 99: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3252 - accuracy: 0.8640 - precision_4: 0.8473 - recall_4: 0.8880 - custom_f1: 0.8679 - val_loss: 0.2315 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 3.2792e-08\nEpoch 100/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3582 - accuracy: 0.8512 - precision_4: 0.8122 - recall_4: 0.8987 - custom_f1: 0.8534\nEpoch 100: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3443 - accuracy: 0.8590 - precision_4: 0.8368 - recall_4: 0.8920 - custom_f1: 0.8661 - val_loss: 0.2316 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 2.9513e-08\nEpoch 101/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3484 - accuracy: 0.8525 - precision_4: 0.8306 - recall_4: 0.8847 - custom_f1: 0.8572\nEpoch 101: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3415 - accuracy: 0.8540 - precision_4: 0.8340 - recall_4: 0.8840 - custom_f1: 0.8531 - val_loss: 0.2311 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 2.6561e-08\nEpoch 102/300\n26/32 [=======================>......] - ETA: 0s - loss: 0.3478 - accuracy: 0.8558 - precision_4: 0.8437 - recall_4: 0.8759 - custom_f1: 0.8607\nEpoch 102: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8480 - precision_4: 0.8359 - recall_4: 0.8660 - custom_f1: 0.8463 - val_loss: 0.2311 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 2.3905e-08\nEpoch 103/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3406 - accuracy: 0.8525 - precision_4: 0.8298 - recall_4: 0.8841 - custom_f1: 0.8529\nEpoch 103: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8550 - precision_4: 0.8330 - recall_4: 0.8880 - custom_f1: 0.8618 - val_loss: 0.2317 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.1515e-08\nEpoch 104/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3359 - accuracy: 0.8587 - precision_4: 0.8404 - recall_4: 0.8731 - custom_f1: 0.8516\nEpoch 104: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8600 - precision_4: 0.8516 - recall_4: 0.8720 - custom_f1: 0.8511 - val_loss: 0.2310 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.9363e-08\nEpoch 105/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3239 - accuracy: 0.8612 - precision_4: 0.8291 - recall_4: 0.9066 - custom_f1: 0.8628\nEpoch 105: val_loss did not improve from 0.23077\n32/32 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8640 - precision_4: 0.8370 - recall_4: 0.9040 - custom_f1: 0.8661 - val_loss: 0.2311 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.7427e-08\nEpoch 106/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3509 - accuracy: 0.8587 - precision_4: 0.8527 - recall_4: 0.8756 - custom_f1: 0.8654\nEpoch 106: val_loss improved from 0.23077 to 0.23061, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8700 - precision_4: 0.8599 - recall_4: 0.8840 - custom_f1: 0.8661 - val_loss: 0.2306 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.5684e-08\nEpoch 107/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3234 - accuracy: 0.8700 - precision_4: 0.8647 - recall_4: 0.8818 - custom_f1: 0.8725\nEpoch 107: val_loss did not improve from 0.23061\n32/32 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8690 - precision_4: 0.8555 - recall_4: 0.8880 - custom_f1: 0.8730 - val_loss: 0.2307 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.4116e-08\nEpoch 108/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3506 - accuracy: 0.8450 - precision_4: 0.8397 - recall_4: 0.8603 - custom_f1: 0.8474\nEpoch 108: val_loss improved from 0.23061 to 0.23023, saving model to best_hybrid_fold5_model.h5\n32/32 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.8450 - precision_4: 0.8376 - recall_4: 0.8560 - custom_f1: 0.8432 - val_loss: 0.2302 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.2704e-08\nEpoch 109/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3354 - accuracy: 0.8512 - precision_4: 0.8222 - recall_4: 0.8945 - custom_f1: 0.8537\nEpoch 109: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8590 - precision_4: 0.8306 - recall_4: 0.9020 - custom_f1: 0.8651 - val_loss: 0.2304 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.1434e-08\nEpoch 110/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3284 - accuracy: 0.8529 - precision_4: 0.8362 - recall_4: 0.8776 - custom_f1: 0.8532\nEpoch 110: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.8550 - precision_4: 0.8433 - recall_4: 0.8720 - custom_f1: 0.8498 - val_loss: 0.2309 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.0290e-08\nEpoch 111/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3453 - accuracy: 0.8363 - precision_4: 0.8113 - recall_4: 0.8709 - custom_f1: 0.8391\nEpoch 111: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3348 - accuracy: 0.8470 - precision_4: 0.8219 - recall_4: 0.8860 - custom_f1: 0.8539 - val_loss: 0.2320 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 9.2614e-09\nEpoch 112/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3307 - accuracy: 0.8550 - precision_4: 0.8396 - recall_4: 0.8812 - custom_f1: 0.8570\nEpoch 112: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3253 - accuracy: 0.8590 - precision_4: 0.8419 - recall_4: 0.8840 - custom_f1: 0.8595 - val_loss: 0.2320 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 8.3352e-09\nEpoch 113/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3336 - accuracy: 0.8612 - precision_4: 0.8547 - recall_4: 0.8738 - custom_f1: 0.8603\nEpoch 113: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8500 - precision_4: 0.8391 - recall_4: 0.8660 - custom_f1: 0.8529 - val_loss: 0.2318 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 7.5017e-09\nEpoch 114/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3185 - accuracy: 0.8659 - precision_4: 0.8313 - recall_4: 0.9127 - custom_f1: 0.8634\nEpoch 114: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3239 - accuracy: 0.8620 - precision_4: 0.8315 - recall_4: 0.9080 - custom_f1: 0.8560 - val_loss: 0.2319 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 6.7516e-09\nEpoch 115/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3446 - accuracy: 0.8462 - precision_4: 0.8294 - recall_4: 0.8728 - custom_f1: 0.8439\nEpoch 115: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8500 - precision_4: 0.8340 - recall_4: 0.8740 - custom_f1: 0.8525 - val_loss: 0.2320 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 6.0764e-09\nEpoch 116/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3461 - accuracy: 0.8450 - precision_4: 0.8238 - recall_4: 0.8737 - custom_f1: 0.8447\nEpoch 116: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3459 - accuracy: 0.8510 - precision_4: 0.8343 - recall_4: 0.8760 - custom_f1: 0.8496 - val_loss: 0.2318 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 5.4688e-09\nEpoch 117/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3195 - accuracy: 0.8537 - precision_4: 0.8484 - recall_4: 0.8632 - custom_f1: 0.8563\nEpoch 117: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.8530 - precision_4: 0.8454 - recall_4: 0.8640 - custom_f1: 0.8520 - val_loss: 0.2319 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 4.9219e-09\nEpoch 118/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3447 - accuracy: 0.8750 - precision_4: 0.8568 - recall_4: 0.9035 - custom_f1: 0.8779\nEpoch 118: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8700 - precision_4: 0.8464 - recall_4: 0.9040 - custom_f1: 0.8713 - val_loss: 0.2321 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 4.4297e-09\nEpoch 119/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3349 - accuracy: 0.8587 - precision_4: 0.8592 - recall_4: 0.8655 - custom_f1: 0.8586\nEpoch 119: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8580 - precision_4: 0.8482 - recall_4: 0.8720 - custom_f1: 0.8461 - val_loss: 0.2321 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 3.9867e-09\nEpoch 120/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3058 - accuracy: 0.8687 - precision_4: 0.8512 - recall_4: 0.8880 - custom_f1: 0.8663\nEpoch 120: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3212 - accuracy: 0.8570 - precision_4: 0.8413 - recall_4: 0.8800 - custom_f1: 0.8568 - val_loss: 0.2318 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 3.5881e-09\nEpoch 121/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3313 - accuracy: 0.8537 - precision_4: 0.8405 - recall_4: 0.8759 - custom_f1: 0.8540\nEpoch 121: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3221 - accuracy: 0.8600 - precision_4: 0.8422 - recall_4: 0.8860 - custom_f1: 0.8643 - val_loss: 0.2318 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 3.2292e-09\nEpoch 122/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3540 - accuracy: 0.8425 - precision_4: 0.8376 - recall_4: 0.8620 - custom_f1: 0.8460\nEpoch 122: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8430 - precision_4: 0.8279 - recall_4: 0.8660 - custom_f1: 0.8407 - val_loss: 0.2322 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.9063e-09\nEpoch 123/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3065 - accuracy: 0.8737 - precision_4: 0.8582 - recall_4: 0.8985 - custom_f1: 0.8756\nEpoch 123: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3076 - accuracy: 0.8720 - precision_4: 0.8550 - recall_4: 0.8960 - custom_f1: 0.8737 - val_loss: 0.2319 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.6157e-09\nEpoch 124/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3544 - accuracy: 0.8487 - precision_4: 0.8410 - recall_4: 0.8639 - custom_f1: 0.8523\nEpoch 124: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3542 - accuracy: 0.8510 - precision_4: 0.8395 - recall_4: 0.8680 - custom_f1: 0.8539 - val_loss: 0.2319 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.3541e-09\nEpoch 125/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3260 - accuracy: 0.8650 - precision_4: 0.8502 - recall_4: 0.8844 - custom_f1: 0.8653\nEpoch 125: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3302 - accuracy: 0.8630 - precision_4: 0.8470 - recall_4: 0.8860 - custom_f1: 0.8685 - val_loss: 0.2322 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 2.1187e-09\nEpoch 126/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3272 - accuracy: 0.8600 - precision_4: 0.8385 - recall_4: 0.8892 - custom_f1: 0.8584\nEpoch 126: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8560 - precision_4: 0.8384 - recall_4: 0.8820 - custom_f1: 0.8568 - val_loss: 0.2318 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.9068e-09\nEpoch 127/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3075 - accuracy: 0.8725 - precision_4: 0.8460 - recall_4: 0.9061 - custom_f1: 0.8734\nEpoch 127: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3086 - accuracy: 0.8710 - precision_4: 0.8493 - recall_4: 0.9020 - custom_f1: 0.8725 - val_loss: 0.2324 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.7162e-09\nEpoch 128/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3430 - accuracy: 0.8462 - precision_4: 0.8248 - recall_4: 0.8803 - custom_f1: 0.8489\nEpoch 128: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3311 - accuracy: 0.8550 - precision_4: 0.8343 - recall_4: 0.8860 - custom_f1: 0.8584 - val_loss: 0.2318 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.5445e-09\nEpoch 129/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3335 - accuracy: 0.8600 - precision_4: 0.8405 - recall_4: 0.8869 - custom_f1: 0.8619\nEpoch 129: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3234 - accuracy: 0.8630 - precision_4: 0.8457 - recall_4: 0.8880 - custom_f1: 0.8657 - val_loss: 0.2323 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 1.3901e-09\nEpoch 130/300\n25/32 [======================>.......] - ETA: 0s - loss: 0.3225 - accuracy: 0.8637 - precision_4: 0.8415 - recall_4: 0.8980 - custom_f1: 0.8605\nEpoch 130: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3339 - accuracy: 0.8510 - precision_4: 0.8369 - recall_4: 0.8720 - custom_f1: 0.8465 - val_loss: 0.2336 - val_accuracy: 0.9200 - val_precision_4: 0.8777 - val_recall_4: 0.9760 - val_custom_f1: 0.7693 - lr: 1.2511e-09\nEpoch 131/300\n24/32 [=====================>........] - ETA: 0s - loss: 0.3375 - accuracy: 0.8594 - precision_4: 0.8504 - recall_4: 0.8766 - custom_f1: 0.8577\nEpoch 131: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3423 - accuracy: 0.8510 - precision_4: 0.8395 - recall_4: 0.8680 - custom_f1: 0.8343 - val_loss: 0.2330 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.1260e-09\nEpoch 132/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3245 - accuracy: 0.8560 - precision_4: 0.8400 - recall_4: 0.8726 - custom_f1: 0.8531\nEpoch 132: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8570 - precision_4: 0.8439 - recall_4: 0.8760 - custom_f1: 0.8470 - val_loss: 0.2325 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 1.0134e-09\nEpoch 133/300\n23/32 [====================>.........] - ETA: 0s - loss: 0.3472 - accuracy: 0.8478 - precision_4: 0.8487 - recall_4: 0.8620 - custom_f1: 0.8521Restoring model weights from the end of the best epoch: 108.\n\nEpoch 133: val_loss did not improve from 0.23023\n32/32 [==============================] - 0s 7ms/step - loss: 0.3456 - accuracy: 0.8490 - precision_4: 0.8286 - recall_4: 0.8800 - custom_f1: 0.8544 - val_loss: 0.2325 - val_accuracy: 0.9240 - val_precision_4: 0.8841 - val_recall_4: 0.9760 - val_custom_f1: 0.7739 - lr: 9.1203e-10\nEpoch 133: early stopping\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\ny_proba = np.mean([m.predict(X_val_fold, verbose=0) for m in models.values()], axis=0)\nfpr, tpr, thresholds = roc_curve(y_val_fold, y_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(6, 5))\nplt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:51:31.642500Z","iopub.execute_input":"2025-09-26T04:51:31.642900Z","iopub.status.idle":"2025-09-26T04:51:32.323545Z","shell.execute_reply.started":"2025-09-26T04:51:31.642875Z","shell.execute_reply":"2025-09-26T04:51:32.322539Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"from sklearn.calibration import calibration_curve\n\nprob_true, prob_pred = calibration_curve(y_val_fold, y_proba, n_bins=10)\n\nplt.figure(figsize=(6, 5))\nplt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve')\nplt.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')\nplt.xlabel('Mean Predicted Probability')\nplt.ylabel('Fraction of Positives')\nplt.title('Calibration Curve')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:51:40.682688Z","iopub.execute_input":"2025-09-26T04:51:40.683060Z","iopub.status.idle":"2025-09-26T04:51:40.886537Z","shell.execute_reply.started":"2025-09-26T04:51:40.683033Z","shell.execute_reply":"2025-09-26T04:51:40.885582Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ny_pred = (y_proba >= 0.5).astype(int)\ncm = confusion_matrix(y_val_fold, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:51:47.062266Z","iopub.execute_input":"2025-09-26T04:51:47.062615Z","iopub.status.idle":"2025-09-26T04:51:47.258747Z","shell.execute_reply.started":"2025-09-26T04:51:47.062590Z","shell.execute_reply":"2025-09-26T04:51:47.257706Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"from sklearn.metrics import brier_score_loss, log_loss\n\nbrier = brier_score_loss(y_val_fold, y_proba)\nlogloss = log_loss(y_val_fold, y_proba)\n\nprint(f\"Brier Score: {brier:.4f}\")\nprint(f\"Log Loss: {logloss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:51:55.682103Z","iopub.execute_input":"2025-09-26T04:51:55.682491Z","iopub.status.idle":"2025-09-26T04:51:55.692604Z","shell.execute_reply.started":"2025-09-26T04:51:55.682464Z","shell.execute_reply":"2025-09-26T04:51:55.691741Z"}},"outputs":[{"name":"stdout","text":"Brier Score: 0.0480\nLog Loss: 0.1925\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, average_precision_score\n\nprecision, recall, _ = precision_recall_curve(y_val_fold, y_proba)\navg_precision = average_precision_score(y_val_fold, y_proba)\n\nplt.figure(figsize=(6, 5))\nplt.plot(recall, precision, label=f'PR Curve (AP = {avg_precision:.2f})')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:53:37.986773Z","iopub.execute_input":"2025-09-26T04:53:37.987487Z","iopub.status.idle":"2025-09-26T04:53:38.177669Z","shell.execute_reply.started":"2025-09-26T04:53:37.987457Z","shell.execute_reply":"2025-09-26T04:53:38.176510Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\nthresholds = np.linspace(0.1, 0.9, 50)\nf1s, precisions, recalls = [], [], []\n\nfor t in thresholds:\n    y_pred_thresh = (y_proba >= t).astype(int)\n    f1s.append(f1_score(y_val_fold, y_pred_thresh))\n    precisions.append(precision_score(y_val_fold, y_pred_thresh))\n    recalls.append(recall_score(y_val_fold, y_pred_thresh))\n\nplt.figure(figsize=(8, 6))\nplt.plot(thresholds, f1s, label='F1 Score')\nplt.plot(thresholds, precisions, label='Precision')\nplt.plot(thresholds, recalls, label='Recall')\nplt.xlabel('Threshold')\nplt.ylabel('Score')\nplt.title('Threshold Sweep: F1, Precision, Recall')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:54:33.546659Z","iopub.execute_input":"2025-09-26T04:54:33.547022Z","iopub.status.idle":"2025-09-26T04:54:34.066739Z","shell.execute_reply.started":"2025-09-26T04:54:33.546997Z","shell.execute_reply":"2025-09-26T04:54:34.065705Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"sns.histplot(y_proba[y_val_fold == 0], color='red', label='Class 0', kde=True)\nsns.histplot(y_proba[y_val_fold == 1], color='green', label='Class 1', kde=True)\nplt.title('Prediction Probability Distribution')\nplt.xlabel('Predicted Probability')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:54:41.756855Z","iopub.execute_input":"2025-09-26T04:54:41.757218Z","iopub.status.idle":"2025-09-26T04:54:42.111617Z","shell.execute_reply.started":"2025-09-26T04:54:41.757193Z","shell.execute_reply":"2025-09-26T04:54:42.110626Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"pred_matrix = np.array([m.predict(X_val_fold, verbose=0).flatten() for m in models.values()])\nstd_dev = np.std(pred_matrix, axis=0)\n\nplt.figure(figsize=(6, 5))\nplt.hist(std_dev, bins=30, color='purple', alpha=0.7)\nplt.title('Ensemble Prediction Variance')\nplt.xlabel('Standard Deviation Across Models')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:54:49.115864Z","iopub.execute_input":"2025-09-26T04:54:49.116237Z","iopub.status.idle":"2025-09-26T04:54:49.779730Z","shell.execute_reply.started":"2025-09-26T04:54:49.116213Z","shell.execute_reply":"2025-09-26T04:54:49.778645Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure predictions and labels are 1D NumPy arrays\ny_val_np = np.array(y_val_fold).flatten()\ny_proba_np = np.array(y_proba).flatten()\n\n# Define bins and assign predictions to bins\nbins = np.linspace(0, 1, 11)\nbin_ids = np.digitize(y_proba_np, bins) - 1\n\n# Compute accuracy per bin\nbin_acc = []\nfor i in range(len(bins) - 1):\n    mask = bin_ids == i\n    if np.sum(mask) > 0:\n        acc = np.mean(y_val_np[mask] == (y_proba_np[mask] >= 0.5))\n    else:\n        acc = np.nan  \n    bin_acc.append(acc)\n\n# Plot reliability diagram\nplt.figure(figsize=(7, 5))\nplt.bar(bins[:-1], bin_acc, width=0.09, align='edge', color='teal', edgecolor='black')\nplt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\nplt.xlabel('Confidence Bin')\nplt.ylabel('Accuracy')\nplt.title('Reliability Diagram')\nplt.xticks(bins)\nplt.ylim(0, 1.05)\nplt.grid(True)\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:57:03.562060Z","iopub.execute_input":"2025-09-26T04:57:03.563030Z","iopub.status.idle":"2025-09-26T04:57:03.808483Z","shell.execute_reply.started":"2025-09-26T04:57:03.562998Z","shell.execute_reply":"2025-09-26T04:57:03.807486Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 700x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Replace these with your actual fold-wise metrics\nmetrics_df = pd.DataFrame({\n    'Fold': [f'Fold {i+1}' for i in range(5)],\n    'F1': [0.82, 0.85, 0.80, 0.83, 0.84],\n    'Precision': [0.81, 0.86, 0.78, 0.82, 0.85],\n    'Recall': [0.83, 0.84, 0.82, 0.85, 0.83]\n})\n\nmetrics_df.set_index('Fold').plot(kind='bar', figsize=(8, 6))\nplt.title('Fold-wise Metrics')\nplt.ylabel('Score')\nplt.grid(True)\nplt.xticks(rotation=0)\nplt.ylim(0.7, 1.0)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T04:55:45.487184Z","iopub.execute_input":"2025-09-26T04:55:45.487905Z","iopub.status.idle":"2025-09-26T04:55:45.787526Z","shell.execute_reply.started":"2025-09-26T04:55:45.487878Z","shell.execute_reply":"2025-09-26T04:55:45.786582Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":52}]}